{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import LSTM, Dense, Dropout, Input, Conv1D, Flatten, concatenate\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Definir look_back\n",
    "look_back = 6  \n",
    "\n",
    "# Cargar el archivo y eliminar filas donde el clúster es NaN\n",
    "file_path = 'data/data.csv'   # Cambia esta ruta al archivo que has subido\n",
    "data = pd.read_csv(file_path)\n",
    "data = data.dropna(subset=['Cluster_Label'])\n",
    "\n",
    "# Convertir 'year' y 'month_no' a una sola columna de tipo fecha\n",
    "data['date'] = pd.to_datetime(data['year'].astype(str) + '-' + data['month_no'].astype(str))\n",
    "\n",
    "# Seleccionar las columnas necesarias para la serie temporal\n",
    "columns_to_keep = ['date', 'species', 'Cluster_Label', 'landed_w_kg',\n",
    "                   'mean_temp_30m','mean_temp_10m','thetao_sfc=6',\n",
    "                   'thetao_sfc=7.92956018447876','thetao_sfc=9.572997093200684','thetao_sfc=11.40499973297119',\n",
    "                   'thetao_sfc=13.46714019775391','thetao_sfc=15.8100700378418','thetao_sfc=18.49555969238281',\n",
    "                   'thetao_sfc=21.59881973266602','thetao_sfc=25.21141052246094','thetao_sfc=29.44473075866699']\n",
    "data = data[columns_to_keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para preparar los datos\n",
    "def prepare_data(group, look_back=6):\n",
    "    features = ['landed_w_kg','Cluster_Label', 'mean_temp_30m','mean_temp_10m','thetao_sfc=6',\n",
    "                   'thetao_sfc=7.92956018447876','thetao_sfc=9.572997093200684','thetao_sfc=11.40499973297119',\n",
    "                   'thetao_sfc=13.46714019775391','thetao_sfc=15.8100700378418','thetao_sfc=18.49555969238281',\n",
    "                   'thetao_sfc=21.59881973266602','thetao_sfc=25.21141052246094','thetao_sfc=29.44473075866699']\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    group_scaled = scaler.fit_transform(group[features])\n",
    "    \n",
    "    X, y = [], []\n",
    "    for i in range(len(group_scaled) - look_back):\n",
    "        a = group_scaled[i:(i + look_back)]\n",
    "        X.append(a)\n",
    "        y.append(group_scaled[i + look_back, 0])  # La primera columna es 'landed_w_kg'\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2]))\n",
    "    return X, y, scaler\n",
    "\n",
    "# Crear el modelo LSTM\n",
    "def create_lstm_model(input_shape):\n",
    "    lstm_input = Input(shape=input_shape)\n",
    "    x = LSTM(50, return_sequences=True)(lstm_input)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = LSTM(25, activation='relu', return_sequences=True)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = LSTM(12, activation='linear')(x)\n",
    "    lstm_output = Dense(1, activation='linear')(x)\n",
    "    return Model(inputs=lstm_input, outputs=lstm_output)\n",
    "\n",
    "# Crear el modelo DNN\n",
    "def create_dnn_model(input_shape):\n",
    "    dnn_input = Input(shape=(input_shape[0], input_shape[1]))\n",
    "    x = Flatten()(dnn_input)\n",
    "    x = Dense(10, activation='relu')(x)\n",
    "    x = Dense(5, activation='relu')(x)\n",
    "    dnn_output = Dense(1, activation='linear')(x)\n",
    "    return Model(inputs=dnn_input, outputs=dnn_output)\n",
    "\n",
    "# Crear el modelo CNN\n",
    "def create_cnn_model(input_shape):\n",
    "    cnn_input = Input(shape=input_shape)\n",
    "    x = Conv1D(32, kernel_size=3, activation='relu')(cnn_input)\n",
    "    x = Flatten()(x)\n",
    "    cnn_output = Dense(1, activation='linear')(x)\n",
    "    return Model(inputs=cnn_input, outputs=cnn_output)\n",
    "\n",
    "# Crear el modelo Mixture of Experts (MoE)\n",
    "def create_moe_model(input_shape):\n",
    "    # Definir los expertos\n",
    "    lstm_model = create_lstm_model(input_shape)\n",
    "    dnn_model = create_dnn_model(input_shape)\n",
    "    cnn_model = create_cnn_model(input_shape)\n",
    "    \n",
    "    # Definir el gating network\n",
    "    moe_input = Input(shape=input_shape)\n",
    "    x = Flatten()(moe_input)\n",
    "    x = Dense(10, activation='relu')(x)\n",
    "    gate_output = Dense(3, activation='softmax')(x)  # Tres expertos\n",
    "\n",
    "    # Obtener las salidas de los expertos\n",
    "    lstm_output = lstm_model(moe_input)\n",
    "    dnn_output = dnn_model(moe_input)\n",
    "    cnn_output = cnn_model(moe_input)\n",
    "    \n",
    "    # Combinar las salidas usando el gating network\n",
    "    output = concatenate([lstm_output * gate_output[:, 0:1],\n",
    "                          dnn_output * gate_output[:, 1:2],\n",
    "                          cnn_output * gate_output[:, 2:3]], axis=1)\n",
    "    output = Dense(1, activation='linear')(output)\n",
    "    \n",
    "    model = Model(inputs=moe_input, outputs=output)\n",
    "    model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar y guardar el modelo MoE\n",
    "def train_and_save_moe_model(data, species_name, cluster_label, look_back=look_back, epochs=50, batch_size=1):\n",
    "    X, y, scaler = prepare_data(data, look_back)\n",
    "    model = create_moe_model((look_back, X.shape[2]))\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "    history = model.fit(X, y, validation_split=0.2, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[early_stopping])\n",
    "    \n",
    "    # Guardar el modelo y el scaler\n",
    "    model_directory = 'modelos_moe'\n",
    "    os.makedirs(model_directory, exist_ok=True)\n",
    "    model_path = os.path.join(model_directory, f'{species_name}_cluster_{cluster_label}_moe_model.h5')\n",
    "    scaler_path = os.path.join(model_directory, f'{species_name}_cluster_{cluster_label}_moe_scaler.pkl')\n",
    "    model.save(model_path)\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    \n",
    "    # Guardar los valores de monitoreo del entrenamiento\n",
    "    train_moe_directory = 'train_moe'\n",
    "    os.makedirs(train_moe_directory, exist_ok=True)\n",
    "    history_path = os.path.join(train_moe_directory, f'{species_name}_cluster_{cluster_label}_training_history.csv')\n",
    "    pd.DataFrame(history.history).to_csv(history_path, index=False)\n",
    "    \n",
    "    print(f'Modelo MoE, scaler y datos de entrenamiento guardados para {species_name} en clúster {cluster_label}')\n",
    "    return model, scaler\n",
    "\n",
    "# Función para hacer predicciones con bandas de confianza usando bootstrap\n",
    "def predict_with_confidence_intervals(model, scaler, data, look_back=6, n_bootstrap=100, alpha=0.01):\n",
    "    features = ['landed_w_kg','Cluster_Label','mean_temp_30m','mean_temp_10m','thetao_sfc=6',\n",
    "                   'thetao_sfc=7.92956018447876','thetao_sfc=9.572997093200684','thetao_sfc=11.40499973297119',\n",
    "                   'thetao_sfc=13.46714019775391','thetao_sfc=15.8100700378418','thetao_sfc=18.49555969238281',\n",
    "                   'thetao_sfc=21.59881973266602','thetao_sfc=25.21141052246094','thetao_sfc=29.44473075866699']\n",
    "    group_scaled = scaler.transform(data[features])\n",
    "\n",
    "    X = []\n",
    "    for i in range(len(group_scaled) - look_back):\n",
    "        a = group_scaled[i:(i + look_back)]\n",
    "        X.append(a)\n",
    "    X = np.array(X)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2]))\n",
    "    \n",
    "    predictions = model.predict(X)\n",
    "    predictions = scaler.inverse_transform(np.hstack((predictions, X[:, -1, 1:])))[:, 0]\n",
    "    \n",
    "    # Bootstrap para bandas de confianza\n",
    "    bootstrap_predictions = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        indices = np.random.choice(range(len(X)), len(X), replace=True)\n",
    "        X_sample = X[indices]\n",
    "        pred_sample = model.predict(X_sample)\n",
    "        pred_sample = scaler.inverse_transform(np.hstack((pred_sample, X_sample[:, -1, 1:])))[:, 0]\n",
    "        bootstrap_predictions.append(pred_sample)\n",
    "    \n",
    "    bootstrap_predictions = np.array(bootstrap_predictions)\n",
    "    lower_bound = np.percentile(bootstrap_predictions, 100 * alpha / 2, axis=0)\n",
    "    upper_bound = np.percentile(bootstrap_predictions, 100 * (1 - alpha / 2), axis=0)\n",
    "    \n",
    "    return predictions, lower_bound, upper_bound\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: RAYA Y SIMILARES, cluster: 7\n",
      "Epoch 1/50\n",
      "1240/1240 [==============================] - 10s 5ms/step - loss: 0.0095 - val_loss: 0.0030\n",
      "Epoch 2/50\n",
      "1240/1240 [==============================] - 6s 5ms/step - loss: 0.0085 - val_loss: 0.0032\n",
      "Epoch 3/50\n",
      "1240/1240 [==============================] - 6s 4ms/step - loss: 0.0084 - val_loss: 0.0030\n",
      "Epoch 4/50\n",
      "1240/1240 [==============================] - 6s 5ms/step - loss: 0.0083 - val_loss: 0.0030\n",
      "Epoch 5/50\n",
      "1240/1240 [==============================] - 6s 5ms/step - loss: 0.0083 - val_loss: 0.0030\n",
      "Epoch 6/50\n",
      "1240/1240 [==============================] - 6s 5ms/step - loss: 0.0081 - val_loss: 0.0029\n",
      "Epoch 7/50\n",
      "1240/1240 [==============================] - 6s 5ms/step - loss: 0.0078 - val_loss: 0.0060\n",
      "Epoch 8/50\n",
      "1240/1240 [==============================] - 6s 5ms/step - loss: 0.0079 - val_loss: 0.0029\n",
      "Epoch 9/50\n",
      "1240/1240 [==============================] - 6s 5ms/step - loss: 0.0077 - val_loss: 0.0042\n",
      "Epoch 10/50\n",
      "1240/1240 [==============================] - 6s 5ms/step - loss: 0.0078 - val_loss: 0.0028\n",
      "Epoch 11/50\n",
      "1240/1240 [==============================] - 6s 5ms/step - loss: 0.0078 - val_loss: 0.0029\n",
      "Epoch 12/50\n",
      "1240/1240 [==============================] - 6s 5ms/step - loss: 0.0077 - val_loss: 0.0029\n",
      "Epoch 13/50\n",
      "1240/1240 [==============================] - 6s 4ms/step - loss: 0.0077 - val_loss: 0.0028\n",
      "Epoch 14/50\n",
      "1240/1240 [==============================] - 6s 5ms/step - loss: 0.0077 - val_loss: 0.0034\n",
      "Epoch 15/50\n",
      "1240/1240 [==============================] - 6s 5ms/step - loss: 0.0076 - val_loss: 0.0032\n",
      "Epoch 16/50\n",
      "1240/1240 [==============================] - 6s 5ms/step - loss: 0.0076 - val_loss: 0.0028\n",
      "Epoch 17/50\n",
      "1240/1240 [==============================] - 6s 5ms/step - loss: 0.0076 - val_loss: 0.0028\n",
      "Epoch 18/50\n",
      "1240/1240 [==============================] - 6s 5ms/step - loss: 0.0075 - val_loss: 0.0033\n",
      "Epoch 19/50\n",
      "1240/1240 [==============================] - 6s 5ms/step - loss: 0.0074 - val_loss: 0.0028\n",
      "Epoch 20/50\n",
      "1240/1240 [==============================] - ETA: 0s - loss: 0.0074Restoring model weights from the end of the best epoch: 10.\n",
      "1240/1240 [==============================] - 6s 5ms/step - loss: 0.0074 - val_loss: 0.0034\n",
      "Epoch 20: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para RAYA Y SIMILARES en clúster 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 4ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para RAYA Y SIMILARES en clúster 7: 1672189.4828175085, R2 Mensual: 0.9699342499008603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_195974/3758942541.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: RAYA Y SIMILARES, cluster: 0\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 4s 24ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "25/32 [======================>.......] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "32/32 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para RAYA Y SIMILARES en clúster 0\n",
      "No se tienen datos suficientes para RAYA Y SIMILARES en clúster 0 en los últimos seis meses de 2023\n",
      "Training model for species: RAYA Y SIMILARES, cluster: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "917/917 [==============================] - 8s 5ms/step - loss: 0.0119 - val_loss: 0.0092\n",
      "Epoch 2/50\n",
      "917/917 [==============================] - 4s 5ms/step - loss: 0.0114 - val_loss: 0.0096\n",
      "Epoch 3/50\n",
      "917/917 [==============================] - 4s 5ms/step - loss: 0.0115 - val_loss: 0.0095\n",
      "Epoch 4/50\n",
      "917/917 [==============================] - 4s 5ms/step - loss: 0.0114 - val_loss: 0.0094\n",
      "Epoch 5/50\n",
      "917/917 [==============================] - 4s 4ms/step - loss: 0.0112 - val_loss: 0.0095\n",
      "Epoch 6/50\n",
      "917/917 [==============================] - 4s 5ms/step - loss: 0.0111 - val_loss: 0.0094\n",
      "Epoch 7/50\n",
      "917/917 [==============================] - 4s 5ms/step - loss: 0.0110 - val_loss: 0.0094\n",
      "Epoch 8/50\n",
      "917/917 [==============================] - 4s 5ms/step - loss: 0.0109 - val_loss: 0.0095\n",
      "Epoch 9/50\n",
      "917/917 [==============================] - 4s 5ms/step - loss: 0.0108 - val_loss: 0.0096\n",
      "Epoch 10/50\n",
      "917/917 [==============================] - 4s 5ms/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 11/50\n",
      "911/917 [============================>.] - ETA: 0s - loss: 0.0108Restoring model weights from the end of the best epoch: 1.\n",
      "917/917 [==============================] - 4s 5ms/step - loss: 0.0107 - val_loss: 0.0100\n",
      "Epoch 11: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para RAYA Y SIMILARES en clúster 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para RAYA Y SIMILARES en clúster 3: 153861551.91382137, R2 Mensual: 0.7464836010120831\n",
      "Training model for species: RAYA Y SIMILARES, cluster: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_195974/3758942541.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4276/4276 [==============================] - 24s 5ms/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 2/50\n",
      "4276/4276 [==============================] - 20s 5ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 3/50\n",
      "4276/4276 [==============================] - 20s 5ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 4/50\n",
      "4276/4276 [==============================] - 20s 5ms/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 5/50\n",
      "4276/4276 [==============================] - 20s 5ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 6/50\n",
      "4276/4276 [==============================] - 20s 5ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 7/50\n",
      "4276/4276 [==============================] - 20s 5ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 8/50\n",
      "4276/4276 [==============================] - 20s 5ms/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 9/50\n",
      "4276/4276 [==============================] - 20s 5ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 10/50\n",
      "4276/4276 [==============================] - 20s 5ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 11/50\n",
      "4276/4276 [==============================] - 20s 5ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 12/50\n",
      "4276/4276 [==============================] - 20s 5ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 13/50\n",
      "4276/4276 [==============================] - 20s 5ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 14/50\n",
      "4276/4276 [==============================] - 20s 5ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 15/50\n",
      "4276/4276 [==============================] - 20s 5ms/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 16/50\n",
      "4276/4276 [==============================] - 20s 5ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 17/50\n",
      "4276/4276 [==============================] - 20s 5ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 18/50\n",
      "4276/4276 [==============================] - 20s 5ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 19/50\n",
      "4276/4276 [==============================] - 20s 5ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 20/50\n",
      "4276/4276 [==============================] - 20s 5ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 21/50\n",
      "4270/4276 [============================>.] - ETA: 0s - loss: 0.0023Restoring model weights from the end of the best epoch: 11.\n",
      "4276/4276 [==============================] - 20s 5ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 21: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para RAYA Y SIMILARES en clúster 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 1s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para RAYA Y SIMILARES en clúster 6: 71823685.78049356, R2 Mensual: 0.9538209460516378\n",
      "Training model for species: RAYA Y SIMILARES, cluster: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_195974/3758942541.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "195/195 [==============================] - 5s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "195/195 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "195/195 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "195/195 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "195/195 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "195/195 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "195/195 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "195/195 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "195/195 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "186/195 [===========================>..] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "195/195 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para RAYA Y SIMILARES en clúster 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para RAYA Y SIMILARES en clúster 5: 395245898.25, R2 Mensual: -0.5071161633951569\n",
      "Training model for species: RAYA Y SIMILARES, cluster: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_195974/3758942541.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 4s 145ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "5/5 [==============================] - 0s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para RAYA Y SIMILARES en clúster 2\n",
      "No se tienen datos suficientes para RAYA Y SIMILARES en clúster 2 en los últimos seis meses de 2023\n",
      "Training model for species: RAYA Y SIMILARES, cluster: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3027/3027 [==============================] - 18s 5ms/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 2/50\n",
      "3027/3027 [==============================] - 14s 5ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 3/50\n",
      "3027/3027 [==============================] - 14s 5ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 4/50\n",
      "3027/3027 [==============================] - 14s 5ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 5/50\n",
      "3027/3027 [==============================] - 14s 5ms/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 6/50\n",
      "3027/3027 [==============================] - 14s 5ms/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 7/50\n",
      "3027/3027 [==============================] - 14s 5ms/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 8/50\n",
      "3027/3027 [==============================] - 14s 5ms/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 9/50\n",
      "3027/3027 [==============================] - 14s 5ms/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 10/50\n",
      "3027/3027 [==============================] - 14s 5ms/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 11/50\n",
      "3027/3027 [==============================] - 14s 5ms/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 12/50\n",
      "3027/3027 [==============================] - 14s 5ms/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 13/50\n",
      "3027/3027 [==============================] - 14s 5ms/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 14/50\n",
      "3027/3027 [==============================] - 14s 5ms/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 15/50\n",
      "3027/3027 [==============================] - 14s 5ms/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 16/50\n",
      "3027/3027 [==============================] - 14s 5ms/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 17/50\n",
      "3027/3027 [==============================] - 14s 5ms/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 18/50\n",
      "3027/3027 [==============================] - 14s 5ms/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 19/50\n",
      "3027/3027 [==============================] - 14s 5ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 20/50\n",
      "3027/3027 [==============================] - 14s 5ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 21/50\n",
      "3027/3027 [==============================] - 14s 5ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 22/50\n",
      "3027/3027 [==============================] - 14s 5ms/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 23/50\n",
      "3027/3027 [==============================] - 14s 5ms/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 24/50\n",
      "3027/3027 [==============================] - 14s 5ms/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 25/50\n",
      "3027/3027 [==============================] - 14s 5ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 26/50\n",
      "3016/3027 [============================>.] - ETA: 0s - loss: 0.0033Restoring model weights from the end of the best epoch: 16.\n",
      "3027/3027 [==============================] - 14s 5ms/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 26: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para RAYA Y SIMILARES en clúster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para RAYA Y SIMILARES en clúster 1: 59472799.732075155, R2 Mensual: 0.9732715934915336\n",
      "Training model for species: RAYA Y SIMILARES, cluster: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_195974/3758942541.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "20/20 [==============================] - 4s 37ms/step - loss: 0.0141 - val_loss: 0.1832\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.1892\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0075 - val_loss: 0.1838\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.1837\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.1842\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0084 - val_loss: 0.1763\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.1859\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0083 - val_loss: 0.1859\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0084 - val_loss: 0.1858\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0075 - val_loss: 0.1810\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0079 - val_loss: 0.1861\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.1795\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.1848\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0074 - val_loss: 0.1803\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.1835\n",
      "Epoch 16/50\n",
      "13/20 [==================>...........] - ETA: 0s - loss: 0.0095    Restoring model weights from the end of the best epoch: 6.\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0084 - val_loss: 0.1784\n",
      "Epoch 16: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para RAYA Y SIMILARES en clúster 4\n",
      "No se tienen datos suficientes para RAYA Y SIMILARES en clúster 4 en los últimos seis meses de 2023\n",
      "Training model for species: ABULON, cluster: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11/11 [==============================] - 4s 65ms/step - loss: 0.0278 - val_loss: 0.0467\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0289\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0237\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.0220\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0236\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 0.0203\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 0.0211\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0199\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0180\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0199\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 9.7670e-04 - val_loss: 0.0195\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.9151e-04 - val_loss: 0.0195\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 9.9049e-04 - val_loss: 0.0195\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.1994e-04 - val_loss: 0.0203\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.6231e-04 - val_loss: 0.0202\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.5970e-04 - val_loss: 0.0204\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.5996e-04 - val_loss: 0.0205\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.7573e-04 - val_loss: 0.0185\n",
      "Epoch 19/50\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 9.9876e-04Restoring model weights from the end of the best epoch: 9.\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 4.7636e-04 - val_loss: 0.0199\n",
      "Epoch 19: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para ABULON en clúster 3\n",
      "No se tienen datos suficientes para ABULON en clúster 3 en los últimos seis meses de 2023\n",
      "Training model for species: ABULON, cluster: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 4s 209ms/step - loss: 0.0675 - val_loss: 0.1782\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0386 - val_loss: 0.1537\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0234 - val_loss: 0.1281\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0146 - val_loss: 0.1056\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0101 - val_loss: 0.0882\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0739\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0693\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0086 - val_loss: 0.0666\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0060 - val_loss: 0.0656\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0041 - val_loss: 0.0644\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0046 - val_loss: 0.0606\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0017 - val_loss: 0.0534\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0470\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.0670e-04 - val_loss: 0.0404\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.4566e-04 - val_loss: 0.0347\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.1084e-04 - val_loss: 0.0308\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.4438e-05 - val_loss: 0.0282\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.9758e-05 - val_loss: 0.0266\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.3971e-04 - val_loss: 0.0260\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.4645e-05 - val_loss: 0.0258\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.2111e-05 - val_loss: 0.0261\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.9102e-05 - val_loss: 0.0262\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.4679e-05 - val_loss: 0.0263\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.7646e-05 - val_loss: 0.0269\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 4.4733e-05 - val_loss: 0.0279\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.0382e-05 - val_loss: 0.0287\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2.6177e-05 - val_loss: 0.0290\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.6550e-05 - val_loss: 0.0287\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 4.7305e-05 - val_loss: 0.0280\n",
      "Epoch 30/50\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 2.8143e-05Restoring model weights from the end of the best epoch: 20.\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.6082e-05 - val_loss: 0.0278\n",
      "Epoch 30: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para ABULON en clúster 1\n",
      "No se tienen datos suficientes para ABULON en clúster 1 en los últimos seis meses de 2023\n",
      "Training model for species: PULPO, cluster: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "35/35 [==============================] - 4s 22ms/step - loss: 0.0370 - val_loss: 0.0562\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0294 - val_loss: 0.0228\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0251 - val_loss: 0.0189\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0276 - val_loss: 0.0425\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0246 - val_loss: 0.0176\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0313 - val_loss: 0.0346\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0253 - val_loss: 0.0175\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0239 - val_loss: 0.0303\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0253 - val_loss: 0.0193\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0256 - val_loss: 0.0240\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0274 - val_loss: 0.0171\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0226 - val_loss: 0.0359\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0273 - val_loss: 0.0246\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0248 - val_loss: 0.0176\n",
      "Epoch 15/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0239 - val_loss: 0.0303\n",
      "Epoch 16/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0244 - val_loss: 0.0171\n",
      "Epoch 17/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0280 - val_loss: 0.0414\n",
      "Epoch 18/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0280 - val_loss: 0.0212\n",
      "Epoch 19/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0255 - val_loss: 0.0185\n",
      "Epoch 20/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0252 - val_loss: 0.0181\n",
      "Epoch 21/50\n",
      "25/35 [====================>.........] - ETA: 0s - loss: 0.0314Restoring model weights from the end of the best epoch: 11.\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0250 - val_loss: 0.0194\n",
      "Epoch 21: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para PULPO en clúster 7\n",
      "No se tienen datos suficientes para PULPO en clúster 7 en los últimos seis meses de 2023\n",
      "Training model for species: PULPO, cluster: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "103/103 [==============================] - 4s 11ms/step - loss: 0.0584 - val_loss: 0.0715\n",
      "Epoch 2/50\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0540 - val_loss: 0.0915\n",
      "Epoch 3/50\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0544 - val_loss: 0.0925\n",
      "Epoch 4/50\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0567 - val_loss: 0.0798\n",
      "Epoch 5/50\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0533 - val_loss: 0.0778\n",
      "Epoch 6/50\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0526 - val_loss: 0.0756\n",
      "Epoch 7/50\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0554 - val_loss: 0.0794\n",
      "Epoch 8/50\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0532 - val_loss: 0.0760\n",
      "Epoch 9/50\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0544 - val_loss: 0.0837\n",
      "Epoch 10/50\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0507 - val_loss: 0.1029\n",
      "Epoch 11/50\n",
      " 99/103 [===========================>..] - ETA: 0s - loss: 0.0528Restoring model weights from the end of the best epoch: 1.\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0513 - val_loss: 0.0886\n",
      "Epoch 11: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para PULPO en clúster 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 564ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "MSE Mensual para PULPO en clúster 3: 309403.6171278284, R2 Mensual: 0.5613177754265922\n",
      "Training model for species: PULPO, cluster: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_195974/3758942541.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2775/2775 [==============================] - 20s 6ms/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 2/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 3/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 4/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 5/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 6/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 7/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 8/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 9/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 10/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 11/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 12/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 13/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 14/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 15/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 16/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 17/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 18/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 19/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 20/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 21/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 22/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 23/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 24/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 25/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 26/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 27/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 28/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 29/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 30/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 31/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 32/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 33/50\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 34/50\n",
      "2772/2775 [============================>.] - ETA: 0s - loss: 0.0049Restoring model weights from the end of the best epoch: 24.\n",
      "2775/2775 [==============================] - 13s 5ms/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 34: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para PULPO en clúster 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para PULPO en clúster 6: 25427541.082522526, R2 Mensual: 0.9003383971550762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_195974/3758942541.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: PULPO, cluster: 2\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 4s 89ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "1/8 [==>...........................] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "8/8 [==============================] - 0s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para PULPO en clúster 2\n",
      "No se tienen datos suficientes para PULPO en clúster 2 en los últimos seis meses de 2023\n",
      "Training model for species: PULPO, cluster: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1317/1317 [==============================] - 10s 5ms/step - loss: 0.0073 - val_loss: 0.0022\n",
      "Epoch 2/50\n",
      "1317/1317 [==============================] - 6s 5ms/step - loss: 0.0067 - val_loss: 0.0022\n",
      "Epoch 3/50\n",
      "1317/1317 [==============================] - 6s 5ms/step - loss: 0.0067 - val_loss: 0.0024\n",
      "Epoch 4/50\n",
      "1317/1317 [==============================] - 6s 5ms/step - loss: 0.0066 - val_loss: 0.0022\n",
      "Epoch 5/50\n",
      "1317/1317 [==============================] - 6s 5ms/step - loss: 0.0066 - val_loss: 0.0016\n",
      "Epoch 6/50\n",
      "1317/1317 [==============================] - 6s 5ms/step - loss: 0.0064 - val_loss: 0.0015\n",
      "Epoch 7/50\n",
      "1317/1317 [==============================] - 6s 5ms/step - loss: 0.0063 - val_loss: 0.0022\n",
      "Epoch 8/50\n",
      "1317/1317 [==============================] - 6s 5ms/step - loss: 0.0061 - val_loss: 0.0020\n",
      "Epoch 9/50\n",
      "1317/1317 [==============================] - 6s 5ms/step - loss: 0.0063 - val_loss: 0.0016\n",
      "Epoch 10/50\n",
      "1317/1317 [==============================] - 6s 5ms/step - loss: 0.0063 - val_loss: 0.0018\n",
      "Epoch 11/50\n",
      "1317/1317 [==============================] - 6s 5ms/step - loss: 0.0061 - val_loss: 0.0016\n",
      "Epoch 12/50\n",
      "1317/1317 [==============================] - 6s 5ms/step - loss: 0.0061 - val_loss: 0.0018\n",
      "Epoch 13/50\n",
      "1317/1317 [==============================] - 6s 5ms/step - loss: 0.0061 - val_loss: 0.0016\n",
      "Epoch 14/50\n",
      "1317/1317 [==============================] - 6s 5ms/step - loss: 0.0061 - val_loss: 0.0017\n",
      "Epoch 15/50\n",
      "1317/1317 [==============================] - 6s 5ms/step - loss: 0.0061 - val_loss: 0.0020\n",
      "Epoch 16/50\n",
      "1315/1317 [============================>.] - ETA: 0s - loss: 0.0060Restoring model weights from the end of the best epoch: 6.\n",
      "1317/1317 [==============================] - 6s 5ms/step - loss: 0.0060 - val_loss: 0.0018\n",
      "Epoch 16: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para PULPO en clúster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para PULPO en clúster 1: 16605304.883338818, R2 Mensual: 0.35452614658756343\n",
      "Training model for species: PULPO, cluster: 4\n",
      "Error entrenando el modelo para especie: PULPO, clúster: 4. Error: tuple index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_195974/3758942541.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: ALGAS, cluster: 3\n",
      "Epoch 1/50\n",
      "25/25 [==============================] - 4s 29ms/step - loss: 0.2181 - val_loss: 0.0412\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0653 - val_loss: 0.0307\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0618 - val_loss: 0.0356\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0524 - val_loss: 0.0456\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0546 - val_loss: 0.0398\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0595 - val_loss: 0.0510\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0444 - val_loss: 0.0537\n",
      "Epoch 8/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0416 - val_loss: 0.0511\n",
      "Epoch 9/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0411 - val_loss: 0.0495\n",
      "Epoch 10/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0366 - val_loss: 0.0664\n",
      "Epoch 11/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0471 - val_loss: 0.0507\n",
      "Epoch 12/50\n",
      "14/25 [===============>..............] - ETA: 0s - loss: 0.0582    Restoring model weights from the end of the best epoch: 2.\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0497 - val_loss: 0.0454\n",
      "Epoch 12: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para ALGAS en clúster 3\n",
      "No se tienen datos suficientes para ALGAS en clúster 3 en los últimos seis meses de 2023\n",
      "Training model for species: ALGAS, cluster: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error entrenando el modelo para especie: ALGAS, clúster: 5. Error: Training data contains 1 samples, which is not sufficient to split it into a validation and training set as specified by `validation_split=0.2`. Either provide more data, or a different value for the `validation_split` argument.\n",
      "Training model for species: ALGAS, cluster: 1\n",
      "Epoch 1/50\n",
      "26/26 [==============================] - 4s 28ms/step - loss: 0.1256 - val_loss: 0.0677\n",
      "Epoch 2/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0959 - val_loss: 0.0690\n",
      "Epoch 3/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0868 - val_loss: 0.0649\n",
      "Epoch 4/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0799 - val_loss: 0.0738\n",
      "Epoch 5/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0693 - val_loss: 0.0692\n",
      "Epoch 6/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0660 - val_loss: 0.0745\n",
      "Epoch 7/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0608 - val_loss: 0.0760\n",
      "Epoch 8/50\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0594 - val_loss: 0.0748\n",
      "Epoch 9/50\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0532 - val_loss: 0.0792\n",
      "Epoch 10/50\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0504 - val_loss: 0.0832\n",
      "Epoch 11/50\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0444 - val_loss: 0.0809\n",
      "Epoch 12/50\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0451 - val_loss: 0.0875\n",
      "Epoch 13/50\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0449Restoring model weights from the end of the best epoch: 3.\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0449 - val_loss: 0.0753\n",
      "Epoch 13: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para ALGAS en clúster 1\n",
      "Error entrenando el modelo para especie: ALGAS, clúster: 1. Error: tuple index out of range\n",
      "Training model for species: CAMARON, cluster: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4000/4000 [==============================] - 22s 5ms/step - loss: 9.1375e-04 - val_loss: 7.4009e-04\n",
      "Epoch 2/50\n",
      "4000/4000 [==============================] - 18s 5ms/step - loss: 8.7992e-04 - val_loss: 7.3772e-04\n",
      "Epoch 3/50\n",
      "4000/4000 [==============================] - 18s 5ms/step - loss: 8.7147e-04 - val_loss: 6.9762e-04\n",
      "Epoch 4/50\n",
      "4000/4000 [==============================] - 19s 5ms/step - loss: 8.6858e-04 - val_loss: 6.9295e-04\n",
      "Epoch 5/50\n",
      "4000/4000 [==============================] - 18s 5ms/step - loss: 8.6466e-04 - val_loss: 7.2662e-04\n",
      "Epoch 6/50\n",
      "4000/4000 [==============================] - 19s 5ms/step - loss: 8.4381e-04 - val_loss: 6.9333e-04\n",
      "Epoch 7/50\n",
      "4000/4000 [==============================] - 19s 5ms/step - loss: 8.3218e-04 - val_loss: 6.5391e-04\n",
      "Epoch 8/50\n",
      "4000/4000 [==============================] - 19s 5ms/step - loss: 8.2803e-04 - val_loss: 6.8494e-04\n",
      "Epoch 9/50\n",
      "4000/4000 [==============================] - 18s 5ms/step - loss: 7.7241e-04 - val_loss: 7.7293e-04\n",
      "Epoch 10/50\n",
      "4000/4000 [==============================] - 19s 5ms/step - loss: 7.5301e-04 - val_loss: 6.5878e-04\n",
      "Epoch 11/50\n",
      "4000/4000 [==============================] - 19s 5ms/step - loss: 7.6288e-04 - val_loss: 6.3304e-04\n",
      "Epoch 12/50\n",
      "4000/4000 [==============================] - 19s 5ms/step - loss: 7.0617e-04 - val_loss: 7.2996e-04\n",
      "Epoch 13/50\n",
      "4000/4000 [==============================] - 19s 5ms/step - loss: 7.3914e-04 - val_loss: 6.6014e-04\n",
      "Epoch 14/50\n",
      "4000/4000 [==============================] - 19s 5ms/step - loss: 7.1139e-04 - val_loss: 6.8735e-04\n",
      "Epoch 15/50\n",
      "4000/4000 [==============================] - 18s 5ms/step - loss: 6.9750e-04 - val_loss: 6.7931e-04\n",
      "Epoch 16/50\n",
      "4000/4000 [==============================] - 19s 5ms/step - loss: 6.9360e-04 - val_loss: 6.4564e-04\n",
      "Epoch 17/50\n",
      "4000/4000 [==============================] - 19s 5ms/step - loss: 7.1341e-04 - val_loss: 7.0376e-04\n",
      "Epoch 18/50\n",
      "4000/4000 [==============================] - 18s 5ms/step - loss: 6.5825e-04 - val_loss: 6.3108e-04\n",
      "Epoch 19/50\n",
      "4000/4000 [==============================] - 18s 5ms/step - loss: 6.6090e-04 - val_loss: 6.8896e-04\n",
      "Epoch 20/50\n",
      "4000/4000 [==============================] - 18s 5ms/step - loss: 6.6685e-04 - val_loss: 7.5043e-04\n",
      "Epoch 21/50\n",
      "4000/4000 [==============================] - 19s 5ms/step - loss: 6.5333e-04 - val_loss: 8.1035e-04\n",
      "Epoch 22/50\n",
      "4000/4000 [==============================] - 18s 5ms/step - loss: 5.9736e-04 - val_loss: 7.5954e-04\n",
      "Epoch 23/50\n",
      "4000/4000 [==============================] - 19s 5ms/step - loss: 5.9687e-04 - val_loss: 7.1018e-04\n",
      "Epoch 24/50\n",
      "4000/4000 [==============================] - 19s 5ms/step - loss: 4.7407e-04 - val_loss: 6.8542e-04\n",
      "Epoch 25/50\n",
      "4000/4000 [==============================] - 19s 5ms/step - loss: 5.6131e-04 - val_loss: 6.8469e-04\n",
      "Epoch 26/50\n",
      "4000/4000 [==============================] - 19s 5ms/step - loss: 6.3609e-04 - val_loss: 6.9954e-04\n",
      "Epoch 27/50\n",
      "4000/4000 [==============================] - 19s 5ms/step - loss: 6.3821e-04 - val_loss: 7.2356e-04\n",
      "Epoch 28/50\n",
      "3992/4000 [============================>.] - ETA: 0s - loss: 6.7761e-04Restoring model weights from the end of the best epoch: 18.\n",
      "4000/4000 [==============================] - 19s 5ms/step - loss: 6.7637e-04 - val_loss: 6.8518e-04\n",
      "Epoch 28: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CAMARON en clúster 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para CAMARON en clúster 7: 1881738408.1811314, R2 Mensual: 0.9562948981784974\n",
      "Training model for species: CAMARON, cluster: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_195974/3758942541.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "590/590 [==============================] - 6s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "590/590 [==============================] - 3s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "590/590 [==============================] - 3s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "590/590 [==============================] - 3s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "590/590 [==============================] - 3s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "590/590 [==============================] - 3s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "590/590 [==============================] - 3s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "590/590 [==============================] - 3s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "590/590 [==============================] - 3s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "589/590 [============================>.] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "590/590 [==============================] - 3s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CAMARON en clúster 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 570ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "MSE Mensual para CAMARON en clúster 0: 739088442.5, R2 Mensual: -0.9340625239018021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_195974/3758942541.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: CAMARON, cluster: 3\n",
      "Epoch 1/50\n",
      "7899/7899 [==============================] - 40s 5ms/step - loss: 0.0011 - val_loss: 6.5034e-04\n",
      "Epoch 2/50\n",
      "7899/7899 [==============================] - 36s 5ms/step - loss: 0.0010 - val_loss: 6.2451e-04\n",
      "Epoch 3/50\n",
      "7899/7899 [==============================] - 36s 5ms/step - loss: 9.4719e-04 - val_loss: 5.8503e-04\n",
      "Epoch 4/50\n",
      "7899/7899 [==============================] - 36s 5ms/step - loss: 9.0227e-04 - val_loss: 5.5500e-04\n",
      "Epoch 5/50\n",
      "7899/7899 [==============================] - 36s 5ms/step - loss: 8.9546e-04 - val_loss: 5.8934e-04\n",
      "Epoch 6/50\n",
      "7899/7899 [==============================] - 36s 5ms/step - loss: 8.7044e-04 - val_loss: 9.1546e-04\n",
      "Epoch 7/50\n",
      "7899/7899 [==============================] - 36s 5ms/step - loss: 8.7305e-04 - val_loss: 5.9335e-04\n",
      "Epoch 8/50\n",
      "7899/7899 [==============================] - 36s 5ms/step - loss: 8.6658e-04 - val_loss: 5.3777e-04\n",
      "Epoch 9/50\n",
      "7899/7899 [==============================] - 36s 5ms/step - loss: 8.6348e-04 - val_loss: 5.8390e-04\n",
      "Epoch 10/50\n",
      "7899/7899 [==============================] - 37s 5ms/step - loss: 8.6733e-04 - val_loss: 6.5619e-04\n",
      "Epoch 11/50\n",
      "7899/7899 [==============================] - 36s 5ms/step - loss: 8.6742e-04 - val_loss: 6.2879e-04\n",
      "Epoch 12/50\n",
      "7899/7899 [==============================] - 36s 5ms/step - loss: 8.5609e-04 - val_loss: 5.4324e-04\n",
      "Epoch 13/50\n",
      "7899/7899 [==============================] - 36s 5ms/step - loss: 8.5305e-04 - val_loss: 5.8081e-04\n",
      "Epoch 14/50\n",
      "7899/7899 [==============================] - 37s 5ms/step - loss: 8.5139e-04 - val_loss: 5.7605e-04\n",
      "Epoch 15/50\n",
      "7899/7899 [==============================] - 36s 5ms/step - loss: 8.5202e-04 - val_loss: 5.4472e-04\n",
      "Epoch 16/50\n",
      "7899/7899 [==============================] - 34s 4ms/step - loss: 8.4781e-04 - val_loss: 5.6026e-04\n",
      "Epoch 17/50\n",
      "7899/7899 [==============================] - 36s 5ms/step - loss: 8.4126e-04 - val_loss: 6.5522e-04\n",
      "Epoch 18/50\n",
      "7897/7899 [============================>.] - ETA: 0s - loss: 8.3957e-04Restoring model weights from the end of the best epoch: 8.\n",
      "7899/7899 [==============================] - 36s 5ms/step - loss: 8.4033e-04 - val_loss: 5.6386e-04\n",
      "Epoch 18: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CAMARON en clúster 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 1s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para CAMARON en clúster 3: 6531588447.272475, R2 Mensual: 0.9523417286053144\n",
      "Training model for species: CAMARON, cluster: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_195974/3758942541.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6096/6096 [==============================] - 31s 5ms/step - loss: 0.0077 - val_loss: 0.0045\n",
      "Epoch 2/50\n",
      "6096/6096 [==============================] - 28s 5ms/step - loss: 0.0070 - val_loss: 0.0040\n",
      "Epoch 3/50\n",
      "6096/6096 [==============================] - 27s 4ms/step - loss: 0.0068 - val_loss: 0.0040\n",
      "Epoch 4/50\n",
      "6096/6096 [==============================] - 28s 5ms/step - loss: 0.0066 - val_loss: 0.0048\n",
      "Epoch 5/50\n",
      "6096/6096 [==============================] - 28s 5ms/step - loss: 0.0066 - val_loss: 0.0042\n",
      "Epoch 6/50\n",
      "6096/6096 [==============================] - 28s 5ms/step - loss: 0.0065 - val_loss: 0.0043\n",
      "Epoch 7/50\n",
      "6096/6096 [==============================] - 27s 4ms/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 8/50\n",
      "6096/6096 [==============================] - 27s 4ms/step - loss: 0.0065 - val_loss: 0.0040\n",
      "Epoch 9/50\n",
      "6096/6096 [==============================] - 28s 5ms/step - loss: 0.0065 - val_loss: 0.0040\n",
      "Epoch 10/50\n",
      "6096/6096 [==============================] - 27s 4ms/step - loss: 0.0064 - val_loss: 0.0040\n",
      "Epoch 11/50\n",
      "6096/6096 [==============================] - 27s 4ms/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 12/50\n",
      "6096/6096 [==============================] - 28s 5ms/step - loss: 0.0064 - val_loss: 0.0038\n",
      "Epoch 13/50\n",
      "6096/6096 [==============================] - 28s 5ms/step - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 14/50\n",
      "6096/6096 [==============================] - 28s 5ms/step - loss: 0.0063 - val_loss: 0.0039\n",
      "Epoch 15/50\n",
      "6096/6096 [==============================] - 28s 5ms/step - loss: 0.0064 - val_loss: 0.0040\n",
      "Epoch 16/50\n",
      "6096/6096 [==============================] - 28s 5ms/step - loss: 0.0063 - val_loss: 0.0040\n",
      "Epoch 17/50\n",
      "6096/6096 [==============================] - 28s 5ms/step - loss: 0.0063 - val_loss: 0.0040\n",
      "Epoch 18/50\n",
      "6096/6096 [==============================] - 28s 5ms/step - loss: 0.0062 - val_loss: 0.0041\n",
      "Epoch 19/50\n",
      "6096/6096 [==============================] - 28s 5ms/step - loss: 0.0063 - val_loss: 0.0042\n",
      "Epoch 20/50\n",
      "6096/6096 [==============================] - 28s 5ms/step - loss: 0.0063 - val_loss: 0.0040\n",
      "Epoch 21/50\n",
      "6096/6096 [==============================] - 28s 5ms/step - loss: 0.0063 - val_loss: 0.0039\n",
      "Epoch 22/50\n",
      "6088/6096 [============================>.] - ETA: 0s - loss: 0.0062Restoring model weights from the end of the best epoch: 12.\n",
      "6096/6096 [==============================] - 28s 5ms/step - loss: 0.0062 - val_loss: 0.0041\n",
      "Epoch 22: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CAMARON en clúster 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 1s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para CAMARON en clúster 6: 397506942.2639497, R2 Mensual: 0.98741302059468\n",
      "Training model for species: CAMARON, cluster: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_195974/3758942541.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1056/1056 [==============================] - 9s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "1056/1056 [==============================] - 5s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "1056/1056 [==============================] - 5s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "1056/1056 [==============================] - 5s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "1056/1056 [==============================] - 5s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "1056/1056 [==============================] - 5s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "1056/1056 [==============================] - 5s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "1056/1056 [==============================] - 5s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "1056/1056 [==============================] - 5s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "1053/1056 [============================>.] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "1056/1056 [==============================] - 5s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CAMARON en clúster 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para CAMARON en clúster 5: 3747738781.8333335, R2 Mensual: -0.588190400323634\n",
      "Training model for species: CAMARON, cluster: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_195974/3758942541.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 4s 67ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CAMARON en clúster 2\n",
      "No se tienen datos suficientes para CAMARON en clúster 2 en los últimos seis meses de 2023\n",
      "Training model for species: CAMARON, cluster: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "22492/22492 [==============================] - 106s 5ms/step - loss: 1.9681e-04 - val_loss: 1.3914e-04\n",
      "Epoch 2/50\n",
      "22492/22492 [==============================] - 102s 5ms/step - loss: 1.9251e-04 - val_loss: 1.3030e-04\n",
      "Epoch 3/50\n",
      "22492/22492 [==============================] - 103s 5ms/step - loss: 1.8556e-04 - val_loss: 1.3160e-04\n",
      "Epoch 4/50\n",
      "22492/22492 [==============================] - 103s 5ms/step - loss: 1.8173e-04 - val_loss: 1.3303e-04\n",
      "Epoch 5/50\n",
      "22492/22492 [==============================] - 101s 4ms/step - loss: 1.8110e-04 - val_loss: 1.0702e-04\n",
      "Epoch 6/50\n",
      "22492/22492 [==============================] - 103s 5ms/step - loss: 1.7916e-04 - val_loss: 1.3198e-04\n",
      "Epoch 7/50\n",
      "22492/22492 [==============================] - 103s 5ms/step - loss: 1.7932e-04 - val_loss: 1.1914e-04\n",
      "Epoch 8/50\n",
      "22492/22492 [==============================] - 99s 4ms/step - loss: 1.7799e-04 - val_loss: 1.1467e-04\n",
      "Epoch 9/50\n",
      "22492/22492 [==============================] - 96s 4ms/step - loss: 1.7343e-04 - val_loss: 1.1126e-04\n",
      "Epoch 10/50\n",
      "22492/22492 [==============================] - 96s 4ms/step - loss: 1.7697e-04 - val_loss: 1.0625e-04\n",
      "Epoch 11/50\n",
      "22492/22492 [==============================] - 96s 4ms/step - loss: 1.7266e-04 - val_loss: 1.2048e-04\n",
      "Epoch 12/50\n",
      "22492/22492 [==============================] - 96s 4ms/step - loss: 1.7601e-04 - val_loss: 1.1046e-04\n",
      "Epoch 13/50\n",
      "22492/22492 [==============================] - 96s 4ms/step - loss: 1.7353e-04 - val_loss: 1.1711e-04\n",
      "Epoch 14/50\n",
      "22492/22492 [==============================] - 96s 4ms/step - loss: 1.7036e-04 - val_loss: 1.0817e-04\n",
      "Epoch 15/50\n",
      "22492/22492 [==============================] - 96s 4ms/step - loss: 1.7267e-04 - val_loss: 1.1411e-04\n",
      "Epoch 16/50\n",
      "22492/22492 [==============================] - 96s 4ms/step - loss: 1.7171e-04 - val_loss: 1.1125e-04\n",
      "Epoch 17/50\n",
      "22492/22492 [==============================] - 96s 4ms/step - loss: 1.7082e-04 - val_loss: 1.1484e-04\n",
      "Epoch 18/50\n",
      "22492/22492 [==============================] - 97s 4ms/step - loss: 1.6938e-04 - val_loss: 1.1530e-04\n",
      "Epoch 19/50\n",
      "22492/22492 [==============================] - 96s 4ms/step - loss: 1.7022e-04 - val_loss: 1.0887e-04\n",
      "Epoch 20/50\n",
      "22490/22492 [============================>.] - ETA: 0s - loss: 1.6991e-04Restoring model weights from the end of the best epoch: 10.\n",
      "22492/22492 [==============================] - 96s 4ms/step - loss: 1.6990e-04 - val_loss: 1.0676e-04\n",
      "Epoch 20: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CAMARON en clúster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1s 3ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n",
      "MSE Mensual para CAMARON en clúster 1: 15986246515.307558, R2 Mensual: 0.9466237802660827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_195974/3758942541.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: CAMARON, cluster: 4\n",
      "Epoch 1/50\n",
      "620/620 [==============================] - 6s 5ms/step - loss: 0.0184 - val_loss: nan\n",
      "Epoch 2/50\n",
      "620/620 [==============================] - 3s 4ms/step - loss: 0.0130 - val_loss: nan\n",
      "Epoch 3/50\n",
      "620/620 [==============================] - 3s 4ms/step - loss: 0.0127 - val_loss: nan\n",
      "Epoch 4/50\n",
      "620/620 [==============================] - 3s 4ms/step - loss: 0.0127 - val_loss: nan\n",
      "Epoch 5/50\n",
      "620/620 [==============================] - 3s 4ms/step - loss: 0.0128 - val_loss: nan\n",
      "Epoch 6/50\n",
      "620/620 [==============================] - 3s 4ms/step - loss: 0.0126 - val_loss: nan\n",
      "Epoch 7/50\n",
      "620/620 [==============================] - 3s 4ms/step - loss: 0.0126 - val_loss: nan\n",
      "Epoch 8/50\n",
      "620/620 [==============================] - 3s 4ms/step - loss: 0.0128 - val_loss: nan\n",
      "Epoch 9/50\n",
      "620/620 [==============================] - 3s 4ms/step - loss: 0.0125 - val_loss: nan\n",
      "Epoch 10/50\n",
      "609/620 [============================>.] - ETA: 0s - loss: 0.0125Restoring model weights from the end of the best epoch: 1.\n",
      "620/620 [==============================] - 3s 4ms/step - loss: 0.0124 - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CAMARON en clúster 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para CAMARON en clúster 4: 86687438.18949674, R2 Mensual: 0.48659350809913526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_195974/3758942541.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: CHARAL, cluster: 7\n",
      "Epoch 1/50\n",
      "204/204 [==============================] - 8s 8ms/step - loss: 0.0304 - val_loss: 0.0129\n",
      "Epoch 2/50\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.0270 - val_loss: 0.0140\n",
      "Epoch 3/50\n",
      "204/204 [==============================] - 1s 5ms/step - loss: 0.0263 - val_loss: 0.0138\n",
      "Epoch 4/50\n",
      "204/204 [==============================] - 1s 5ms/step - loss: 0.0258 - val_loss: 0.0135\n",
      "Epoch 5/50\n",
      "204/204 [==============================] - 1s 5ms/step - loss: 0.0254 - val_loss: 0.0168\n",
      "Epoch 6/50\n",
      "204/204 [==============================] - 1s 5ms/step - loss: 0.0240 - val_loss: 0.0134\n",
      "Epoch 7/50\n",
      "204/204 [==============================] - 1s 5ms/step - loss: 0.0237 - val_loss: 0.0128\n",
      "Epoch 8/50\n",
      "204/204 [==============================] - 1s 5ms/step - loss: 0.0244 - val_loss: 0.0129\n",
      "Epoch 9/50\n",
      "204/204 [==============================] - 1s 5ms/step - loss: 0.0233 - val_loss: 0.0179\n",
      "Epoch 10/50\n",
      "204/204 [==============================] - 1s 5ms/step - loss: 0.0244 - val_loss: 0.0128\n",
      "Epoch 11/50\n",
      "204/204 [==============================] - 1s 5ms/step - loss: 0.0231 - val_loss: 0.0146\n",
      "Epoch 12/50\n",
      "204/204 [==============================] - 1s 5ms/step - loss: 0.0229 - val_loss: 0.0160\n",
      "Epoch 13/50\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.0226 - val_loss: 0.0129\n",
      "Epoch 14/50\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.0226 - val_loss: 0.0156\n",
      "Epoch 15/50\n",
      "204/204 [==============================] - 1s 5ms/step - loss: 0.0226 - val_loss: 0.0147\n",
      "Epoch 16/50\n",
      "204/204 [==============================] - 1s 5ms/step - loss: 0.0214 - val_loss: 0.0134\n",
      "Epoch 17/50\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.0217 - val_loss: 0.0156\n",
      "Epoch 18/50\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.0215 - val_loss: 0.0153\n",
      "Epoch 19/50\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.0218 - val_loss: 0.0142\n",
      "Epoch 20/50\n",
      "201/204 [============================>.] - ETA: 0s - loss: 0.0203Restoring model weights from the end of the best epoch: 10.\n",
      "204/204 [==============================] - 1s 5ms/step - loss: 0.0204 - val_loss: 0.0162\n",
      "Epoch 20: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CHARAL en clúster 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 570ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "MSE Mensual para CHARAL en clúster 7: 4080305.8063128125, R2 Mensual: 0.5327392399895228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_195974/3758942541.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: CHARAL, cluster: 3\n",
      "Epoch 1/50\n",
      "60/60 [==============================] - 4s 15ms/step - loss: 0.0376 - val_loss: 0.0439\n",
      "Epoch 2/50\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.0264 - val_loss: 0.0380\n",
      "Epoch 3/50\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.0259 - val_loss: 0.0328\n",
      "Epoch 4/50\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.0237 - val_loss: 0.0368\n",
      "Epoch 5/50\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.0254 - val_loss: 0.0306\n",
      "Epoch 6/50\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.0230 - val_loss: 0.0319\n",
      "Epoch 7/50\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.0221 - val_loss: 0.0292\n",
      "Epoch 8/50\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.0195 - val_loss: 0.0299\n",
      "Epoch 9/50\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.0182 - val_loss: 0.0326\n",
      "Epoch 10/50\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.0167 - val_loss: 0.0302\n",
      "Epoch 11/50\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.0155 - val_loss: 0.0358\n",
      "Epoch 12/50\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.0151 - val_loss: 0.0338\n",
      "Epoch 13/50\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0293\n",
      "Epoch 14/50\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0316\n",
      "Epoch 15/50\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0327\n",
      "Epoch 16/50\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0318\n",
      "Epoch 17/50\n",
      "52/60 [=========================>....] - ETA: 0s - loss: 0.0123Restoring model weights from the end of the best epoch: 7.\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0326\n",
      "Epoch 17: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CHARAL en clúster 3\n",
      "No se tienen datos suficientes para CHARAL en clúster 3 en los últimos seis meses de 2023\n",
      "Training model for species: CHARAL, cluster: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 4s 562ms/step - loss: 0.0110 - val_loss: 0.0285\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0035 - val_loss: 0.0282\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0016 - val_loss: 0.0247\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 4.0890e-04 - val_loss: 0.0239\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 4.4922e-04 - val_loss: 0.0262\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 3.3435e-04 - val_loss: 0.0283\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 3.3538e-04 - val_loss: 0.0272\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 3.8417e-04 - val_loss: 0.0246\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 6.1945e-05 - val_loss: 0.0230\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 6.9957e-05 - val_loss: 0.0221\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 3.8637e-05 - val_loss: 0.0219\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 4.8932e-06 - val_loss: 0.0222\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0268e-04 - val_loss: 0.0218\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 7.0647e-05 - val_loss: 0.0209\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.4118e-04 - val_loss: 0.0196\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.2962e-04 - val_loss: 0.0203\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.5328e-05 - val_loss: 0.0215\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 3.4944e-05 - val_loss: 0.0220\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 3.7863e-05 - val_loss: 0.0214\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 8.4719e-07 - val_loss: 0.0206\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.4897e-05 - val_loss: 0.0201\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.4579e-05 - val_loss: 0.0204\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.2046e-05 - val_loss: 0.0209\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.5369e-05 - val_loss: 0.0208\n",
      "Epoch 25/50\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2974e-05Restoring model weights from the end of the best epoch: 15.\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 8.3210e-06 - val_loss: 0.0203\n",
      "Epoch 25: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CHARAL en clúster 1\n",
      "No se tienen datos suficientes para CHARAL en clúster 1 en los últimos seis meses de 2023\n",
      "Training model for species: PEPINO DE MAR, cluster: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "29/29 [==============================] - 4s 26ms/step - loss: 0.0581 - val_loss: 0.1024\n",
      "Epoch 2/50\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0535 - val_loss: 0.1022\n",
      "Epoch 3/50\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0509 - val_loss: 0.0935\n",
      "Epoch 4/50\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0497 - val_loss: 0.1013\n",
      "Epoch 5/50\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0494 - val_loss: 0.1015\n",
      "Epoch 6/50\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0500 - val_loss: 0.1005\n",
      "Epoch 7/50\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0506 - val_loss: 0.0960\n",
      "Epoch 8/50\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0480 - val_loss: 0.0960\n",
      "Epoch 9/50\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0461 - val_loss: 0.0945\n",
      "Epoch 10/50\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0463 - val_loss: 0.0928\n",
      "Epoch 11/50\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0451 - val_loss: 0.0970\n",
      "Epoch 12/50\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0474 - val_loss: 0.1123\n",
      "Epoch 13/50\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0445 - val_loss: 0.1174\n",
      "Epoch 14/50\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0453 - val_loss: 0.1132\n",
      "Epoch 15/50\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0428 - val_loss: 0.1237\n",
      "Epoch 16/50\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0457 - val_loss: 0.1111\n",
      "Epoch 17/50\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0417 - val_loss: 0.1429\n",
      "Epoch 18/50\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0421 - val_loss: 0.1426\n",
      "Epoch 19/50\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0385 - val_loss: 0.1279\n",
      "Epoch 20/50\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0403Restoring model weights from the end of the best epoch: 10.\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0391 - val_loss: 0.1363\n",
      "Epoch 20: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para PEPINO DE MAR en clúster 3\n",
      "No se tienen datos suficientes para PEPINO DE MAR en clúster 3 en los últimos seis meses de 2023\n",
      "Training model for species: PEPINO DE MAR, cluster: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "44/44 [==============================] - 4s 18ms/step - loss: 0.0253 - val_loss: 0.0146\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.0184 - val_loss: 0.0066\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0285\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0029\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0131\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.0112 - val_loss: 0.0054\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.0034\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0165\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.0103\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.0074\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 14/50\n",
      "40/44 [==========================>...] - ETA: 0s - loss: 0.0046Restoring model weights from the end of the best epoch: 4.\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 14: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para PEPINO DE MAR en clúster 6\n",
      "No se tienen datos suficientes para PEPINO DE MAR en clúster 6 en los últimos seis meses de 2023\n",
      "Training model for species: PEPINO DE MAR, cluster: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 3s 82ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "1/8 [==>...........................] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "8/8 [==============================] - 0s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para PEPINO DE MAR en clúster 5\n",
      "No se tienen datos suficientes para PEPINO DE MAR en clúster 5 en los últimos seis meses de 2023\n",
      "Training model for species: PEPINO DE MAR, cluster: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 4s 55ms/step - loss: 0.0414 - val_loss: 0.0107\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0151\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0062 - val_loss: 0.0116\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0057 - val_loss: 0.0113\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0056 - val_loss: 0.0121\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0059 - val_loss: 0.0112\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 0.0114\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0114\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0118\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0041 - val_loss: 0.0116\n",
      "Epoch 11/50\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.0042Restoring model weights from the end of the best epoch: 1.\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0115\n",
      "Epoch 11: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para PEPINO DE MAR en clúster 4\n",
      "No se tienen datos suficientes para PEPINO DE MAR en clúster 4 en los últimos seis meses de 2023\n",
      "Training model for species: MACARELA, cluster: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "108/108 [==============================] - 4s 11ms/step - loss: 0.0685 - val_loss: 0.0370\n",
      "Epoch 2/50\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.0559 - val_loss: 0.0331\n",
      "Epoch 3/50\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0494 - val_loss: 0.0358\n",
      "Epoch 4/50\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.0479 - val_loss: 0.0392\n",
      "Epoch 5/50\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0493 - val_loss: 0.0417\n",
      "Epoch 6/50\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.0487 - val_loss: 0.0460\n",
      "Epoch 7/50\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.0461 - val_loss: 0.0318\n",
      "Epoch 8/50\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.0466 - val_loss: 0.0377\n",
      "Epoch 9/50\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0463 - val_loss: 0.0314\n",
      "Epoch 10/50\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.0463 - val_loss: 0.0321\n",
      "Epoch 11/50\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0459 - val_loss: 0.0313\n",
      "Epoch 12/50\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0454 - val_loss: 0.0382\n",
      "Epoch 13/50\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.0449 - val_loss: 0.0440\n",
      "Epoch 14/50\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0458 - val_loss: 0.0358\n",
      "Epoch 15/50\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0445 - val_loss: 0.0323\n",
      "Epoch 16/50\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.0444 - val_loss: 0.0323\n",
      "Epoch 17/50\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.0456 - val_loss: 0.0323\n",
      "Epoch 18/50\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.0443 - val_loss: 0.0332\n",
      "Epoch 19/50\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.0445 - val_loss: 0.0339\n",
      "Epoch 20/50\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.0465 - val_loss: 0.0344\n",
      "Epoch 21/50\n",
      "106/108 [============================>.] - ETA: 0s - loss: 0.0431Restoring model weights from the end of the best epoch: 11.\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.0437 - val_loss: 0.0365\n",
      "Epoch 21: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para MACARELA en clúster 3\n",
      "No se tienen datos suficientes para MACARELA en clúster 3 en los últimos seis meses de 2023\n",
      "Training model for species: MACARELA, cluster: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "55/55 [==============================] - 4s 15ms/step - loss: 7.6225e-04 - val_loss: 0.0670\n",
      "Epoch 2/50\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 1.3900e-04 - val_loss: 0.0680\n",
      "Epoch 3/50\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 7.0711e-05 - val_loss: 0.0685\n",
      "Epoch 4/50\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 6.8502e-05 - val_loss: 0.0686\n",
      "Epoch 5/50\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 6.4644e-05 - val_loss: 0.0686\n",
      "Epoch 6/50\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 5.6517e-05 - val_loss: 0.0694\n",
      "Epoch 7/50\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 6.1075e-05 - val_loss: 0.0689\n",
      "Epoch 8/50\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 4.9787e-05 - val_loss: 0.0688\n",
      "Epoch 9/50\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 5.2115e-05 - val_loss: 0.0696\n",
      "Epoch 10/50\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 4.5308e-05 - val_loss: 0.0687\n",
      "Epoch 11/50\n",
      "44/55 [=======================>......] - ETA: 0s - loss: 4.7876e-05Restoring model weights from the end of the best epoch: 1.\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 5.0955e-05 - val_loss: 0.0692\n",
      "Epoch 11: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para MACARELA en clúster 1\n",
      "No se tienen datos suficientes para MACARELA en clúster 1 en los últimos seis meses de 2023\n",
      "Training model for species: MACARELA, cluster: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4343 - val_loss: 0.5213\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3022 - val_loss: 0.4876\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1910 - val_loss: 0.4595\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1157 - val_loss: 0.4332\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0623 - val_loss: 0.4085\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0278 - val_loss: 0.3855\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0082 - val_loss: 0.3643\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.8175e-04 - val_loss: 0.3456\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0024 - val_loss: 0.3303\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0104 - val_loss: 0.3184\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0208 - val_loss: 0.3100\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0268 - val_loss: 0.3046\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0309 - val_loss: 0.3013\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0338 - val_loss: 0.3000\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0319 - val_loss: 0.3003\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0285 - val_loss: 0.3018\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0221 - val_loss: 0.3043\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0151 - val_loss: 0.3074\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0111 - val_loss: 0.3109\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0057 - val_loss: 0.3145\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0024 - val_loss: 0.3180\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4.8452e-04 - val_loss: 0.3212\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.6997e-06 - val_loss: 0.3237\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.7893e-04Restoring model weights from the end of the best epoch: 14.\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.7893e-04 - val_loss: 0.3258\n",
      "Epoch 24: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para MACARELA en clúster 4\n",
      "No se tienen datos suficientes para MACARELA en clúster 4 en los últimos seis meses de 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: LEBRANCHA, cluster: 3\n",
      "Error entrenando el modelo para especie: LEBRANCHA, clúster: 3. Error: tuple index out of range\n",
      "Training model for species: LEBRANCHA, cluster: 1\n",
      "Epoch 1/50\n",
      "144/144 [==============================] - 4s 9ms/step - loss: 0.0259 - val_loss: 0.0081\n",
      "Epoch 2/50\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.0216 - val_loss: 0.0135\n",
      "Epoch 3/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 0.0202 - val_loss: 0.0130\n",
      "Epoch 4/50\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.0203 - val_loss: 0.0123\n",
      "Epoch 5/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 0.0190 - val_loss: 0.0095\n",
      "Epoch 6/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 0.0192 - val_loss: 0.0144\n",
      "Epoch 7/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 0.0192 - val_loss: 0.0112\n",
      "Epoch 8/50\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.0177 - val_loss: 0.0192\n",
      "Epoch 9/50\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.0182 - val_loss: 0.0131\n",
      "Epoch 10/50\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.0178 - val_loss: 0.0188\n",
      "Epoch 11/50\n",
      "139/144 [===========================>..] - ETA: 0s - loss: 0.0183Restoring model weights from the end of the best epoch: 1.\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.0180 - val_loss: 0.0162\n",
      "Epoch 11: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LEBRANCHA en clúster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 527ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "MSE Mensual para LEBRANCHA en clúster 1: 478154.88545180607, R2 Mensual: 0.9101737334863262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_195974/3758942541.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: RUBIA Y VILLAJAIBA, cluster: 1\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 3s 112ms/step - loss: 0.2112 - val_loss: 0.0058\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1656 - val_loss: 0.0058\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1419 - val_loss: 0.0255\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1032 - val_loss: 0.0541\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0964 - val_loss: 0.0905\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0907 - val_loss: 0.0951\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0845 - val_loss: 0.0862\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0894 - val_loss: 0.0804\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0803 - val_loss: 0.0515\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0786 - val_loss: 0.0455\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0811 - val_loss: 0.0380\n",
      "Epoch 12/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.0192Restoring model weights from the end of the best epoch: 2.\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0794 - val_loss: 0.0378\n",
      "Epoch 12: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para RUBIA Y VILLAJAIBA en clúster 1\n",
      "No se tienen datos suficientes para RUBIA Y VILLAJAIBA en clúster 1 en los últimos seis meses de 2023\n",
      "Training model for species: FAUNA, cluster: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "35/35 [==============================] - 4s 22ms/step - loss: 0.0693 - val_loss: 0.2000\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0593 - val_loss: 0.1819\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0655 - val_loss: 0.1850\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0595 - val_loss: 0.1798\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0604 - val_loss: 0.1895\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0586 - val_loss: 0.1704\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0561 - val_loss: 0.1757\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0595 - val_loss: 0.1748\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0561 - val_loss: 0.1704\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0559 - val_loss: 0.1683\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0588 - val_loss: 0.1673\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0581 - val_loss: 0.1680\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0566 - val_loss: 0.1599\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0563 - val_loss: 0.1625\n",
      "Epoch 15/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0574 - val_loss: 0.1596\n",
      "Epoch 16/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0545 - val_loss: 0.1587\n",
      "Epoch 17/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0555 - val_loss: 0.1595\n",
      "Epoch 18/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0549 - val_loss: 0.1556\n",
      "Epoch 19/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0561 - val_loss: 0.1579\n",
      "Epoch 20/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0568 - val_loss: 0.1599\n",
      "Epoch 21/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0581 - val_loss: 0.1488\n",
      "Epoch 22/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0552 - val_loss: 0.1530\n",
      "Epoch 23/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0541 - val_loss: 0.1531\n",
      "Epoch 24/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0534 - val_loss: 0.1533\n",
      "Epoch 25/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0540 - val_loss: 0.1537\n",
      "Epoch 26/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0559 - val_loss: 0.1529\n",
      "Epoch 27/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0565 - val_loss: 0.1526\n",
      "Epoch 28/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0554 - val_loss: 0.1491\n",
      "Epoch 29/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0585 - val_loss: 0.1527\n",
      "Epoch 30/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0556 - val_loss: 0.1512\n",
      "Epoch 31/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0534 - val_loss: 0.1478\n",
      "Epoch 32/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0528 - val_loss: 0.1472\n",
      "Epoch 33/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0547 - val_loss: 0.1477\n",
      "Epoch 34/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0517 - val_loss: 0.1449\n",
      "Epoch 35/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0527 - val_loss: 0.1425\n",
      "Epoch 36/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0538 - val_loss: 0.1354\n",
      "Epoch 37/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0516 - val_loss: 0.1386\n",
      "Epoch 38/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0512 - val_loss: 0.1322\n",
      "Epoch 39/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0501 - val_loss: 0.1327\n",
      "Epoch 40/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0525 - val_loss: 0.1209\n",
      "Epoch 41/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0509 - val_loss: 0.1312\n",
      "Epoch 42/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0496 - val_loss: 0.1304\n",
      "Epoch 43/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0503 - val_loss: 0.1334\n",
      "Epoch 44/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0501 - val_loss: 0.1272\n",
      "Epoch 45/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0507 - val_loss: 0.1255\n",
      "Epoch 46/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0503 - val_loss: 0.1266\n",
      "Epoch 47/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0560 - val_loss: 0.1296\n",
      "Epoch 48/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0481 - val_loss: 0.1316\n",
      "Epoch 49/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0510 - val_loss: 0.1269\n",
      "Epoch 50/50\n",
      "27/35 [======================>.......] - ETA: 0s - loss: 0.0490Restoring model weights from the end of the best epoch: 40.\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0475 - val_loss: 0.1245\n",
      "Epoch 50: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para FAUNA en clúster 7\n",
      "No se tienen datos suficientes para FAUNA en clúster 7 en los últimos seis meses de 2023\n",
      "Training model for species: FAUNA, cluster: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0806 - val_loss: 0.0483\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0337 - val_loss: 0.1062\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0063 - val_loss: 0.1896\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0011 - val_loss: 0.2704\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0199 - val_loss: 0.2936\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0244 - val_loss: 0.2732\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0161 - val_loss: 0.2345\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0064 - val_loss: 0.1939\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - val_loss: 0.1576\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.1374e-05 - val_loss: 0.1301\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.2203e-04Restoring model weights from the end of the best epoch: 1.\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 9.2203e-04 - val_loss: 0.1113\n",
      "Epoch 11: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para FAUNA en clúster 3\n",
      "No se tienen datos suficientes para FAUNA en clúster 3 en los últimos seis meses de 2023\n",
      "Training model for species: FAUNA, cluster: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0730 - val_loss: 0.1840\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0436 - val_loss: 0.1524\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0275 - val_loss: 0.1246\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0194 - val_loss: 0.1008\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0091 - val_loss: 0.0801\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0055 - val_loss: 0.0624\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.7922e-06 - val_loss: 0.0482\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.1277e-05 - val_loss: 0.0369\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0025 - val_loss: 0.0296\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0032 - val_loss: 0.0254\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0066 - val_loss: 0.0242\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0055 - val_loss: 0.0247\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0084 - val_loss: 0.0270\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0019 - val_loss: 0.0298\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0031 - val_loss: 0.0332\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0013 - val_loss: 0.0368\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0025 - val_loss: 0.0407\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 5.3811e-04 - val_loss: 0.0445\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.3150e-04 - val_loss: 0.0478\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.0984e-05 - val_loss: 0.0505\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1958e-04Restoring model weights from the end of the best epoch: 11.\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1958e-04 - val_loss: 0.0528\n",
      "Epoch 21: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para FAUNA en clúster 1\n",
      "No se tienen datos suficientes para FAUNA en clúster 1 en los últimos seis meses de 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: SARGAZO, cluster: 3\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 3s 551ms/step - loss: 0.1720 - val_loss: 0.0244\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1427 - val_loss: 0.0214\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1366 - val_loss: 0.0210\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1316 - val_loss: 0.0250\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1141 - val_loss: 0.0249\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1036 - val_loss: 0.0254\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0969 - val_loss: 0.0259\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0921 - val_loss: 0.0290\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0856 - val_loss: 0.0285\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0788 - val_loss: 0.0281\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0740 - val_loss: 0.0272\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0765 - val_loss: 0.0282\n",
      "Epoch 13/50\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0486Restoring model weights from the end of the best epoch: 3.\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0663 - val_loss: 0.0263\n",
      "Epoch 13: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para SARGAZO en clúster 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 521ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "MSE Mensual para SARGAZO en clúster 3: 251097.3350985909, R2 Mensual: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_195974/3758942541.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n",
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/sklearn/metrics/_regression.py:1187: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "# Obtener listas de especies y clústeres únicos\n",
    "unique_species = data['species'].unique()\n",
    "unique_clusters = data['Cluster_Label'].unique()\n",
    "\n",
    "# Definir la especie y clúster desde donde retomar el proceso y detenerlo\n",
    "start_species = 'RAYA Y SIMILARES'\n",
    "start_cluster = 7.0\n",
    "stop_species = 'BESUGO'\n",
    "stop_cluster = 0.0\n",
    "\n",
    "# Inicializar banderas\n",
    "start_training = False\n",
    "stop_training = False\n",
    "\n",
    "for species_name in unique_species:\n",
    "    for cluster_label in unique_clusters:\n",
    "        # Activar la bandera cuando se alcance la especie y clúster deseados para iniciar\n",
    "        if species_name == start_species and cluster_label == start_cluster:\n",
    "            start_training = True\n",
    "        \n",
    "        # Detener el proceso cuando se alcance la especie y clúster deseados para detener\n",
    "        if species_name == stop_species and cluster_label == stop_cluster:\n",
    "            stop_training = True\n",
    "        \n",
    "        # Continuar solo si la bandera de inicio está activada y la de detener no lo está\n",
    "        if start_training and not stop_training:\n",
    "            # Filtrar los datos para obtener una especie y un clúster específico\n",
    "            filtered_data = data[(data['species'] == species_name) & (data['Cluster_Label'] == cluster_label)]\n",
    "            \n",
    "            if len(filtered_data) >= look_back:\n",
    "                filtered_data = filtered_data.sort_values('date')\n",
    "                try:\n",
    "                    print(f'Training model for species: {species_name}, cluster: {cluster_label}')\n",
    "                    model, scaler = train_and_save_moe_model(filtered_data, species_name, cluster_label, look_back)\n",
    "\n",
    "                    # Guardar los datos para las bandas de confianza\n",
    "                    test_data_2023 = filtered_data[(filtered_data['date'].dt.year == 2023) & (filtered_data['date'].dt.month >= 1)]\n",
    "                    if len(test_data_2023) >= look_back:\n",
    "                        predictions, lower_bound, upper_bound = predict_with_confidence_intervals(model, scaler, test_data_2023, look_back)\n",
    "                        real_values = test_data_2023['landed_w_kg'].values[look_back:]\n",
    "                        \n",
    "                        # Crear un DataFrame para los resultados\n",
    "                        results_df = pd.DataFrame({\n",
    "                            'date': test_data_2023['date'].values[look_back:],\n",
    "                            'real_values': real_values,\n",
    "                            'predictions': predictions,\n",
    "                            'lower_bound': lower_bound,\n",
    "                            'upper_bound': upper_bound\n",
    "                        })\n",
    "                        \n",
    "                        # Guardar los resultados\n",
    "                        results_directory = 'resultados_moe'\n",
    "                        os.makedirs(results_directory, exist_ok=True)\n",
    "                        results_path = os.path.join(results_directory, f'{species_name}_cluster_{cluster_label}_predictions.csv')\n",
    "                        results_df.to_csv(results_path, index=False)\n",
    "                        \n",
    "                        # Agrupar por mes y sumar los valores\n",
    "                        monthly_totals = results_df.set_index('date').resample('M').sum()\n",
    "                        \n",
    "                        # Calcular MSE y R2 para los totales mensuales\n",
    "                        mse = mean_squared_error(monthly_totals['real_values'], monthly_totals['predictions'])\n",
    "                        r2 = r2_score(monthly_totals['real_values'], monthly_totals['predictions'])\n",
    "                        print(f'MSE Mensual para {species_name} en clúster {cluster_label}: {mse}, R2 Mensual: {r2}')\n",
    "                        \n",
    "                        # Crear figura\n",
    "                        plt.figure(figsize=(10, 6))\n",
    "                        plt.plot(monthly_totals.index, monthly_totals['real_values'], color='blue', label='Real')\n",
    "                        plt.plot(monthly_totals.index, monthly_totals['predictions'], color='red', linestyle='--', label='Predicho')\n",
    "                        plt.fill_between(monthly_totals.index, monthly_totals['lower_bound'], monthly_totals['upper_bound'], color='gray', alpha=0.2, label='Intervalo de Confianza 95%')\n",
    "                        plt.title(f'Totales Mensuales de {species_name} en clúster {cluster_label} para los Últimos Seis Meses de 2023')\n",
    "                        plt.xlabel('Fecha')\n",
    "                        plt.ylabel('Peso Desembarcado (kg)')\n",
    "                        plt.legend()\n",
    "                        plot_path = os.path.join(results_directory, f'{species_name}_cluster_{cluster_label}_plot.png')\n",
    "                        plt.savefig(plot_path)\n",
    "                        plt.close()\n",
    "                    else:\n",
    "                        print(f'No se tienen datos suficientes para {species_name} en clúster {cluster_label} en los últimos seis meses de 2023')\n",
    "                except Exception as e:\n",
    "                    print(f'Error entrenando el modelo para especie: {species_name}, clúster: {cluster_label}. Error: {e}')\n",
    "        \n",
    "        # Salir del bucle si se alcanza el punto de detener\n",
    "        if stop_training:\n",
    "            break\n",
    "    if stop_training:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cedo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
