{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 20:27:24.176725: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-30 20:27:24.180230: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-30 20:27:24.220547: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-30 20:27:24.220574: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-30 20:27:24.221847: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-30 20:27:24.228760: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-30 20:27:24.229602: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-30 20:27:25.045378: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import LSTM, Dense, Dropout, Input, Conv1D, Flatten, concatenate\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Definir look_back\n",
    "look_back = 6  \n",
    "\n",
    "# Cargar el archivo y eliminar filas donde el clúster es NaN\n",
    "file_path = 'data/data.csv'   # Cambia esta ruta al archivo que has subido\n",
    "data = pd.read_csv(file_path)\n",
    "data = data.dropna(subset=['Cluster_Label'])\n",
    "\n",
    "# Convertir 'year' y 'month_no' a una sola columna de tipo fecha\n",
    "data['date'] = pd.to_datetime(data['year'].astype(str) + '-' + data['month_no'].astype(str))\n",
    "\n",
    "# Seleccionar las columnas necesarias para la serie temporal\n",
    "columns_to_keep = ['date', 'species', 'Cluster_Label', 'landed_w_kg',\n",
    "                   'mean_temp_30m','mean_temp_10m','thetao_sfc=6',\n",
    "                   'thetao_sfc=7.92956018447876','thetao_sfc=9.572997093200684','thetao_sfc=11.40499973297119',\n",
    "                   'thetao_sfc=13.46714019775391','thetao_sfc=15.8100700378418','thetao_sfc=18.49555969238281',\n",
    "                   'thetao_sfc=21.59881973266602','thetao_sfc=25.21141052246094','thetao_sfc=29.44473075866699']\n",
    "data = data[columns_to_keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para preparar los datos\n",
    "def prepare_data(group, look_back=6):\n",
    "    features = ['landed_w_kg','Cluster_Label', 'mean_temp_30m','mean_temp_10m','thetao_sfc=6',\n",
    "                   'thetao_sfc=7.92956018447876','thetao_sfc=9.572997093200684','thetao_sfc=11.40499973297119',\n",
    "                   'thetao_sfc=13.46714019775391','thetao_sfc=15.8100700378418','thetao_sfc=18.49555969238281',\n",
    "                   'thetao_sfc=21.59881973266602','thetao_sfc=25.21141052246094','thetao_sfc=29.44473075866699']\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    group_scaled = scaler.fit_transform(group[features])\n",
    "    \n",
    "    X, y = [], []\n",
    "    for i in range(len(group_scaled) - look_back):\n",
    "        a = group_scaled[i:(i + look_back)]\n",
    "        X.append(a)\n",
    "        y.append(group_scaled[i + look_back, 0])  # La primera columna es 'landed_w_kg'\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2]))\n",
    "    return X, y, scaler\n",
    "\n",
    "# Crear el modelo LSTM\n",
    "def create_lstm_model(input_shape):\n",
    "    lstm_input = Input(shape=input_shape)\n",
    "    x = LSTM(50, return_sequences=True)(lstm_input)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = LSTM(25, activation='relu', return_sequences=True)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = LSTM(12, activation='linear')(x)\n",
    "    lstm_output = Dense(1, activation='linear')(x)\n",
    "    return Model(inputs=lstm_input, outputs=lstm_output)\n",
    "\n",
    "# Crear el modelo DNN\n",
    "def create_dnn_model(input_shape):\n",
    "    dnn_input = Input(shape=(input_shape[0], input_shape[1]))\n",
    "    x = Flatten()(dnn_input)\n",
    "    x = Dense(10, activation='relu')(x)\n",
    "    x = Dense(5, activation='relu')(x)\n",
    "    dnn_output = Dense(1, activation='linear')(x)\n",
    "    return Model(inputs=dnn_input, outputs=dnn_output)\n",
    "\n",
    "# Crear el modelo CNN\n",
    "def create_cnn_model(input_shape):\n",
    "    cnn_input = Input(shape=input_shape)\n",
    "    x = Conv1D(32, kernel_size=3, activation='relu')(cnn_input)\n",
    "    x = Flatten()(x)\n",
    "    cnn_output = Dense(1, activation='linear')(x)\n",
    "    return Model(inputs=cnn_input, outputs=cnn_output)\n",
    "\n",
    "# Crear el modelo Mixture of Experts (MoE)\n",
    "def create_moe_model(input_shape):\n",
    "    # Definir los expertos\n",
    "    lstm_model = create_lstm_model(input_shape)\n",
    "    dnn_model = create_dnn_model(input_shape)\n",
    "    cnn_model = create_cnn_model(input_shape)\n",
    "    \n",
    "    # Definir el gating network\n",
    "    moe_input = Input(shape=input_shape)\n",
    "    x = Flatten()(moe_input)\n",
    "    x = Dense(10, activation='relu')(x)\n",
    "    gate_output = Dense(3, activation='softmax')(x)  # Tres expertos\n",
    "\n",
    "    # Obtener las salidas de los expertos\n",
    "    lstm_output = lstm_model(moe_input)\n",
    "    dnn_output = dnn_model(moe_input)\n",
    "    cnn_output = cnn_model(moe_input)\n",
    "    \n",
    "    # Combinar las salidas usando el gating network\n",
    "    output = concatenate([lstm_output * gate_output[:, 0:1],\n",
    "                          dnn_output * gate_output[:, 1:2],\n",
    "                          cnn_output * gate_output[:, 2:3]], axis=1)\n",
    "    output = Dense(1, activation='linear')(output)\n",
    "    \n",
    "    model = Model(inputs=moe_input, outputs=output)\n",
    "    model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar y guardar el modelo MoE\n",
    "def train_and_save_moe_model(data, species_name, cluster_label, look_back=look_back, epochs=50, batch_size=1):\n",
    "    X, y, scaler = prepare_data(data, look_back)\n",
    "    model = create_moe_model((look_back, X.shape[2]))\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "    history = model.fit(X, y, validation_split=0.2, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[early_stopping])\n",
    "    \n",
    "    # Guardar el modelo y el scaler\n",
    "    model_directory = 'modelos_moe'\n",
    "    os.makedirs(model_directory, exist_ok=True)\n",
    "    model_path = os.path.join(model_directory, f'{species_name}_cluster_{cluster_label}_moe_model.h5')\n",
    "    scaler_path = os.path.join(model_directory, f'{species_name}_cluster_{cluster_label}_moe_scaler.pkl')\n",
    "    model.save(model_path)\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    \n",
    "    # Guardar los valores de monitoreo del entrenamiento\n",
    "    train_moe_directory = 'train_moe'\n",
    "    os.makedirs(train_moe_directory, exist_ok=True)\n",
    "    history_path = os.path.join(train_moe_directory, f'{species_name}_cluster_{cluster_label}_training_history.csv')\n",
    "    pd.DataFrame(history.history).to_csv(history_path, index=False)\n",
    "    \n",
    "    print(f'Modelo MoE, scaler y datos de entrenamiento guardados para {species_name} en clúster {cluster_label}')\n",
    "    return model, scaler\n",
    "\n",
    "# Función para hacer predicciones con bandas de confianza usando bootstrap\n",
    "def predict_with_confidence_intervals(model, scaler, data, look_back=6, n_bootstrap=100, alpha=0.01):\n",
    "    features = ['landed_w_kg','Cluster_Label','mean_temp_30m','mean_temp_10m','thetao_sfc=6',\n",
    "                   'thetao_sfc=7.92956018447876','thetao_sfc=9.572997093200684','thetao_sfc=11.40499973297119',\n",
    "                   'thetao_sfc=13.46714019775391','thetao_sfc=15.8100700378418','thetao_sfc=18.49555969238281',\n",
    "                   'thetao_sfc=21.59881973266602','thetao_sfc=25.21141052246094','thetao_sfc=29.44473075866699']\n",
    "    group_scaled = scaler.transform(data[features])\n",
    "\n",
    "    X = []\n",
    "    for i in range(len(group_scaled) - look_back):\n",
    "        a = group_scaled[i:(i + look_back)]\n",
    "        X.append(a)\n",
    "    X = np.array(X)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2]))\n",
    "    \n",
    "    predictions = model.predict(X)\n",
    "    predictions = scaler.inverse_transform(np.hstack((predictions, X[:, -1, 1:])))[:, 0]\n",
    "    \n",
    "    # Bootstrap para bandas de confianza\n",
    "    bootstrap_predictions = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        indices = np.random.choice(range(len(X)), len(X), replace=True)\n",
    "        X_sample = X[indices]\n",
    "        pred_sample = model.predict(X_sample)\n",
    "        pred_sample = scaler.inverse_transform(np.hstack((pred_sample, X_sample[:, -1, 1:])))[:, 0]\n",
    "        bootstrap_predictions.append(pred_sample)\n",
    "    \n",
    "    bootstrap_predictions = np.array(bootstrap_predictions)\n",
    "    lower_bound = np.percentile(bootstrap_predictions, 100 * alpha / 2, axis=0)\n",
    "    upper_bound = np.percentile(bootstrap_predictions, 100 * (1 - alpha / 2), axis=0)\n",
    "    \n",
    "    return predictions, lower_bound, upper_bound\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: BANDERA, cluster: 7\n",
      "Epoch 1/50\n",
      "9264/9264 [==============================] - 61s 6ms/step - loss: 0.0012 - val_loss: 7.8446e-04\n",
      "Epoch 2/50\n",
      "9264/9264 [==============================] - 54s 6ms/step - loss: 0.0011 - val_loss: 7.0231e-04\n",
      "Epoch 3/50\n",
      "9264/9264 [==============================] - 54s 6ms/step - loss: 0.0011 - val_loss: 6.5556e-04\n",
      "Epoch 4/50\n",
      "9264/9264 [==============================] - 54s 6ms/step - loss: 0.0010 - val_loss: 6.5407e-04\n",
      "Epoch 5/50\n",
      "9264/9264 [==============================] - 54s 6ms/step - loss: 0.0010 - val_loss: 6.2270e-04\n",
      "Epoch 6/50\n",
      "9264/9264 [==============================] - 53s 6ms/step - loss: 0.0010 - val_loss: 6.3542e-04\n",
      "Epoch 7/50\n",
      "9264/9264 [==============================] - 53s 6ms/step - loss: 0.0010 - val_loss: 6.8005e-04\n",
      "Epoch 8/50\n",
      "9264/9264 [==============================] - 53s 6ms/step - loss: 0.0010 - val_loss: 6.7603e-04\n",
      "Epoch 9/50\n",
      "9264/9264 [==============================] - 53s 6ms/step - loss: 0.0010 - val_loss: 7.1091e-04\n",
      "Epoch 10/50\n",
      "9264/9264 [==============================] - 54s 6ms/step - loss: 0.0010 - val_loss: 6.1196e-04\n",
      "Epoch 11/50\n",
      "9264/9264 [==============================] - 53s 6ms/step - loss: 0.0010 - val_loss: 6.1473e-04\n",
      "Epoch 12/50\n",
      "9264/9264 [==============================] - 53s 6ms/step - loss: 9.9601e-04 - val_loss: 6.1610e-04\n",
      "Epoch 13/50\n",
      "9264/9264 [==============================] - 53s 6ms/step - loss: 0.0010 - val_loss: 7.6085e-04\n",
      "Epoch 14/50\n",
      "9264/9264 [==============================] - 53s 6ms/step - loss: 9.8996e-04 - val_loss: 6.5475e-04\n",
      "Epoch 15/50\n",
      "9264/9264 [==============================] - 53s 6ms/step - loss: 9.9004e-04 - val_loss: 6.0944e-04\n",
      "Epoch 16/50\n",
      "9264/9264 [==============================] - 52s 6ms/step - loss: 9.8786e-04 - val_loss: 6.2702e-04\n",
      "Epoch 17/50\n",
      "9264/9264 [==============================] - 52s 6ms/step - loss: 9.9242e-04 - val_loss: 6.1289e-04\n",
      "Epoch 18/50\n",
      "9264/9264 [==============================] - 51s 6ms/step - loss: 9.8273e-04 - val_loss: 6.1515e-04\n",
      "Epoch 19/50\n",
      "9264/9264 [==============================] - 51s 6ms/step - loss: 9.8944e-04 - val_loss: 6.1481e-04\n",
      "Epoch 20/50\n",
      "9264/9264 [==============================] - 51s 6ms/step - loss: 9.8274e-04 - val_loss: 6.3917e-04\n",
      "Epoch 21/50\n",
      "9264/9264 [==============================] - 52s 6ms/step - loss: 9.8480e-04 - val_loss: 6.1769e-04\n",
      "Epoch 22/50\n",
      "9264/9264 [==============================] - 52s 6ms/step - loss: 9.8142e-04 - val_loss: 6.6612e-04\n",
      "Epoch 23/50\n",
      "9264/9264 [==============================] - 51s 6ms/step - loss: 9.8584e-04 - val_loss: 6.0662e-04\n",
      "Epoch 24/50\n",
      "9264/9264 [==============================] - 51s 6ms/step - loss: 9.7642e-04 - val_loss: 6.3496e-04\n",
      "Epoch 25/50\n",
      "9264/9264 [==============================] - 51s 6ms/step - loss: 9.8076e-04 - val_loss: 6.0570e-04\n",
      "Epoch 26/50\n",
      "9264/9264 [==============================] - 51s 6ms/step - loss: 9.8006e-04 - val_loss: 6.0830e-04\n",
      "Epoch 27/50\n",
      "9264/9264 [==============================] - 52s 6ms/step - loss: 9.7273e-04 - val_loss: 6.1885e-04\n",
      "Epoch 28/50\n",
      "9264/9264 [==============================] - 51s 6ms/step - loss: 9.7008e-04 - val_loss: 6.4852e-04\n",
      "Epoch 29/50\n",
      "9264/9264 [==============================] - 56s 6ms/step - loss: 9.7828e-04 - val_loss: 6.5560e-04\n",
      "Epoch 30/50\n",
      "9264/9264 [==============================] - 57s 6ms/step - loss: 9.7537e-04 - val_loss: 6.4259e-04\n",
      "Epoch 31/50\n",
      "9264/9264 [==============================] - 56s 6ms/step - loss: 9.7441e-04 - val_loss: 6.0331e-04\n",
      "Epoch 32/50\n",
      "9264/9264 [==============================] - 56s 6ms/step - loss: 9.7106e-04 - val_loss: 6.3104e-04\n",
      "Epoch 33/50\n",
      "9264/9264 [==============================] - 55s 6ms/step - loss: 9.7312e-04 - val_loss: 7.8759e-04\n",
      "Epoch 34/50\n",
      "9264/9264 [==============================] - 55s 6ms/step - loss: 9.7738e-04 - val_loss: 6.1390e-04\n",
      "Epoch 35/50\n",
      "9264/9264 [==============================] - 55s 6ms/step - loss: 9.7692e-04 - val_loss: 6.0317e-04\n",
      "Epoch 36/50\n",
      "9264/9264 [==============================] - 56s 6ms/step - loss: 9.7367e-04 - val_loss: 6.0244e-04\n",
      "Epoch 37/50\n",
      "9264/9264 [==============================] - 57s 6ms/step - loss: 9.7379e-04 - val_loss: 6.6550e-04\n",
      "Epoch 38/50\n",
      "9264/9264 [==============================] - 56s 6ms/step - loss: 9.7387e-04 - val_loss: 6.1902e-04\n",
      "Epoch 39/50\n",
      "9264/9264 [==============================] - 57s 6ms/step - loss: 9.7114e-04 - val_loss: 6.0981e-04\n",
      "Epoch 40/50\n",
      "9264/9264 [==============================] - 56s 6ms/step - loss: 9.8549e-04 - val_loss: 7.8795e-04\n",
      "Epoch 41/50\n",
      "9264/9264 [==============================] - 56s 6ms/step - loss: 9.7351e-04 - val_loss: 6.0108e-04\n",
      "Epoch 42/50\n",
      "9264/9264 [==============================] - 55s 6ms/step - loss: 9.7338e-04 - val_loss: 6.2571e-04\n",
      "Epoch 43/50\n",
      "9264/9264 [==============================] - 56s 6ms/step - loss: 9.6911e-04 - val_loss: 6.0854e-04\n",
      "Epoch 44/50\n",
      "9264/9264 [==============================] - 56s 6ms/step - loss: 9.7848e-04 - val_loss: 6.0857e-04\n",
      "Epoch 45/50\n",
      "9264/9264 [==============================] - 56s 6ms/step - loss: 9.7230e-04 - val_loss: 6.0192e-04\n",
      "Epoch 46/50\n",
      "9264/9264 [==============================] - 56s 6ms/step - loss: 9.7328e-04 - val_loss: 6.2208e-04\n",
      "Epoch 47/50\n",
      "9264/9264 [==============================] - 51s 6ms/step - loss: 9.7159e-04 - val_loss: 6.0848e-04\n",
      "Epoch 48/50\n",
      "9264/9264 [==============================] - 52s 6ms/step - loss: 9.7432e-04 - val_loss: 6.1865e-04\n",
      "Epoch 49/50\n",
      "9264/9264 [==============================] - 51s 5ms/step - loss: 9.7343e-04 - val_loss: 6.0935e-04\n",
      "Epoch 50/50\n",
      "9264/9264 [==============================] - 51s 5ms/step - loss: 9.7702e-04 - val_loss: 6.5011e-04\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BANDERA en clúster 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 1s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para BANDERA en clúster 7: 83180717.66826181, R2 Mensual: -1.9601911090489557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: BANDERA, cluster: 0\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - 7s 31ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "41/41 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BANDERA en clúster 0\n",
      "No se tienen datos suficientes para BANDERA en clúster 0 en los últimos seis meses de 2023\n",
      "Training model for species: BANDERA, cluster: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6043/6043 [==============================] - 42s 6ms/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 2/50\n",
      "6043/6043 [==============================] - 34s 6ms/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 3/50\n",
      "6043/6043 [==============================] - 34s 6ms/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 4/50\n",
      "6043/6043 [==============================] - 34s 6ms/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 5/50\n",
      "6043/6043 [==============================] - 34s 6ms/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 6/50\n",
      "6043/6043 [==============================] - 34s 6ms/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 7/50\n",
      "6043/6043 [==============================] - 34s 6ms/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 8/50\n",
      "6043/6043 [==============================] - 35s 6ms/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 9/50\n",
      "6043/6043 [==============================] - 34s 6ms/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 10/50\n",
      "6043/6043 [==============================] - 34s 6ms/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 11/50\n",
      "6043/6043 [==============================] - 34s 6ms/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 12/50\n",
      "6043/6043 [==============================] - 34s 6ms/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 13/50\n",
      "6043/6043 [==============================] - 34s 6ms/step - loss: 0.0049 - val_loss: 0.0060\n",
      "Epoch 14/50\n",
      "6043/6043 [==============================] - 34s 6ms/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 15/50\n",
      "6043/6043 [==============================] - 34s 6ms/step - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 16/50\n",
      "6040/6043 [============================>.] - ETA: 0s - loss: 0.0048Restoring model weights from the end of the best epoch: 6.\n",
      "6043/6043 [==============================] - 34s 6ms/step - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 16: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BANDERA en clúster 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 1s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para BANDERA en clúster 3: 6387065.57637426, R2 Mensual: 0.8142002515233677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: BANDERA, cluster: 6\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 7s 1s/step - loss: 0.1547 - val_loss: 0.1427\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0978 - val_loss: 0.0799\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0316 - val_loss: 0.0404\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0045 - val_loss: 0.0154\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0055 - val_loss: 0.0013\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0134 - val_loss: 7.8219e-04\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0149 - val_loss: 6.5316e-04\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0138 - val_loss: 0.0017\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0090 - val_loss: 0.0040\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0044 - val_loss: 0.0068\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0022 - val_loss: 0.0106\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0156\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 3.7483e-04 - val_loss: 0.0201\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 7.4112e-04 - val_loss: 0.0240\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 6.8226e-04 - val_loss: 0.0266\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0013 - val_loss: 0.0285\n",
      "Epoch 18/50\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 4.7147e-05Restoring model weights from the end of the best epoch: 8.\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.0290\n",
      "Epoch 18: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BANDERA en clúster 6\n",
      "No se tienen datos suficientes para BANDERA en clúster 6 en los últimos seis meses de 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: BANDERA, cluster: 1\n",
      "Epoch 1/50\n",
      "847/847 [==============================] - 12s 7ms/step - loss: 0.0051 - val_loss: 0.0115\n",
      "Epoch 2/50\n",
      "847/847 [==============================] - 5s 6ms/step - loss: 0.0048 - val_loss: 0.0118\n",
      "Epoch 3/50\n",
      "847/847 [==============================] - 5s 6ms/step - loss: 0.0047 - val_loss: 0.0120\n",
      "Epoch 4/50\n",
      "847/847 [==============================] - 5s 6ms/step - loss: 0.0046 - val_loss: 0.0119\n",
      "Epoch 5/50\n",
      "847/847 [==============================] - 5s 6ms/step - loss: 0.0046 - val_loss: 0.0119\n",
      "Epoch 6/50\n",
      "847/847 [==============================] - 5s 6ms/step - loss: 0.0046 - val_loss: 0.0116\n",
      "Epoch 7/50\n",
      "847/847 [==============================] - 5s 6ms/step - loss: 0.0045 - val_loss: 0.0116\n",
      "Epoch 8/50\n",
      "847/847 [==============================] - 5s 6ms/step - loss: 0.0045 - val_loss: 0.0115\n",
      "Epoch 9/50\n",
      "847/847 [==============================] - 5s 6ms/step - loss: 0.0045 - val_loss: 0.0118\n",
      "Epoch 10/50\n",
      "847/847 [==============================] - 5s 6ms/step - loss: 0.0044 - val_loss: 0.0116\n",
      "Epoch 11/50\n",
      "847/847 [==============================] - 5s 6ms/step - loss: 0.0045 - val_loss: 0.0117\n",
      "Epoch 12/50\n",
      "847/847 [==============================] - 5s 6ms/step - loss: 0.0044 - val_loss: 0.0118\n",
      "Epoch 13/50\n",
      "847/847 [==============================] - 5s 6ms/step - loss: 0.0044 - val_loss: 0.0116\n",
      "Epoch 14/50\n",
      "847/847 [==============================] - 5s 6ms/step - loss: 0.0044 - val_loss: 0.0120\n",
      "Epoch 15/50\n",
      "847/847 [==============================] - 5s 6ms/step - loss: 0.0043 - val_loss: 0.0121\n",
      "Epoch 16/50\n",
      "847/847 [==============================] - 5s 6ms/step - loss: 0.0044 - val_loss: 0.0116\n",
      "Epoch 17/50\n",
      "847/847 [==============================] - 5s 6ms/step - loss: 0.0043 - val_loss: 0.0115\n",
      "Epoch 18/50\n",
      "847/847 [==============================] - 5s 6ms/step - loss: 0.0043 - val_loss: 0.0116\n",
      "Epoch 19/50\n",
      "847/847 [==============================] - 5s 6ms/step - loss: 0.0043 - val_loss: 0.0119\n",
      "Epoch 20/50\n",
      "847/847 [==============================] - 5s 6ms/step - loss: 0.0042 - val_loss: 0.0118\n",
      "Epoch 21/50\n",
      "847/847 [==============================] - 5s 6ms/step - loss: 0.0042 - val_loss: 0.0123\n",
      "Epoch 22/50\n",
      "847/847 [==============================] - 5s 6ms/step - loss: 0.0043 - val_loss: 0.0116\n",
      "Epoch 23/50\n",
      "847/847 [==============================] - 5s 6ms/step - loss: 0.0042 - val_loss: 0.0116\n",
      "Epoch 24/50\n",
      "847/847 [==============================] - 5s 6ms/step - loss: 0.0042 - val_loss: 0.0120\n",
      "Epoch 25/50\n",
      "847/847 [==============================] - 5s 6ms/step - loss: 0.0041 - val_loss: 0.0116\n",
      "Epoch 26/50\n",
      "847/847 [==============================] - 5s 6ms/step - loss: 0.0041 - val_loss: 0.0116\n",
      "Epoch 27/50\n",
      "842/847 [============================>.] - ETA: 0s - loss: 0.0042Restoring model weights from the end of the best epoch: 17.\n",
      "847/847 [==============================] - 5s 6ms/step - loss: 0.0041 - val_loss: 0.0117\n",
      "Epoch 27: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BANDERA en clúster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 5ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para BANDERA en clúster 1: 2433678.8089433736, R2 Mensual: 0.713005543258019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: BANDERA, cluster: 4\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 7s 258ms/step - loss: 0.0101 - val_loss: 0.4142\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0031 - val_loss: 0.4105\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0016 - val_loss: 0.4399\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 8.5232e-04 - val_loss: 0.4492\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 7.5688e-04 - val_loss: 0.4506\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 5.9852e-04 - val_loss: 0.4502\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.4380e-04 - val_loss: 0.4472\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.6507e-04 - val_loss: 0.4470\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.8021e-04 - val_loss: 0.4478\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.9111e-04 - val_loss: 0.4510\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.7106e-04 - val_loss: 0.4581\n",
      "Epoch 12/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0168e-05Restoring model weights from the end of the best epoch: 2.\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.4852e-04 - val_loss: 0.4599\n",
      "Epoch 12: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BANDERA en clúster 4\n",
      "No se tienen datos suficientes para BANDERA en clúster 4 en los últimos seis meses de 2023\n",
      "Training model for species: LANGOSTA, cluster: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "188/188 [==============================] - 8s 11ms/step - loss: 0.0527 - val_loss: 0.0259\n",
      "Epoch 2/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0422 - val_loss: 0.0256\n",
      "Epoch 3/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0373 - val_loss: 0.0221\n",
      "Epoch 4/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0411 - val_loss: 0.0223\n",
      "Epoch 5/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0369 - val_loss: 0.0319\n",
      "Epoch 6/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0373 - val_loss: 0.0244\n",
      "Epoch 7/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0368 - val_loss: 0.0229\n",
      "Epoch 8/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0348 - val_loss: 0.0494\n",
      "Epoch 9/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0369 - val_loss: 0.0292\n",
      "Epoch 10/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0336 - val_loss: 0.0317\n",
      "Epoch 11/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0338 - val_loss: 0.0341\n",
      "Epoch 12/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0327 - val_loss: 0.0243\n",
      "Epoch 13/50\n",
      "180/188 [===========================>..] - ETA: 0s - loss: 0.0329Restoring model weights from the end of the best epoch: 3.\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0323 - val_loss: 0.0300\n",
      "Epoch 13: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LANGOSTA en clúster 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 986ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "MSE Mensual para LANGOSTA en clúster 7: 118397.00986289665, R2 Mensual: -0.4439733769162122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: LANGOSTA, cluster: 3\n",
      "Epoch 1/50\n",
      "459/459 [==============================] - 10s 8ms/step - loss: 0.0143 - val_loss: 0.0127\n",
      "Epoch 2/50\n",
      "459/459 [==============================] - 3s 6ms/step - loss: 0.0139 - val_loss: 0.0113\n",
      "Epoch 3/50\n",
      "459/459 [==============================] - 3s 6ms/step - loss: 0.0134 - val_loss: 0.0153\n",
      "Epoch 4/50\n",
      "459/459 [==============================] - 3s 6ms/step - loss: 0.0137 - val_loss: 0.0124\n",
      "Epoch 5/50\n",
      "459/459 [==============================] - 3s 6ms/step - loss: 0.0134 - val_loss: 0.0131\n",
      "Epoch 6/50\n",
      "459/459 [==============================] - 3s 6ms/step - loss: 0.0134 - val_loss: 0.0123\n",
      "Epoch 7/50\n",
      "459/459 [==============================] - 3s 6ms/step - loss: 0.0135 - val_loss: 0.0123\n",
      "Epoch 8/50\n",
      "459/459 [==============================] - 3s 6ms/step - loss: 0.0134 - val_loss: 0.0117\n",
      "Epoch 9/50\n",
      "459/459 [==============================] - 3s 6ms/step - loss: 0.0134 - val_loss: 0.0114\n",
      "Epoch 10/50\n",
      "459/459 [==============================] - 3s 7ms/step - loss: 0.0132 - val_loss: 0.0113\n",
      "Epoch 11/50\n",
      "459/459 [==============================] - 3s 7ms/step - loss: 0.0133 - val_loss: 0.0120\n",
      "Epoch 12/50\n",
      "459/459 [==============================] - 3s 7ms/step - loss: 0.0134 - val_loss: 0.0116\n",
      "Epoch 13/50\n",
      "459/459 [==============================] - 3s 7ms/step - loss: 0.0133 - val_loss: 0.0118\n",
      "Epoch 14/50\n",
      "459/459 [==============================] - 3s 7ms/step - loss: 0.0132 - val_loss: 0.0117\n",
      "Epoch 15/50\n",
      "459/459 [==============================] - 3s 7ms/step - loss: 0.0132 - val_loss: 0.0115\n",
      "Epoch 16/50\n",
      "459/459 [==============================] - 3s 7ms/step - loss: 0.0133 - val_loss: 0.0124\n",
      "Epoch 17/50\n",
      "459/459 [==============================] - 3s 7ms/step - loss: 0.0131 - val_loss: 0.0116\n",
      "Epoch 18/50\n",
      "459/459 [==============================] - 3s 7ms/step - loss: 0.0132 - val_loss: 0.0112\n",
      "Epoch 19/50\n",
      "459/459 [==============================] - 3s 6ms/step - loss: 0.0131 - val_loss: 0.0118\n",
      "Epoch 20/50\n",
      "459/459 [==============================] - 3s 6ms/step - loss: 0.0133 - val_loss: 0.0113\n",
      "Epoch 21/50\n",
      "459/459 [==============================] - 3s 6ms/step - loss: 0.0132 - val_loss: 0.0118\n",
      "Epoch 22/50\n",
      "459/459 [==============================] - 3s 6ms/step - loss: 0.0132 - val_loss: 0.0113\n",
      "Epoch 23/50\n",
      "459/459 [==============================] - 3s 7ms/step - loss: 0.0132 - val_loss: 0.0113\n",
      "Epoch 24/50\n",
      "459/459 [==============================] - 3s 7ms/step - loss: 0.0132 - val_loss: 0.0112\n",
      "Epoch 25/50\n",
      "459/459 [==============================] - 3s 7ms/step - loss: 0.0132 - val_loss: 0.0113\n",
      "Epoch 26/50\n",
      "459/459 [==============================] - 3s 6ms/step - loss: 0.0132 - val_loss: 0.0109\n",
      "Epoch 27/50\n",
      "459/459 [==============================] - 3s 6ms/step - loss: 0.0132 - val_loss: 0.0118\n",
      "Epoch 28/50\n",
      "459/459 [==============================] - 3s 6ms/step - loss: 0.0131 - val_loss: 0.0115\n",
      "Epoch 29/50\n",
      "459/459 [==============================] - 3s 6ms/step - loss: 0.0132 - val_loss: 0.0110\n",
      "Epoch 30/50\n",
      "459/459 [==============================] - 3s 6ms/step - loss: 0.0132 - val_loss: 0.0113\n",
      "Epoch 31/50\n",
      "459/459 [==============================] - 3s 6ms/step - loss: 0.0131 - val_loss: 0.0112\n",
      "Epoch 32/50\n",
      "459/459 [==============================] - 3s 6ms/step - loss: 0.0131 - val_loss: 0.0112\n",
      "Epoch 33/50\n",
      "459/459 [==============================] - 3s 6ms/step - loss: 0.0130 - val_loss: 0.0119\n",
      "Epoch 34/50\n",
      "459/459 [==============================] - 3s 7ms/step - loss: 0.0131 - val_loss: 0.0112\n",
      "Epoch 35/50\n",
      "459/459 [==============================] - 3s 6ms/step - loss: 0.0129 - val_loss: 0.0124\n",
      "Epoch 36/50\n",
      "451/459 [============================>.] - ETA: 0s - loss: 0.0131Restoring model weights from the end of the best epoch: 26.\n",
      "459/459 [==============================] - 3s 6ms/step - loss: 0.0129 - val_loss: 0.0118\n",
      "Epoch 36: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LANGOSTA en clúster 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 6ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "MSE Mensual para LANGOSTA en clúster 3: 1184300.28012156, R2 Mensual: 0.6954390932451271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: LANGOSTA, cluster: 6\n",
      "Epoch 1/50\n",
      "159/159 [==============================] - 8s 13ms/step - loss: 0.0358 - val_loss: 0.0904\n",
      "Epoch 2/50\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.0314 - val_loss: 0.0865\n",
      "Epoch 3/50\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.0297 - val_loss: 0.0830\n",
      "Epoch 4/50\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.0308 - val_loss: 0.0845\n",
      "Epoch 5/50\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.0289 - val_loss: 0.0844\n",
      "Epoch 6/50\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.0293 - val_loss: 0.0889\n",
      "Epoch 7/50\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.0290 - val_loss: 0.0851\n",
      "Epoch 8/50\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.0289 - val_loss: 0.0843\n",
      "Epoch 9/50\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.0287 - val_loss: 0.0869\n",
      "Epoch 10/50\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.0281 - val_loss: 0.0880\n",
      "Epoch 11/50\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.0275 - val_loss: 0.0902\n",
      "Epoch 12/50\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.0288 - val_loss: 0.0881\n",
      "Epoch 13/50\n",
      "155/159 [============================>.] - ETA: 0s - loss: 0.0274Restoring model weights from the end of the best epoch: 3.\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.0279 - val_loss: 0.0872\n",
      "Epoch 13: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LANGOSTA en clúster 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 993ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "MSE Mensual para LANGOSTA en clúster 6: 1798084.0585934464, R2 Mensual: 0.6211194532005783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: LANGOSTA, cluster: 5\n",
      "Epoch 1/50\n",
      "96/96 [==============================] - 8s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 1s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 1s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 1s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 1s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 1s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 1s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 1s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 1s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "90/96 [===========================>..] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "96/96 [==============================] - 1s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LANGOSTA en clúster 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 958ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "MSE Mensual para LANGOSTA en clúster 5: 398731.25, R2 Mensual: -4.298424101488695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: LANGOSTA, cluster: 1\n",
      "Epoch 1/50\n",
      "54/54 [==============================] - 9s 27ms/step - loss: 0.1398 - val_loss: 0.1467\n",
      "Epoch 2/50\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.1116 - val_loss: 0.0785\n",
      "Epoch 3/50\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.1018 - val_loss: 0.0730\n",
      "Epoch 4/50\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0869 - val_loss: 0.0700\n",
      "Epoch 5/50\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0809 - val_loss: 0.0766\n",
      "Epoch 6/50\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0789 - val_loss: 0.0772\n",
      "Epoch 7/50\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0716 - val_loss: 0.0828\n",
      "Epoch 8/50\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0654 - val_loss: 0.0830\n",
      "Epoch 9/50\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0654 - val_loss: 0.0826\n",
      "Epoch 10/50\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0608 - val_loss: 0.0879\n",
      "Epoch 11/50\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0589 - val_loss: 0.1007\n",
      "Epoch 12/50\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0600 - val_loss: 0.0927\n",
      "Epoch 13/50\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0569 - val_loss: 0.1000\n",
      "Epoch 14/50\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.0503Restoring model weights from the end of the best epoch: 4.\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0542 - val_loss: 0.0988\n",
      "Epoch 14: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LANGOSTA en clúster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1000ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "MSE Mensual para LANGOSTA en clúster 1: 2437642.69630128, R2 Mensual: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n",
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/sklearn/metrics/_regression.py:1187: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: LANGOSTA, cluster: 4\n",
      "Epoch 1/50\n",
      "19/19 [==============================] - 7s 62ms/step - loss: 0.2433 - val_loss: 0.2022\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.1415 - val_loss: 0.1630\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.1292 - val_loss: 0.1561\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.1094 - val_loss: 0.1565\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.1041 - val_loss: 0.1504\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0970 - val_loss: 0.1566\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0920 - val_loss: 0.1751\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0897 - val_loss: 0.1727\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.1108 - val_loss: 0.1849\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.1026 - val_loss: 0.2099\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0861 - val_loss: 0.1733\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0848 - val_loss: 0.1730\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.0863 - val_loss: 0.1834\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.0834 - val_loss: 0.2024\n",
      "Epoch 15/50\n",
      "10/19 [==============>...............] - ETA: 0s - loss: 0.0814Restoring model weights from the end of the best epoch: 5.\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0770 - val_loss: 0.2088\n",
      "Epoch 15: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LANGOSTA en clúster 4\n",
      "No se tienen datos suficientes para LANGOSTA en clúster 4 en los últimos seis meses de 2023\n",
      "Training model for species: BERRUGATA, cluster: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3231/3231 [==============================] - 25s 6ms/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 2/50\n",
      "3231/3231 [==============================] - 19s 6ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 3/50\n",
      "3231/3231 [==============================] - 19s 6ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 4/50\n",
      "3231/3231 [==============================] - 19s 6ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 5/50\n",
      "3231/3231 [==============================] - 19s 6ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 6/50\n",
      "3231/3231 [==============================] - 19s 6ms/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 7/50\n",
      "3231/3231 [==============================] - 19s 6ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 8/50\n",
      "3231/3231 [==============================] - 18s 6ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 9/50\n",
      "3231/3231 [==============================] - 19s 6ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 10/50\n",
      "3231/3231 [==============================] - 19s 6ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 11/50\n",
      "3231/3231 [==============================] - 19s 6ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 12/50\n",
      "3231/3231 [==============================] - 19s 6ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 13/50\n",
      "3231/3231 [==============================] - 19s 6ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 14/50\n",
      "3231/3231 [==============================] - 19s 6ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 15/50\n",
      "3231/3231 [==============================] - 19s 6ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 16/50\n",
      "3231/3231 [==============================] - 19s 6ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 17/50\n",
      "3231/3231 [==============================] - 19s 6ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 18/50\n",
      "3231/3231 [==============================] - 20s 6ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 19/50\n",
      "3231/3231 [==============================] - 20s 6ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 20/50\n",
      "3231/3231 [==============================] - 20s 6ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 21/50\n",
      "3231/3231 [==============================] - 20s 6ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 22/50\n",
      "3231/3231 [==============================] - 20s 6ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 23/50\n",
      "3231/3231 [==============================] - 20s 6ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 24/50\n",
      "3231/3231 [==============================] - 19s 6ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 25/50\n",
      "3231/3231 [==============================] - 20s 6ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 26/50\n",
      "3231/3231 [==============================] - 20s 6ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 27/50\n",
      "3231/3231 [==============================] - 20s 6ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 28/50\n",
      "3231/3231 [==============================] - 20s 6ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 29/50\n",
      "3231/3231 [==============================] - 20s 6ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 30/50\n",
      "3231/3231 [==============================] - 20s 6ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 31/50\n",
      "3231/3231 [==============================] - 20s 6ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 32/50\n",
      "3231/3231 [==============================] - 19s 6ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 33/50\n",
      "3231/3231 [==============================] - 19s 6ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 34/50\n",
      "3231/3231 [==============================] - 20s 6ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 35/50\n",
      "3231/3231 [==============================] - 20s 6ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 36/50\n",
      "3231/3231 [==============================] - 20s 6ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 37/50\n",
      "3231/3231 [==============================] - 20s 6ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 38/50\n",
      "3231/3231 [==============================] - 19s 6ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 39/50\n",
      "3231/3231 [==============================] - 19s 6ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 40/50\n",
      "3231/3231 [==============================] - 19s 6ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 41/50\n",
      "3228/3231 [============================>.] - ETA: 0s - loss: 0.0037Restoring model weights from the end of the best epoch: 31.\n",
      "3231/3231 [==============================] - 19s 6ms/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 41: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BERRUGATA en clúster 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para BERRUGATA en clúster 7: 1695715.0201626215, R2 Mensual: 0.9423874760525713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: BERRUGATA, cluster: 0\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 8s 152ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "1/8 [==>...........................] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "8/8 [==============================] - 0s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BERRUGATA en clúster 0\n",
      "No se tienen datos suficientes para BERRUGATA en clúster 0 en los últimos seis meses de 2023\n",
      "Training model for species: BERRUGATA, cluster: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7143/7143 [==============================] - 50s 6ms/step - loss: 0.0024 - val_loss: 8.7545e-04\n",
      "Epoch 2/50\n",
      "7143/7143 [==============================] - 42s 6ms/step - loss: 0.0021 - val_loss: 9.1908e-04\n",
      "Epoch 3/50\n",
      "7143/7143 [==============================] - 43s 6ms/step - loss: 0.0021 - val_loss: 8.3113e-04\n",
      "Epoch 4/50\n",
      "7143/7143 [==============================] - 42s 6ms/step - loss: 0.0021 - val_loss: 7.8554e-04\n",
      "Epoch 5/50\n",
      "7143/7143 [==============================] - 43s 6ms/step - loss: 0.0020 - val_loss: 8.1479e-04\n",
      "Epoch 6/50\n",
      "7143/7143 [==============================] - 43s 6ms/step - loss: 0.0020 - val_loss: 8.2899e-04\n",
      "Epoch 7/50\n",
      "7143/7143 [==============================] - 42s 6ms/step - loss: 0.0020 - val_loss: 8.0274e-04\n",
      "Epoch 8/50\n",
      "7143/7143 [==============================] - 42s 6ms/step - loss: 0.0020 - val_loss: 9.1523e-04\n",
      "Epoch 9/50\n",
      "7143/7143 [==============================] - 42s 6ms/step - loss: 0.0019 - val_loss: 7.6724e-04\n",
      "Epoch 10/50\n",
      "7143/7143 [==============================] - 44s 6ms/step - loss: 0.0020 - val_loss: 7.9059e-04\n",
      "Epoch 11/50\n",
      "7143/7143 [==============================] - 46s 6ms/step - loss: 0.0020 - val_loss: 8.2062e-04\n",
      "Epoch 12/50\n",
      "7143/7143 [==============================] - 42s 6ms/step - loss: 0.0020 - val_loss: 8.6585e-04\n",
      "Epoch 13/50\n",
      "7143/7143 [==============================] - 41s 6ms/step - loss: 0.0020 - val_loss: 8.2633e-04\n",
      "Epoch 14/50\n",
      "7143/7143 [==============================] - 41s 6ms/step - loss: 0.0020 - val_loss: 7.7061e-04\n",
      "Epoch 15/50\n",
      "7143/7143 [==============================] - 41s 6ms/step - loss: 0.0020 - val_loss: 7.8427e-04\n",
      "Epoch 16/50\n",
      "7143/7143 [==============================] - 41s 6ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 17/50\n",
      "7143/7143 [==============================] - 41s 6ms/step - loss: 0.0020 - val_loss: 9.0593e-04\n",
      "Epoch 18/50\n",
      "7143/7143 [==============================] - 41s 6ms/step - loss: 0.0019 - val_loss: 7.8933e-04\n",
      "Epoch 19/50\n",
      "7143/7143 [==============================] - ETA: 0s - loss: 0.0019Restoring model weights from the end of the best epoch: 9.\n",
      "7143/7143 [==============================] - 41s 6ms/step - loss: 0.0019 - val_loss: 8.5014e-04\n",
      "Epoch 19: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BERRUGATA en clúster 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 1s 4ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para BERRUGATA en clúster 3: 52676967.43226596, R2 Mensual: 0.7954683997020531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: BERRUGATA, cluster: 6\n",
      "Epoch 1/50\n",
      "3978/3978 [==============================] - 30s 6ms/step - loss: 0.0086 - val_loss: 0.0106\n",
      "Epoch 2/50\n",
      "3978/3978 [==============================] - 23s 6ms/step - loss: 0.0076 - val_loss: 0.0105\n",
      "Epoch 3/50\n",
      "3978/3978 [==============================] - 23s 6ms/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 4/50\n",
      "3978/3978 [==============================] - 24s 6ms/step - loss: 0.0074 - val_loss: 0.0108\n",
      "Epoch 5/50\n",
      "3978/3978 [==============================] - 24s 6ms/step - loss: 0.0073 - val_loss: 0.0107\n",
      "Epoch 6/50\n",
      "3978/3978 [==============================] - 25s 6ms/step - loss: 0.0072 - val_loss: 0.0112\n",
      "Epoch 7/50\n",
      "3978/3978 [==============================] - 24s 6ms/step - loss: 0.0072 - val_loss: 0.0103\n",
      "Epoch 8/50\n",
      "3978/3978 [==============================] - 25s 6ms/step - loss: 0.0072 - val_loss: 0.0117\n",
      "Epoch 9/50\n",
      "3978/3978 [==============================] - 24s 6ms/step - loss: 0.0071 - val_loss: 0.0109\n",
      "Epoch 10/50\n",
      "3978/3978 [==============================] - 25s 6ms/step - loss: 0.0071 - val_loss: 0.0120\n",
      "Epoch 11/50\n",
      "3978/3978 [==============================] - 24s 6ms/step - loss: 0.0071 - val_loss: 0.0108\n",
      "Epoch 12/50\n",
      "3978/3978 [==============================] - 23s 6ms/step - loss: 0.0071 - val_loss: 0.0108\n",
      "Epoch 13/50\n",
      "3971/3978 [============================>.] - ETA: 0s - loss: 0.0070Restoring model weights from the end of the best epoch: 3.\n",
      "3978/3978 [==============================] - 23s 6ms/step - loss: 0.0070 - val_loss: 0.0109\n",
      "Epoch 13: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BERRUGATA en clúster 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para BERRUGATA en clúster 6: 9008631111.96653, R2 Mensual: 0.9716879901862207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: BERRUGATA, cluster: 5\n",
      "Epoch 1/50\n",
      "368/368 [==============================] - 9s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "368/368 [==============================] - 2s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "368/368 [==============================] - 2s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "368/368 [==============================] - 2s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "368/368 [==============================] - 2s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "368/368 [==============================] - 2s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "368/368 [==============================] - 2s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "368/368 [==============================] - 2s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "368/368 [==============================] - 2s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "360/368 [============================>.] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "368/368 [==============================] - 2s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BERRUGATA en clúster 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 5ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para BERRUGATA en clúster 5: 84206073023.18182, R2 Mensual: -0.3333463951061608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: BERRUGATA, cluster: 2\n",
      "Error entrenando el modelo para especie: BERRUGATA, clúster: 2. Error: tuple index out of range\n",
      "Training model for species: BERRUGATA, cluster: 1\n",
      "Epoch 1/50\n",
      "3777/3777 [==============================] - 32s 7ms/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 2/50\n",
      "3777/3777 [==============================] - 23s 6ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 3/50\n",
      "3777/3777 [==============================] - 23s 6ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 4/50\n",
      "3777/3777 [==============================] - 23s 6ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 5/50\n",
      "3777/3777 [==============================] - 24s 6ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 6/50\n",
      "3777/3777 [==============================] - 23s 6ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 7/50\n",
      "3777/3777 [==============================] - 22s 6ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 8/50\n",
      "3777/3777 [==============================] - 24s 6ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 9/50\n",
      "3777/3777 [==============================] - 24s 6ms/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 10/50\n",
      "3777/3777 [==============================] - 23s 6ms/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 11/50\n",
      "3777/3777 [==============================] - 22s 6ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 12/50\n",
      "3777/3777 [==============================] - 22s 6ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 13/50\n",
      "3777/3777 [==============================] - 23s 6ms/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 14/50\n",
      "3777/3777 [==============================] - 23s 6ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 15/50\n",
      "3777/3777 [==============================] - 23s 6ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 16/50\n",
      "3777/3777 [==============================] - 23s 6ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 17/50\n",
      "3777/3777 [==============================] - 22s 6ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 18/50\n",
      "3768/3777 [============================>.] - ETA: 0s - loss: 0.0042Restoring model weights from the end of the best epoch: 8.\n",
      "3777/3777 [==============================] - 21s 6ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 18: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BERRUGATA en clúster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para BERRUGATA en clúster 1: 802462786.3553718, R2 Mensual: 0.9188174117489087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: BERRUGATA, cluster: 4\n",
      "Epoch 1/50\n",
      "10/10 [==============================] - 7s 118ms/step - loss: 0.1483 - val_loss: 0.3547\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0926 - val_loss: 0.3344\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0856 - val_loss: 0.3095\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0742 - val_loss: 0.2881\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0653 - val_loss: 0.2720\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0647 - val_loss: 0.2648\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0611 - val_loss: 0.2648\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0571 - val_loss: 0.2667\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0515 - val_loss: 0.2631\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0493 - val_loss: 0.2656\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0473 - val_loss: 0.2792\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0454 - val_loss: 0.2747\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0415 - val_loss: 0.2839\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0449 - val_loss: 0.2984\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0375 - val_loss: 0.3012\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0384 - val_loss: 0.3017\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0363 - val_loss: 0.3070\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0356 - val_loss: 0.3093\n",
      "Epoch 19/50\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0172Restoring model weights from the end of the best epoch: 9.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0355 - val_loss: 0.3109\n",
      "Epoch 19: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BERRUGATA en clúster 4\n",
      "No se tienen datos suficientes para BERRUGATA en clúster 4 en los últimos seis meses de 2023\n",
      "Training model for species: ROBALO, cluster: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12775/12775 [==============================] - 80s 6ms/step - loss: 6.3667e-04 - val_loss: 8.1846e-04\n",
      "Epoch 2/50\n",
      "12775/12775 [==============================] - 73s 6ms/step - loss: 6.2306e-04 - val_loss: 7.8690e-04\n",
      "Epoch 3/50\n",
      "12775/12775 [==============================] - 74s 6ms/step - loss: 6.0715e-04 - val_loss: 7.1291e-04\n",
      "Epoch 4/50\n",
      "12775/12775 [==============================] - 75s 6ms/step - loss: 5.5098e-04 - val_loss: 6.6899e-04\n",
      "Epoch 5/50\n",
      "12775/12775 [==============================] - 76s 6ms/step - loss: 5.3471e-04 - val_loss: 7.1181e-04\n",
      "Epoch 6/50\n",
      "12775/12775 [==============================] - 76s 6ms/step - loss: 5.3387e-04 - val_loss: 6.4205e-04\n",
      "Epoch 7/50\n",
      "12775/12775 [==============================] - 76s 6ms/step - loss: 5.2232e-04 - val_loss: 6.3706e-04\n",
      "Epoch 8/50\n",
      "12775/12775 [==============================] - 74s 6ms/step - loss: 5.3294e-04 - val_loss: 6.8611e-04\n",
      "Epoch 9/50\n",
      "12775/12775 [==============================] - 74s 6ms/step - loss: 5.2299e-04 - val_loss: 7.1114e-04\n",
      "Epoch 10/50\n",
      "12775/12775 [==============================] - 74s 6ms/step - loss: 5.2147e-04 - val_loss: 6.4476e-04\n",
      "Epoch 11/50\n",
      "12775/12775 [==============================] - 73s 6ms/step - loss: 5.2588e-04 - val_loss: 6.7592e-04\n",
      "Epoch 12/50\n",
      "12775/12775 [==============================] - 73s 6ms/step - loss: 5.1943e-04 - val_loss: 7.6971e-04\n",
      "Epoch 13/50\n",
      "12775/12775 [==============================] - 72s 6ms/step - loss: 5.2190e-04 - val_loss: 6.7336e-04\n",
      "Epoch 14/50\n",
      "12775/12775 [==============================] - 74s 6ms/step - loss: 5.2074e-04 - val_loss: 6.7572e-04\n",
      "Epoch 15/50\n",
      "12775/12775 [==============================] - 75s 6ms/step - loss: 5.2189e-04 - val_loss: 7.1039e-04\n",
      "Epoch 16/50\n",
      "12775/12775 [==============================] - 72s 6ms/step - loss: 5.1987e-04 - val_loss: 6.7198e-04\n",
      "Epoch 17/50\n",
      "12770/12775 [============================>.] - ETA: 0s - loss: 5.1525e-04Restoring model weights from the end of the best epoch: 7.\n",
      "12775/12775 [==============================] - 72s 6ms/step - loss: 5.1507e-04 - val_loss: 8.0773e-04\n",
      "Epoch 17: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para ROBALO en clúster 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para ROBALO en clúster 7: 11225626.379080748, R2 Mensual: 0.7933037285055675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: ROBALO, cluster: 0\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 7s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "112/112 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para ROBALO en clúster 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 7ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "MSE Mensual para ROBALO en clúster 0: 8271745.0, R2 Mensual: -2.672931201129266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: ROBALO, cluster: 3\n",
      "Epoch 1/50\n",
      "3492/3492 [==============================] - 27s 6ms/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 2/50\n",
      "3492/3492 [==============================] - 20s 6ms/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 3/50\n",
      "3492/3492 [==============================] - 20s 6ms/step - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 4/50\n",
      "3492/3492 [==============================] - 20s 6ms/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 5/50\n",
      "3492/3492 [==============================] - 20s 6ms/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 6/50\n",
      "3492/3492 [==============================] - 20s 6ms/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 7/50\n",
      "3492/3492 [==============================] - 20s 6ms/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 8/50\n",
      "3492/3492 [==============================] - 20s 6ms/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 9/50\n",
      "3492/3492 [==============================] - 20s 6ms/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 10/50\n",
      "3492/3492 [==============================] - 20s 6ms/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 11/50\n",
      "3492/3492 [==============================] - 20s 6ms/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 12/50\n",
      "3492/3492 [==============================] - 20s 6ms/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 13/50\n",
      "3492/3492 [==============================] - 20s 6ms/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 14/50\n",
      "3492/3492 [==============================] - 20s 6ms/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 15/50\n",
      "3491/3492 [============================>.] - ETA: 0s - loss: 0.0029Restoring model weights from the end of the best epoch: 5.\n",
      "3492/3492 [==============================] - 20s 6ms/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 15: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para ROBALO en clúster 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 2s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para ROBALO en clúster 3: 27000751.53368775, R2 Mensual: 0.7895985871590403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: ROBALO, cluster: 6\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 7s 36ms/step - loss: 0.0632 - val_loss: 0.0061\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0561 - val_loss: 0.0070\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0519 - val_loss: 0.0072\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0486 - val_loss: 0.0083\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0473 - val_loss: 0.0092\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0440 - val_loss: 0.0096\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0419 - val_loss: 0.0131\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0399 - val_loss: 0.0100\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0383 - val_loss: 0.0135\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0357 - val_loss: 0.0102\n",
      "Epoch 11/50\n",
      "31/36 [========================>.....] - ETA: 0s - loss: 0.0385Restoring model weights from the end of the best epoch: 1.\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0352 - val_loss: 0.0136\n",
      "Epoch 11: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para ROBALO en clúster 6\n",
      "No se tienen datos suficientes para ROBALO en clúster 6 en los últimos seis meses de 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: ROBALO, cluster: 1\n",
      "Epoch 1/50\n",
      "1930/1930 [==============================] - 18s 6ms/step - loss: 0.0016 - val_loss: 5.5420e-04\n",
      "Epoch 2/50\n",
      "1930/1930 [==============================] - 11s 6ms/step - loss: 0.0015 - val_loss: 6.3564e-04\n",
      "Epoch 3/50\n",
      "1930/1930 [==============================] - 11s 6ms/step - loss: 0.0014 - val_loss: 5.5520e-04\n",
      "Epoch 4/50\n",
      "1930/1930 [==============================] - 11s 6ms/step - loss: 0.0015 - val_loss: 5.5061e-04\n",
      "Epoch 5/50\n",
      "1930/1930 [==============================] - 11s 6ms/step - loss: 0.0014 - val_loss: 5.7721e-04\n",
      "Epoch 6/50\n",
      "1930/1930 [==============================] - 11s 6ms/step - loss: 0.0014 - val_loss: 5.5002e-04\n",
      "Epoch 7/50\n",
      "1930/1930 [==============================] - 11s 6ms/step - loss: 0.0014 - val_loss: 5.8761e-04\n",
      "Epoch 8/50\n",
      "1930/1930 [==============================] - 11s 6ms/step - loss: 0.0014 - val_loss: 6.2242e-04\n",
      "Epoch 9/50\n",
      "1930/1930 [==============================] - 11s 6ms/step - loss: 0.0014 - val_loss: 5.7444e-04\n",
      "Epoch 10/50\n",
      "1930/1930 [==============================] - 12s 6ms/step - loss: 0.0014 - val_loss: 5.5420e-04\n",
      "Epoch 11/50\n",
      "1930/1930 [==============================] - 12s 6ms/step - loss: 0.0014 - val_loss: 5.5872e-04\n",
      "Epoch 12/50\n",
      "1930/1930 [==============================] - 11s 6ms/step - loss: 0.0014 - val_loss: 5.6339e-04\n",
      "Epoch 13/50\n",
      "1930/1930 [==============================] - 11s 6ms/step - loss: 0.0014 - val_loss: 5.9162e-04\n",
      "Epoch 14/50\n",
      "1930/1930 [==============================] - 12s 6ms/step - loss: 0.0014 - val_loss: 5.8486e-04\n",
      "Epoch 15/50\n",
      "1930/1930 [==============================] - 12s 6ms/step - loss: 0.0014 - val_loss: 5.9887e-04\n",
      "Epoch 16/50\n",
      "1927/1930 [============================>.] - ETA: 0s - loss: 0.0014Restoring model weights from the end of the best epoch: 6.\n",
      "1930/1930 [==============================] - 11s 6ms/step - loss: 0.0014 - val_loss: 5.7854e-04\n",
      "Epoch 16: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para ROBALO en clúster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para ROBALO en clúster 1: 3391052.2954197912, R2 Mensual: 0.3944290144800435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: ROBALO, cluster: 4\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 7s 129ms/step - loss: 0.2437 - val_loss: 0.3260\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1169 - val_loss: 0.2514\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0394 - val_loss: 0.2404\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0277 - val_loss: 0.2509\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0256 - val_loss: 0.2615\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0185 - val_loss: 0.2567\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0177 - val_loss: 0.2542\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.2528\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0205 - val_loss: 0.2514\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.2579\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0192 - val_loss: 0.2647\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.2624\n",
      "Epoch 13/50\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 4.8879e-05Restoring model weights from the end of the best epoch: 3.\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0158 - val_loss: 0.2576\n",
      "Epoch 13: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para ROBALO en clúster 4\n",
      "No se tienen datos suficientes para ROBALO en clúster 4 en los últimos seis meses de 2023\n",
      "Training model for species: BAQUETA, cluster: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "196/196 [==============================] - 8s 12ms/step - loss: 0.0066 - val_loss: 0.0014\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0061 - val_loss: 0.0015\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0061 - val_loss: 0.0014\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0059 - val_loss: 0.0014\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0059 - val_loss: 0.0014\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0022\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0014\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0015\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0014\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0014\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0056 - val_loss: 0.0016\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0056 - val_loss: 0.0014\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0017\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0056 - val_loss: 0.0015\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0017\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0056 - val_loss: 0.0016\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0014\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0056 - val_loss: 0.0015\n",
      "Epoch 19/50\n",
      "190/196 [============================>.] - ETA: 0s - loss: 0.0056Restoring model weights from the end of the best epoch: 9.\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0014\n",
      "Epoch 19: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BAQUETA en clúster 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 929ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "MSE Mensual para BAQUETA en clúster 7: 166401.37338409797, R2 Mensual: -2.7198055743441483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: BAQUETA, cluster: 3\n",
      "Epoch 1/50\n",
      "3809/3809 [==============================] - 28s 6ms/step - loss: 0.0021 - val_loss: 9.2929e-04\n",
      "Epoch 2/50\n",
      "3809/3809 [==============================] - 22s 6ms/step - loss: 0.0017 - val_loss: 8.5257e-04\n",
      "Epoch 3/50\n",
      "3809/3809 [==============================] - 22s 6ms/step - loss: 0.0017 - val_loss: 9.1682e-04\n",
      "Epoch 4/50\n",
      "3809/3809 [==============================] - 22s 6ms/step - loss: 0.0017 - val_loss: 8.0607e-04\n",
      "Epoch 5/50\n",
      "3809/3809 [==============================] - 22s 6ms/step - loss: 0.0016 - val_loss: 7.9746e-04\n",
      "Epoch 6/50\n",
      "3809/3809 [==============================] - 22s 6ms/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 7/50\n",
      "3809/3809 [==============================] - 22s 6ms/step - loss: 0.0017 - val_loss: 8.7112e-04\n",
      "Epoch 8/50\n",
      "3809/3809 [==============================] - 22s 6ms/step - loss: 0.0017 - val_loss: 8.0026e-04\n",
      "Epoch 9/50\n",
      "3809/3809 [==============================] - 22s 6ms/step - loss: 0.0016 - val_loss: 8.7541e-04\n",
      "Epoch 10/50\n",
      "3809/3809 [==============================] - 22s 6ms/step - loss: 0.0016 - val_loss: 9.5861e-04\n",
      "Epoch 11/50\n",
      "3809/3809 [==============================] - 22s 6ms/step - loss: 0.0016 - val_loss: 8.1302e-04\n",
      "Epoch 12/50\n",
      "3809/3809 [==============================] - 22s 6ms/step - loss: 0.0016 - val_loss: 8.0713e-04\n",
      "Epoch 13/50\n",
      "3809/3809 [==============================] - 22s 6ms/step - loss: 0.0016 - val_loss: 8.4616e-04\n",
      "Epoch 14/50\n",
      "3809/3809 [==============================] - 22s 6ms/step - loss: 0.0016 - val_loss: 8.3197e-04\n",
      "Epoch 15/50\n",
      "3807/3809 [============================>.] - ETA: 0s - loss: 0.0016Restoring model weights from the end of the best epoch: 5.\n",
      "3809/3809 [==============================] - 22s 6ms/step - loss: 0.0016 - val_loss: 8.0134e-04\n",
      "Epoch 15: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BAQUETA en clúster 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para BAQUETA en clúster 3: 53274498.40412819, R2 Mensual: 0.5770780344049351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: BAQUETA, cluster: 6\n",
      "Epoch 1/50\n",
      "4692/4692 [==============================] - 34s 6ms/step - loss: 0.0149 - val_loss: 0.0068\n",
      "Epoch 2/50\n",
      "4692/4692 [==============================] - 27s 6ms/step - loss: 0.0143 - val_loss: 0.0065\n",
      "Epoch 3/50\n",
      "4692/4692 [==============================] - 27s 6ms/step - loss: 0.0141 - val_loss: 0.0100\n",
      "Epoch 4/50\n",
      "4692/4692 [==============================] - 27s 6ms/step - loss: 0.0139 - val_loss: 0.0072\n",
      "Epoch 5/50\n",
      "4692/4692 [==============================] - 27s 6ms/step - loss: 0.0139 - val_loss: 0.0076\n",
      "Epoch 6/50\n",
      "4692/4692 [==============================] - 27s 6ms/step - loss: 0.0137 - val_loss: 0.0068\n",
      "Epoch 7/50\n",
      "4692/4692 [==============================] - 27s 6ms/step - loss: 0.0137 - val_loss: 0.0068\n",
      "Epoch 8/50\n",
      "4692/4692 [==============================] - 27s 6ms/step - loss: 0.0136 - val_loss: 0.0064\n",
      "Epoch 9/50\n",
      "4692/4692 [==============================] - 27s 6ms/step - loss: 0.0137 - val_loss: 0.0063\n",
      "Epoch 10/50\n",
      "4692/4692 [==============================] - 28s 6ms/step - loss: 0.0137 - val_loss: 0.0065\n",
      "Epoch 11/50\n",
      "4692/4692 [==============================] - 28s 6ms/step - loss: 0.0136 - val_loss: 0.0061\n",
      "Epoch 12/50\n",
      "4692/4692 [==============================] - 28s 6ms/step - loss: 0.0135 - val_loss: 0.0064\n",
      "Epoch 13/50\n",
      "4692/4692 [==============================] - 28s 6ms/step - loss: 0.0136 - val_loss: 0.0062\n",
      "Epoch 14/50\n",
      "4692/4692 [==============================] - 28s 6ms/step - loss: 0.0136 - val_loss: 0.0064\n",
      "Epoch 15/50\n",
      "4692/4692 [==============================] - 28s 6ms/step - loss: 0.0135 - val_loss: 0.0062\n",
      "Epoch 16/50\n",
      "4692/4692 [==============================] - 27s 6ms/step - loss: 0.0137 - val_loss: 0.0064\n",
      "Epoch 17/50\n",
      "4692/4692 [==============================] - 28s 6ms/step - loss: 0.0135 - val_loss: 0.0065\n",
      "Epoch 18/50\n",
      "4692/4692 [==============================] - 28s 6ms/step - loss: 0.0134 - val_loss: 0.0063\n",
      "Epoch 19/50\n",
      "4692/4692 [==============================] - 27s 6ms/step - loss: 0.0134 - val_loss: 0.0065\n",
      "Epoch 20/50\n",
      "4692/4692 [==============================] - 27s 6ms/step - loss: 0.0134 - val_loss: 0.0063\n",
      "Epoch 21/50\n",
      "4688/4692 [============================>.] - ETA: 0s - loss: 0.0135Restoring model weights from the end of the best epoch: 11.\n",
      "4692/4692 [==============================] - 27s 6ms/step - loss: 0.0135 - val_loss: 0.0064\n",
      "Epoch 21: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BAQUETA en clúster 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para BAQUETA en clúster 6: 41847132.18447862, R2 Mensual: 0.9689949839935972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: BAQUETA, cluster: 5\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 7s 506ms/step - loss: 0.0110 - val_loss: 0.0967\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0119 - val_loss: 0.0748\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0076 - val_loss: 0.0709\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0064 - val_loss: 0.0685\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0042 - val_loss: 0.0712\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0036 - val_loss: 0.0735\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0027 - val_loss: 0.0742\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0023 - val_loss: 0.0750\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0020 - val_loss: 0.0696\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0014 - val_loss: 0.0652\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 9.1751e-04 - val_loss: 0.0632\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 6.5617e-04 - val_loss: 0.0625\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.3649e-04 - val_loss: 0.0611\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.9527e-04 - val_loss: 0.0601\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 9.1048e-05 - val_loss: 0.0589\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 2.6754e-05 - val_loss: 0.0581\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.2835e-05 - val_loss: 0.0580\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.4283e-05 - val_loss: 0.0574\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.4734e-06 - val_loss: 0.0565\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.4020e-05 - val_loss: 0.0560\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.8451e-05 - val_loss: 0.0555\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 2.3055e-05 - val_loss: 0.0553\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 4.1847e-05 - val_loss: 0.0561\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.8039e-06 - val_loss: 0.0564\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.4190e-05 - val_loss: 0.0565\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 4.5238e-06 - val_loss: 0.0568\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.3470e-06 - val_loss: 0.0568\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.1650e-06 - val_loss: 0.0563\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 4.3104e-06 - val_loss: 0.0563\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.4234e-05 - val_loss: 0.0563\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.4457e-06 - val_loss: 0.0570\n",
      "Epoch 32/50\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.0716e-06Restoring model weights from the end of the best epoch: 22.\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0002e-05 - val_loss: 0.0576\n",
      "Epoch 32: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BAQUETA en clúster 5\n",
      "Error entrenando el modelo para especie: BAQUETA, clúster: 5. Error: tuple index out of range\n",
      "Training model for species: BAQUETA, cluster: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 7s 53ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "21/23 [==========================>...] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "23/23 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BAQUETA en clúster 2\n",
      "No se tienen datos suficientes para BAQUETA en clúster 2 en los últimos seis meses de 2023\n",
      "Training model for species: BAQUETA, cluster: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5121/5121 [==============================] - 37s 6ms/step - loss: 0.0065 - val_loss: 0.0043\n",
      "Epoch 2/50\n",
      "5121/5121 [==============================] - 30s 6ms/step - loss: 0.0063 - val_loss: 0.0042\n",
      "Epoch 3/50\n",
      "5121/5121 [==============================] - 30s 6ms/step - loss: 0.0061 - val_loss: 0.0041\n",
      "Epoch 4/50\n",
      "5121/5121 [==============================] - 29s 6ms/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 5/50\n",
      "5121/5121 [==============================] - 30s 6ms/step - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 6/50\n",
      "5121/5121 [==============================] - 29s 6ms/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 7/50\n",
      "5121/5121 [==============================] - 30s 6ms/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 8/50\n",
      "5121/5121 [==============================] - 30s 6ms/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 9/50\n",
      "5121/5121 [==============================] - 30s 6ms/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 10/50\n",
      "5121/5121 [==============================] - 30s 6ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 11/50\n",
      "5121/5121 [==============================] - 30s 6ms/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 12/50\n",
      "5121/5121 [==============================] - 30s 6ms/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 13/50\n",
      "5121/5121 [==============================] - 30s 6ms/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 14/50\n",
      "5121/5121 [==============================] - 30s 6ms/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 15/50\n",
      "5121/5121 [==============================] - 30s 6ms/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 16/50\n",
      "5121/5121 [==============================] - 29s 6ms/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 17/50\n",
      "5121/5121 [==============================] - 29s 6ms/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 18/50\n",
      "5121/5121 [==============================] - 29s 6ms/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 19/50\n",
      "5121/5121 [==============================] - 29s 6ms/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 20/50\n",
      "5121/5121 [==============================] - 29s 6ms/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 21/50\n",
      "5121/5121 [==============================] - 29s 6ms/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 22/50\n",
      "5121/5121 [==============================] - 29s 6ms/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 23/50\n",
      "5121/5121 [==============================] - 29s 6ms/step - loss: 0.0057 - val_loss: 0.0040\n",
      "Epoch 24/50\n",
      "5121/5121 [==============================] - 30s 6ms/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 25/50\n",
      "5121/5121 [==============================] - 30s 6ms/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 26/50\n",
      "5121/5121 [==============================] - 30s 6ms/step - loss: 0.0057 - val_loss: 0.0040\n",
      "Epoch 27/50\n",
      "5121/5121 [==============================] - 30s 6ms/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 28/50\n",
      "5120/5121 [============================>.] - ETA: 0s - loss: 0.0057Restoring model weights from the end of the best epoch: 18.\n",
      "5121/5121 [==============================] - 30s 6ms/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 28: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BAQUETA en clúster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 1s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para BAQUETA en clúster 1: 113566086.07305433, R2 Mensual: 0.6260091899821781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: BAQUETA, cluster: 4\n",
      "Epoch 1/50\n",
      "10/10 [==============================] - 7s 117ms/step - loss: 0.0624 - val_loss: 0.3241\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 0.2630\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.2830\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.3041\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.2916\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0073 - val_loss: 0.2648\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.2749\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.2793\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0047 - val_loss: 0.2786\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.2808\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.2860\n",
      "Epoch 12/50\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 8.1611e-04Restoring model weights from the end of the best epoch: 2.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0037 - val_loss: 0.2743\n",
      "Epoch 12: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BAQUETA en clúster 4\n",
      "No se tienen datos suficientes para BAQUETA en clúster 4 en los últimos seis meses de 2023\n",
      "Training model for species: LENGUADO, cluster: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "301/301 [==============================] - 9s 9ms/step - loss: 0.0126 - val_loss: 0.0079\n",
      "Epoch 2/50\n",
      "301/301 [==============================] - 2s 6ms/step - loss: 0.0107 - val_loss: 0.0082\n",
      "Epoch 3/50\n",
      "301/301 [==============================] - 2s 6ms/step - loss: 0.0107 - val_loss: 0.0100\n",
      "Epoch 4/50\n",
      "301/301 [==============================] - 2s 6ms/step - loss: 0.0106 - val_loss: 0.0080\n",
      "Epoch 5/50\n",
      "301/301 [==============================] - 2s 6ms/step - loss: 0.0106 - val_loss: 0.0077\n",
      "Epoch 6/50\n",
      "301/301 [==============================] - 2s 6ms/step - loss: 0.0105 - val_loss: 0.0080\n",
      "Epoch 7/50\n",
      "301/301 [==============================] - 2s 6ms/step - loss: 0.0104 - val_loss: 0.0080\n",
      "Epoch 8/50\n",
      "301/301 [==============================] - 2s 6ms/step - loss: 0.0105 - val_loss: 0.0078\n",
      "Epoch 9/50\n",
      "301/301 [==============================] - 2s 6ms/step - loss: 0.0101 - val_loss: 0.0078\n",
      "Epoch 10/50\n",
      "301/301 [==============================] - 2s 6ms/step - loss: 0.0104 - val_loss: 0.0079\n",
      "Epoch 11/50\n",
      "301/301 [==============================] - 2s 6ms/step - loss: 0.0104 - val_loss: 0.0078\n",
      "Epoch 12/50\n",
      "301/301 [==============================] - 2s 6ms/step - loss: 0.0103 - val_loss: 0.0078\n",
      "Epoch 13/50\n",
      "301/301 [==============================] - 2s 6ms/step - loss: 0.0103 - val_loss: 0.0082\n",
      "Epoch 14/50\n",
      "301/301 [==============================] - 2s 6ms/step - loss: 0.0104 - val_loss: 0.0079\n",
      "Epoch 15/50\n",
      "292/301 [============================>.] - ETA: 0s - loss: 0.0105Restoring model weights from the end of the best epoch: 5.\n",
      "301/301 [==============================] - 2s 6ms/step - loss: 0.0103 - val_loss: 0.0077\n",
      "Epoch 15: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LENGUADO en clúster 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para LENGUADO en clúster 7: 215270.29499997688, R2 Mensual: 0.903945606435219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: LENGUADO, cluster: 3\n",
      "Epoch 1/50\n",
      "2143/2143 [==============================] - 20s 6ms/step - loss: 0.0043 - val_loss: 5.4888e-04\n",
      "Epoch 2/50\n",
      "2143/2143 [==============================] - 12s 6ms/step - loss: 0.0042 - val_loss: 3.7671e-04\n",
      "Epoch 3/50\n",
      "2143/2143 [==============================] - 13s 6ms/step - loss: 0.0041 - val_loss: 3.4462e-04\n",
      "Epoch 4/50\n",
      "2143/2143 [==============================] - 13s 6ms/step - loss: 0.0041 - val_loss: 2.4282e-04\n",
      "Epoch 5/50\n",
      "2143/2143 [==============================] - 13s 6ms/step - loss: 0.0040 - val_loss: 2.9464e-04\n",
      "Epoch 6/50\n",
      "2143/2143 [==============================] - 13s 6ms/step - loss: 0.0039 - val_loss: 4.2542e-04\n",
      "Epoch 7/50\n",
      "2143/2143 [==============================] - 13s 6ms/step - loss: 0.0039 - val_loss: 2.5206e-04\n",
      "Epoch 8/50\n",
      "2143/2143 [==============================] - 13s 6ms/step - loss: 0.0038 - val_loss: 2.4201e-04\n",
      "Epoch 9/50\n",
      "2143/2143 [==============================] - 13s 6ms/step - loss: 0.0038 - val_loss: 8.9055e-04\n",
      "Epoch 10/50\n",
      "2143/2143 [==============================] - 13s 6ms/step - loss: 0.0038 - val_loss: 4.3443e-04\n",
      "Epoch 11/50\n",
      "2143/2143 [==============================] - 13s 6ms/step - loss: 0.0038 - val_loss: 2.6336e-04\n",
      "Epoch 12/50\n",
      "2143/2143 [==============================] - 13s 6ms/step - loss: 0.0038 - val_loss: 2.2691e-04\n",
      "Epoch 13/50\n",
      "2143/2143 [==============================] - 13s 6ms/step - loss: 0.0037 - val_loss: 2.7290e-04\n",
      "Epoch 14/50\n",
      "2143/2143 [==============================] - 13s 6ms/step - loss: 0.0038 - val_loss: 3.2281e-04\n",
      "Epoch 15/50\n",
      "2143/2143 [==============================] - 13s 6ms/step - loss: 0.0037 - val_loss: 2.4687e-04\n",
      "Epoch 16/50\n",
      "2143/2143 [==============================] - 13s 6ms/step - loss: 0.0037 - val_loss: 2.3492e-04\n",
      "Epoch 17/50\n",
      "2143/2143 [==============================] - 12s 6ms/step - loss: 0.0037 - val_loss: 2.3848e-04\n",
      "Epoch 18/50\n",
      "2143/2143 [==============================] - 12s 6ms/step - loss: 0.0037 - val_loss: 3.1904e-04\n",
      "Epoch 19/50\n",
      "2143/2143 [==============================] - 12s 6ms/step - loss: 0.0036 - val_loss: 2.4626e-04\n",
      "Epoch 20/50\n",
      "2143/2143 [==============================] - 12s 6ms/step - loss: 0.0036 - val_loss: 3.7545e-04\n",
      "Epoch 21/50\n",
      "2143/2143 [==============================] - 12s 6ms/step - loss: 0.0036 - val_loss: 2.3236e-04\n",
      "Epoch 22/50\n",
      "2143/2143 [==============================] - 12s 6ms/step - loss: 0.0036 - val_loss: 2.1701e-04\n",
      "Epoch 23/50\n",
      "2143/2143 [==============================] - 13s 6ms/step - loss: 0.0035 - val_loss: 2.7397e-04\n",
      "Epoch 24/50\n",
      "2143/2143 [==============================] - 12s 6ms/step - loss: 0.0036 - val_loss: 2.2018e-04\n",
      "Epoch 25/50\n",
      "2143/2143 [==============================] - 12s 6ms/step - loss: 0.0036 - val_loss: 2.7899e-04\n",
      "Epoch 26/50\n",
      "2143/2143 [==============================] - 12s 6ms/step - loss: 0.0036 - val_loss: 3.3896e-04\n",
      "Epoch 27/50\n",
      "2143/2143 [==============================] - 12s 6ms/step - loss: 0.0035 - val_loss: 2.3671e-04\n",
      "Epoch 28/50\n",
      "2143/2143 [==============================] - 13s 6ms/step - loss: 0.0036 - val_loss: 3.1970e-04\n",
      "Epoch 29/50\n",
      "2143/2143 [==============================] - 12s 6ms/step - loss: 0.0036 - val_loss: 2.4561e-04\n",
      "Epoch 30/50\n",
      "2143/2143 [==============================] - 12s 6ms/step - loss: 0.0036 - val_loss: 4.0576e-04\n",
      "Epoch 31/50\n",
      "2143/2143 [==============================] - 12s 6ms/step - loss: 0.0035 - val_loss: 2.2943e-04\n",
      "Epoch 32/50\n",
      "2142/2143 [============================>.] - ETA: 0s - loss: 0.0036Restoring model weights from the end of the best epoch: 22.\n",
      "2143/2143 [==============================] - 13s 6ms/step - loss: 0.0036 - val_loss: 2.4062e-04\n",
      "Epoch 32: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LENGUADO en clúster 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para LENGUADO en clúster 3: 51666243.701746844, R2 Mensual: 0.8024757890399262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: LENGUADO, cluster: 6\n",
      "Epoch 1/50\n",
      "6611/6611 [==============================] - 45s 6ms/step - loss: 1.5832e-04 - val_loss: 2.5346e-07\n",
      "Epoch 2/50\n",
      "6611/6611 [==============================] - 39s 6ms/step - loss: 1.5533e-04 - val_loss: 1.4847e-06\n",
      "Epoch 3/50\n",
      "6611/6611 [==============================] - 39s 6ms/step - loss: 1.5498e-04 - val_loss: 2.3995e-07\n",
      "Epoch 4/50\n",
      "6611/6611 [==============================] - 39s 6ms/step - loss: 1.5408e-04 - val_loss: 1.3622e-07\n",
      "Epoch 5/50\n",
      "6611/6611 [==============================] - 38s 6ms/step - loss: 1.5323e-04 - val_loss: 6.6222e-07\n",
      "Epoch 6/50\n",
      "6611/6611 [==============================] - 38s 6ms/step - loss: 1.5669e-04 - val_loss: 1.5842e-07\n",
      "Epoch 7/50\n",
      "6611/6611 [==============================] - 39s 6ms/step - loss: 1.5581e-04 - val_loss: 5.9668e-07\n",
      "Epoch 8/50\n",
      "6611/6611 [==============================] - 39s 6ms/step - loss: 1.5516e-04 - val_loss: 1.6876e-07\n",
      "Epoch 9/50\n",
      "6611/6611 [==============================] - 39s 6ms/step - loss: 1.5370e-04 - val_loss: 2.1452e-07\n",
      "Epoch 10/50\n",
      "6611/6611 [==============================] - 38s 6ms/step - loss: 1.5638e-04 - val_loss: 1.4833e-07\n",
      "Epoch 11/50\n",
      "6611/6611 [==============================] - 38s 6ms/step - loss: 1.5409e-04 - val_loss: 1.4206e-07\n",
      "Epoch 12/50\n",
      "6611/6611 [==============================] - 38s 6ms/step - loss: 1.5584e-04 - val_loss: 1.5694e-07\n",
      "Epoch 13/50\n",
      "6611/6611 [==============================] - 38s 6ms/step - loss: 1.5553e-04 - val_loss: 2.1116e-07\n",
      "Epoch 14/50\n",
      "6611/6611 [==============================] - 39s 6ms/step - loss: 1.5362e-04 - val_loss: 1.3248e-07\n",
      "Epoch 15/50\n",
      "6611/6611 [==============================] - 39s 6ms/step - loss: 1.5620e-04 - val_loss: 1.5995e-07\n",
      "Epoch 16/50\n",
      "6611/6611 [==============================] - 39s 6ms/step - loss: 1.5322e-04 - val_loss: 2.5469e-07\n",
      "Epoch 17/50\n",
      "6611/6611 [==============================] - 38s 6ms/step - loss: 1.5673e-04 - val_loss: 1.5838e-07\n",
      "Epoch 18/50\n",
      "6611/6611 [==============================] - 38s 6ms/step - loss: 1.5630e-04 - val_loss: 1.3702e-07\n",
      "Epoch 19/50\n",
      "6611/6611 [==============================] - 38s 6ms/step - loss: 1.5436e-04 - val_loss: 2.1370e-07\n",
      "Epoch 20/50\n",
      "6611/6611 [==============================] - 38s 6ms/step - loss: 1.5498e-04 - val_loss: 1.4916e-07\n",
      "Epoch 21/50\n",
      "6611/6611 [==============================] - 38s 6ms/step - loss: 1.5453e-04 - val_loss: 1.3497e-07\n",
      "Epoch 22/50\n",
      "6611/6611 [==============================] - 38s 6ms/step - loss: 1.5551e-04 - val_loss: 1.6883e-07\n",
      "Epoch 23/50\n",
      "6611/6611 [==============================] - 38s 6ms/step - loss: 1.5462e-04 - val_loss: 1.8880e-07\n",
      "Epoch 24/50\n",
      "6611/6611 [==============================] - ETA: 0s - loss: 1.5427e-04Restoring model weights from the end of the best epoch: 14.\n",
      "6611/6611 [==============================] - 39s 6ms/step - loss: 1.5427e-04 - val_loss: 1.4954e-07\n",
      "Epoch 24: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LENGUADO en clúster 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 1s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "60/60 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para LENGUADO en clúster 6: 493546461.8730466, R2 Mensual: 0.9102468224905406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: LENGUADO, cluster: 5\n",
      "Epoch 1/50\n",
      "136/136 [==============================] - 8s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "136/136 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "136/136 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "136/136 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "136/136 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "136/136 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "136/136 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "136/136 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "136/136 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "131/136 [===========================>..] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "136/136 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LENGUADO en clúster 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para LENGUADO en clúster 5: 71589156.0, R2 Mensual: -0.6248789582548717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: LENGUADO, cluster: 2\n",
      "Epoch 1/50\n",
      "35/35 [==============================] - 7s 35ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "31/35 [=========================>....] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "35/35 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LENGUADO en clúster 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "MSE Mensual para LENGUADO en clúster 2: 3038049.0, R2 Mensual: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n",
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/sklearn/metrics/_regression.py:1187: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: LENGUADO, cluster: 1\n",
      "Epoch 1/50\n",
      "5294/5294 [==============================] - 38s 6ms/step - loss: 0.0056 - val_loss: 0.0032\n",
      "Epoch 2/50\n",
      "5294/5294 [==============================] - 31s 6ms/step - loss: 0.0055 - val_loss: 0.0033\n",
      "Epoch 3/50\n",
      "5294/5294 [==============================] - 31s 6ms/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 4/50\n",
      "5294/5294 [==============================] - 31s 6ms/step - loss: 0.0053 - val_loss: 0.0034\n",
      "Epoch 5/50\n",
      "5294/5294 [==============================] - 32s 6ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 6/50\n",
      "5294/5294 [==============================] - 31s 6ms/step - loss: 0.0053 - val_loss: 0.0031\n",
      "Epoch 7/50\n",
      "5294/5294 [==============================] - 31s 6ms/step - loss: 0.0053 - val_loss: 0.0031\n",
      "Epoch 8/50\n",
      "5294/5294 [==============================] - 31s 6ms/step - loss: 0.0052 - val_loss: 0.0032\n",
      "Epoch 9/50\n",
      "5294/5294 [==============================] - 31s 6ms/step - loss: 0.0053 - val_loss: 0.0031\n",
      "Epoch 10/50\n",
      "5294/5294 [==============================] - 31s 6ms/step - loss: 0.0052 - val_loss: 0.0032\n",
      "Epoch 11/50\n",
      "5294/5294 [==============================] - 31s 6ms/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 12/50\n",
      "5294/5294 [==============================] - 31s 6ms/step - loss: 0.0052 - val_loss: 0.0033\n",
      "Epoch 13/50\n",
      "5294/5294 [==============================] - 31s 6ms/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 14/50\n",
      "5294/5294 [==============================] - 31s 6ms/step - loss: 0.0052 - val_loss: 0.0031\n",
      "Epoch 15/50\n",
      "5294/5294 [==============================] - 31s 6ms/step - loss: 0.0052 - val_loss: 0.0031\n",
      "Epoch 16/50\n",
      "5294/5294 [==============================] - 31s 6ms/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 17/50\n",
      "5294/5294 [==============================] - 32s 6ms/step - loss: 0.0052 - val_loss: 0.0034\n",
      "Epoch 18/50\n",
      "5294/5294 [==============================] - 32s 6ms/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 19/50\n",
      "5294/5294 [==============================] - 31s 6ms/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 20/50\n",
      "5294/5294 [==============================] - 31s 6ms/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 21/50\n",
      "5294/5294 [==============================] - 31s 6ms/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 22/50\n",
      "5294/5294 [==============================] - 31s 6ms/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 23/50\n",
      "5294/5294 [==============================] - 31s 6ms/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 24/50\n",
      "5294/5294 [==============================] - 31s 6ms/step - loss: 0.0052 - val_loss: 0.0034\n",
      "Epoch 25/50\n",
      "5294/5294 [==============================] - 31s 6ms/step - loss: 0.0051 - val_loss: 0.0030\n",
      "Epoch 26/50\n",
      "5294/5294 [==============================] - 31s 6ms/step - loss: 0.0051 - val_loss: 0.0030\n",
      "Epoch 27/50\n",
      "5294/5294 [==============================] - 31s 6ms/step - loss: 0.0051 - val_loss: 0.0030\n",
      "Epoch 28/50\n",
      "5291/5294 [============================>.] - ETA: 0s - loss: 0.0051Restoring model weights from the end of the best epoch: 18.\n",
      "5294/5294 [==============================] - 32s 6ms/step - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 28: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LENGUADO en clúster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 1s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para LENGUADO en clúster 1: 157187838.9745666, R2 Mensual: 0.8900098885037225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: LENGUADO, cluster: 4\n",
      "Epoch 1/50\n",
      "27/27 [==============================] - 7s 43ms/step - loss: 0.0265 - val_loss: 0.2040\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0249 - val_loss: 0.2096\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0265 - val_loss: 0.2195\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0237 - val_loss: 0.1984\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0228 - val_loss: 0.1989\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0225 - val_loss: 0.1946\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0224 - val_loss: 0.1971\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0223 - val_loss: 0.1955\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0218 - val_loss: 0.1971\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0229 - val_loss: 0.1967\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0217 - val_loss: 0.1956\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0223 - val_loss: 0.2000\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0223 - val_loss: 0.1985\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0225 - val_loss: 0.1880\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0223 - val_loss: 0.1985\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0221 - val_loss: 0.1979\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0214 - val_loss: 0.1924\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0221 - val_loss: 0.1883\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0236 - val_loss: 0.2018\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0213 - val_loss: 0.1924\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0216 - val_loss: 0.1995\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0213 - val_loss: 0.1949\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0222 - val_loss: 0.2028\n",
      "Epoch 24/50\n",
      "21/27 [======================>.......] - ETA: 0s - loss: 0.0238Restoring model weights from the end of the best epoch: 14.\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0218 - val_loss: 0.1891\n",
      "Epoch 24: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LENGUADO en clúster 4\n",
      "No se tienen datos suficientes para LENGUADO en clúster 4 en los últimos seis meses de 2023\n",
      "Training model for species: CABRILLA, cluster: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "128/128 [==============================] - 10s 15ms/step - loss: 0.0070 - val_loss: 0.1144\n",
      "Epoch 2/50\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.0058 - val_loss: 0.1161\n",
      "Epoch 3/50\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.0056 - val_loss: 0.1066\n",
      "Epoch 4/50\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.0053 - val_loss: 0.1166\n",
      "Epoch 5/50\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.0054 - val_loss: 0.1009\n",
      "Epoch 6/50\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.0051 - val_loss: 0.1073\n",
      "Epoch 7/50\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.1048\n",
      "Epoch 8/50\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.0051 - val_loss: 0.1096\n",
      "Epoch 9/50\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.1037\n",
      "Epoch 10/50\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.1079\n",
      "Epoch 11/50\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.1118\n",
      "Epoch 12/50\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.1133\n",
      "Epoch 13/50\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.1100\n",
      "Epoch 14/50\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.1131\n",
      "Epoch 15/50\n",
      "127/128 [============================>.] - ETA: 0s - loss: 0.0047Restoring model weights from the end of the best epoch: 5.\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.1106\n",
      "Epoch 15: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CABRILLA en clúster 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "MSE Mensual para CABRILLA en clúster 7: 420953.3183762122, R2 Mensual: 0.2958926483550125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: CABRILLA, cluster: 3\n",
      "Epoch 1/50\n",
      "2036/2036 [==============================] - 19s 6ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 2/50\n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 3/50\n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 4/50\n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 5/50\n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 6/50\n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 7/50\n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 8/50\n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 9/50\n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 10/50\n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 11/50\n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 12/50\n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 13/50\n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 14/50\n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 15/50\n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 16/50\n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 17/50\n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 18/50\n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 19/50\n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 20/50\n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 21/50\n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 22/50\n",
      "2028/2036 [============================>.] - ETA: 0s - loss: 0.0020Restoring model weights from the end of the best epoch: 12.\n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 22: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CABRILLA en clúster 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para CABRILLA en clúster 3: 6618294.055350733, R2 Mensual: 0.6762692543198376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: CABRILLA, cluster: 6\n",
      "Epoch 1/50\n",
      "3169/3169 [==============================] - 25s 6ms/step - loss: 3.6844e-04 - val_loss: 6.3476e-05\n",
      "Epoch 2/50\n",
      "3169/3169 [==============================] - 18s 6ms/step - loss: 3.2692e-04 - val_loss: 4.0307e-07\n",
      "Epoch 3/50\n",
      "3169/3169 [==============================] - 18s 6ms/step - loss: 3.2730e-04 - val_loss: 2.2096e-07\n",
      "Epoch 4/50\n",
      "3169/3169 [==============================] - 18s 6ms/step - loss: 3.2553e-04 - val_loss: 1.5255e-07\n",
      "Epoch 5/50\n",
      "3169/3169 [==============================] - 18s 6ms/step - loss: 3.2186e-04 - val_loss: 3.1925e-07\n",
      "Epoch 6/50\n",
      "3169/3169 [==============================] - 18s 6ms/step - loss: 3.2783e-04 - val_loss: 1.8489e-07\n",
      "Epoch 7/50\n",
      "3169/3169 [==============================] - 18s 6ms/step - loss: 3.2623e-04 - val_loss: 1.6925e-07\n",
      "Epoch 8/50\n",
      "3169/3169 [==============================] - 18s 6ms/step - loss: 3.2512e-04 - val_loss: 1.5278e-07\n",
      "Epoch 9/50\n",
      "3169/3169 [==============================] - 18s 6ms/step - loss: 3.2383e-04 - val_loss: 1.7731e-07\n",
      "Epoch 10/50\n",
      "3169/3169 [==============================] - 18s 6ms/step - loss: 3.2203e-04 - val_loss: 2.0924e-07\n",
      "Epoch 11/50\n",
      "3169/3169 [==============================] - 19s 6ms/step - loss: 3.2625e-04 - val_loss: 1.9045e-07\n",
      "Epoch 12/50\n",
      "3169/3169 [==============================] - 19s 6ms/step - loss: 3.2548e-04 - val_loss: 2.5710e-07\n",
      "Epoch 13/50\n",
      "3169/3169 [==============================] - 19s 6ms/step - loss: 3.2504e-04 - val_loss: 1.5351e-07\n",
      "Epoch 14/50\n",
      "3163/3169 [============================>.] - ETA: 0s - loss: 3.2371e-04Restoring model weights from the end of the best epoch: 4.\n",
      "3169/3169 [==============================] - 19s 6ms/step - loss: 3.2310e-04 - val_loss: 1.6116e-07\n",
      "Epoch 14: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CABRILLA en clúster 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 1s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "33/33 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para CABRILLA en clúster 6: 296663321.3573287, R2 Mensual: -3.787515821467524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: CABRILLA, cluster: 5\n",
      "Epoch 1/50\n",
      "65/65 [==============================] - 7s 22ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "65/65 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "65/65 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "60/65 [==========================>...] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "65/65 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CABRILLA en clúster 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 955ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "MSE Mensual para CABRILLA en clúster 5: 4159712.285714286, R2 Mensual: -0.49588755854338196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: CABRILLA, cluster: 2\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 7s 253ms/step - loss: 0.1343 - val_loss: nan\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1258 - val_loss: nan\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1200 - val_loss: nan\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1151 - val_loss: nan\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1089 - val_loss: nan\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0992 - val_loss: nan\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0895 - val_loss: nan\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0862 - val_loss: nan\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0778 - val_loss: nan\n",
      "Epoch 10/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0042Restoring model weights from the end of the best epoch: 1.\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0643 - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CABRILLA en clúster 2\n",
      "No se tienen datos suficientes para CABRILLA en clúster 2 en los últimos seis meses de 2023\n",
      "Training model for species: CABRILLA, cluster: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3871/3871 [==============================] - 30s 6ms/step - loss: 0.0063 - val_loss: 0.0029\n",
      "Epoch 2/50\n",
      "3871/3871 [==============================] - 22s 6ms/step - loss: 0.0059 - val_loss: 0.0027\n",
      "Epoch 3/50\n",
      "3871/3871 [==============================] - 23s 6ms/step - loss: 0.0058 - val_loss: 0.0024\n",
      "Epoch 4/50\n",
      "3871/3871 [==============================] - 22s 6ms/step - loss: 0.0057 - val_loss: 0.0024\n",
      "Epoch 5/50\n",
      "3871/3871 [==============================] - 22s 6ms/step - loss: 0.0056 - val_loss: 0.0025\n",
      "Epoch 6/50\n",
      "3871/3871 [==============================] - 22s 6ms/step - loss: 0.0056 - val_loss: 0.0029\n",
      "Epoch 7/50\n",
      "3871/3871 [==============================] - 22s 6ms/step - loss: 0.0056 - val_loss: 0.0027\n",
      "Epoch 8/50\n",
      "3871/3871 [==============================] - 22s 6ms/step - loss: 0.0056 - val_loss: 0.0024\n",
      "Epoch 9/50\n",
      "3871/3871 [==============================] - 22s 6ms/step - loss: 0.0053 - val_loss: 0.0024\n",
      "Epoch 10/50\n",
      "3871/3871 [==============================] - 22s 6ms/step - loss: 0.0054 - val_loss: 0.0026\n",
      "Epoch 11/50\n",
      "3871/3871 [==============================] - 22s 6ms/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 12/50\n",
      "3871/3871 [==============================] - 22s 6ms/step - loss: 0.0055 - val_loss: 0.0026\n",
      "Epoch 13/50\n",
      "3871/3871 [==============================] - 22s 6ms/step - loss: 0.0055 - val_loss: 0.0024\n",
      "Epoch 14/50\n",
      "3871/3871 [==============================] - 22s 6ms/step - loss: 0.0054 - val_loss: 0.0024\n",
      "Epoch 15/50\n",
      "3871/3871 [==============================] - 22s 6ms/step - loss: 0.0052 - val_loss: 0.0034\n",
      "Epoch 16/50\n",
      "3871/3871 [==============================] - 22s 6ms/step - loss: 0.0053 - val_loss: 0.0025\n",
      "Epoch 17/50\n",
      "3871/3871 [==============================] - 22s 6ms/step - loss: 0.0053 - val_loss: 0.0026\n",
      "Epoch 18/50\n",
      "3871/3871 [==============================] - 23s 6ms/step - loss: 0.0053 - val_loss: 0.0023\n",
      "Epoch 19/50\n",
      "3871/3871 [==============================] - 23s 6ms/step - loss: 0.0052 - val_loss: 0.0023\n",
      "Epoch 20/50\n",
      "3871/3871 [==============================] - 22s 6ms/step - loss: 0.0053 - val_loss: 0.0024\n",
      "Epoch 21/50\n",
      "3871/3871 [==============================] - 23s 6ms/step - loss: 0.0052 - val_loss: 0.0024\n",
      "Epoch 22/50\n",
      "3871/3871 [==============================] - 22s 6ms/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 23/50\n",
      "3871/3871 [==============================] - 23s 6ms/step - loss: 0.0053 - val_loss: 0.0027\n",
      "Epoch 24/50\n",
      "3871/3871 [==============================] - 23s 6ms/step - loss: 0.0052 - val_loss: 0.0025\n",
      "Epoch 25/50\n",
      "3871/3871 [==============================] - 23s 6ms/step - loss: 0.0054 - val_loss: 0.0025\n",
      "Epoch 26/50\n",
      "3871/3871 [==============================] - 23s 6ms/step - loss: 0.0053 - val_loss: 0.0025\n",
      "Epoch 27/50\n",
      "3871/3871 [==============================] - 24s 6ms/step - loss: 0.0053 - val_loss: 0.0024\n",
      "Epoch 28/50\n",
      "3871/3871 [==============================] - 23s 6ms/step - loss: 0.0052 - val_loss: 0.0024\n",
      "Epoch 29/50\n",
      "3869/3871 [============================>.] - ETA: 0s - loss: 0.0051Restoring model weights from the end of the best epoch: 19.\n",
      "3871/3871 [==============================] - 23s 6ms/step - loss: 0.0051 - val_loss: 0.0024\n",
      "Epoch 29: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CABRILLA en clúster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 1s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para CABRILLA en clúster 1: 16379437.922523016, R2 Mensual: 0.644428943127218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: CABRILLA, cluster: 4\n",
      "Epoch 1/50\n",
      "43/43 [==============================] - 7s 30ms/step - loss: 0.0457 - val_loss: 0.0073\n",
      "Epoch 2/50\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0427 - val_loss: 0.0067\n",
      "Epoch 3/50\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0432 - val_loss: 0.0071\n",
      "Epoch 4/50\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0417 - val_loss: 0.0051\n",
      "Epoch 5/50\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0411 - val_loss: 0.0067\n",
      "Epoch 6/50\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0420 - val_loss: 0.0064\n",
      "Epoch 7/50\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0408 - val_loss: 0.0065\n",
      "Epoch 8/50\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0423 - val_loss: 0.0058\n",
      "Epoch 9/50\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0406 - val_loss: 0.0062\n",
      "Epoch 10/50\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0400 - val_loss: 0.0098\n",
      "Epoch 11/50\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0401 - val_loss: 0.0063\n",
      "Epoch 12/50\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0408 - val_loss: 0.0059\n",
      "Epoch 13/50\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0407 - val_loss: 0.0085\n",
      "Epoch 14/50\n",
      "41/43 [===========================>..] - ETA: 0s - loss: 0.0436Restoring model weights from the end of the best epoch: 4.\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0418 - val_loss: 0.0082\n",
      "Epoch 14: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CABRILLA en clúster 4\n",
      "No se tienen datos suficientes para CABRILLA en clúster 4 en los últimos seis meses de 2023\n",
      "Training model for species: MERO, cluster: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "256/256 [==============================] - 9s 10ms/step - loss: 0.0197 - val_loss: 0.0284\n",
      "Epoch 2/50\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0179 - val_loss: 0.0326\n",
      "Epoch 3/50\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0188 - val_loss: 0.0230\n",
      "Epoch 4/50\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0179 - val_loss: 0.0238\n",
      "Epoch 5/50\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0180 - val_loss: 0.0239\n",
      "Epoch 6/50\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0179 - val_loss: 0.0230\n",
      "Epoch 7/50\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0175 - val_loss: 0.0261\n",
      "Epoch 8/50\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0175 - val_loss: 0.0232\n",
      "Epoch 9/50\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0175 - val_loss: 0.0248\n",
      "Epoch 10/50\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0176 - val_loss: 0.0231\n",
      "Epoch 11/50\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0175 - val_loss: 0.0240\n",
      "Epoch 12/50\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0171 - val_loss: 0.0236\n",
      "Epoch 13/50\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0172 - val_loss: 0.0234\n",
      "Epoch 14/50\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0173 - val_loss: 0.0229\n",
      "Epoch 15/50\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0172 - val_loss: 0.0235\n",
      "Epoch 16/50\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0170 - val_loss: 0.0235\n",
      "Epoch 17/50\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0165 - val_loss: 0.0231\n",
      "Epoch 18/50\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0170 - val_loss: 0.0237\n",
      "Epoch 19/50\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0165 - val_loss: 0.0239\n",
      "Epoch 20/50\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0168 - val_loss: 0.0236\n",
      "Epoch 21/50\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0166 - val_loss: 0.0239\n",
      "Epoch 22/50\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0166 - val_loss: 0.0235\n",
      "Epoch 23/50\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0164 - val_loss: 0.0230\n",
      "Epoch 24/50\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.0162Restoring model weights from the end of the best epoch: 14.\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0163 - val_loss: 0.0234\n",
      "Epoch 24: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para MERO en clúster 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "MSE Mensual para MERO en clúster 7: 26725.95674977611, R2 Mensual: 0.30295361186034986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: MERO, cluster: 3\n",
      "Epoch 1/50\n",
      "1137/1137 [==============================] - 14s 7ms/step - loss: 0.0105 - val_loss: 0.0020\n",
      "Epoch 2/50\n",
      "1137/1137 [==============================] - 7s 7ms/step - loss: 0.0104 - val_loss: 0.0022\n",
      "Epoch 3/50\n",
      "1137/1137 [==============================] - 8s 7ms/step - loss: 0.0103 - val_loss: 0.0020\n",
      "Epoch 4/50\n",
      "1137/1137 [==============================] - 8s 7ms/step - loss: 0.0103 - val_loss: 0.0021\n",
      "Epoch 5/50\n",
      "1137/1137 [==============================] - 8s 7ms/step - loss: 0.0103 - val_loss: 0.0021\n",
      "Epoch 6/50\n",
      "1137/1137 [==============================] - 8s 7ms/step - loss: 0.0103 - val_loss: 0.0021\n",
      "Epoch 7/50\n",
      "1137/1137 [==============================] - 7s 7ms/step - loss: 0.0102 - val_loss: 0.0021\n",
      "Epoch 8/50\n",
      "1137/1137 [==============================] - 8s 7ms/step - loss: 0.0102 - val_loss: 0.0020\n",
      "Epoch 9/50\n",
      "1137/1137 [==============================] - 8s 7ms/step - loss: 0.0101 - val_loss: 0.0022\n",
      "Epoch 10/50\n",
      "1137/1137 [==============================] - 8s 7ms/step - loss: 0.0100 - val_loss: 0.0021\n",
      "Epoch 11/50\n",
      "1132/1137 [============================>.] - ETA: 0s - loss: 0.0100Restoring model weights from the end of the best epoch: 1.\n",
      "1137/1137 [==============================] - 8s 7ms/step - loss: 0.0100 - val_loss: 0.0020\n",
      "Epoch 11: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para MERO en clúster 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 5ms/step\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para MERO en clúster 3: 1679760.2937318282, R2 Mensual: 0.839639683722219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: MERO, cluster: 6\n",
      "Epoch 1/50\n",
      "440/440 [==============================] - 10s 9ms/step - loss: 0.0048 - val_loss: 1.8393e-04\n",
      "Epoch 2/50\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.0041 - val_loss: 5.8838e-04\n",
      "Epoch 3/50\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.0041 - val_loss: 1.9983e-04\n",
      "Epoch 4/50\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.0041 - val_loss: 3.7817e-04\n",
      "Epoch 5/50\n",
      "440/440 [==============================] - 3s 6ms/step - loss: 0.0040 - val_loss: 3.1426e-04\n",
      "Epoch 6/50\n",
      "440/440 [==============================] - 3s 6ms/step - loss: 0.0041 - val_loss: 2.7436e-04\n",
      "Epoch 7/50\n",
      "440/440 [==============================] - 3s 6ms/step - loss: 0.0040 - val_loss: 6.8757e-04\n",
      "Epoch 8/50\n",
      "440/440 [==============================] - 3s 6ms/step - loss: 0.0040 - val_loss: 2.9821e-04\n",
      "Epoch 9/50\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.0042 - val_loss: 1.7015e-04\n",
      "Epoch 10/50\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.0040 - val_loss: 3.8143e-04\n",
      "Epoch 11/50\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.0040 - val_loss: 3.0879e-04\n",
      "Epoch 12/50\n",
      "440/440 [==============================] - 3s 6ms/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 13/50\n",
      "440/440 [==============================] - 3s 6ms/step - loss: 0.0040 - val_loss: 4.1236e-04\n",
      "Epoch 14/50\n",
      "440/440 [==============================] - 3s 6ms/step - loss: 0.0040 - val_loss: 2.9602e-04\n",
      "Epoch 15/50\n",
      "440/440 [==============================] - 3s 6ms/step - loss: 0.0040 - val_loss: 3.2620e-04\n",
      "Epoch 16/50\n",
      "440/440 [==============================] - 3s 6ms/step - loss: 0.0040 - val_loss: 3.3773e-04\n",
      "Epoch 17/50\n",
      "440/440 [==============================] - 3s 6ms/step - loss: 0.0039 - val_loss: 3.3506e-04\n",
      "Epoch 18/50\n",
      "440/440 [==============================] - 3s 6ms/step - loss: 0.0040 - val_loss: 3.1836e-04\n",
      "Epoch 19/50\n",
      "433/440 [============================>.] - ETA: 0s - loss: 0.0040Restoring model weights from the end of the best epoch: 9.\n",
      "440/440 [==============================] - 3s 6ms/step - loss: 0.0039 - val_loss: 6.5181e-04\n",
      "Epoch 19: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para MERO en clúster 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 5ms/step\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para MERO en clúster 6: 948499.4640980299, R2 Mensual: 0.2173635261543042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: MERO, cluster: 5\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 7s 170ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "1/7 [===>..........................] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "7/7 [==============================] - 0s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para MERO en clúster 5\n",
      "No se tienen datos suficientes para MERO en clúster 5 en los últimos seis meses de 2023\n",
      "Training model for species: MERO, cluster: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "809/809 [==============================] - 12s 7ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 2/50\n",
      "809/809 [==============================] - 5s 6ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 3/50\n",
      "809/809 [==============================] - 5s 6ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 4/50\n",
      "809/809 [==============================] - 5s 6ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 5/50\n",
      "809/809 [==============================] - 5s 6ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 6/50\n",
      "809/809 [==============================] - 5s 6ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 7/50\n",
      "809/809 [==============================] - 5s 6ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 8/50\n",
      "809/809 [==============================] - 5s 6ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 9/50\n",
      "809/809 [==============================] - 5s 6ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 10/50\n",
      "809/809 [==============================] - 5s 6ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 11/50\n",
      "809/809 [==============================] - 5s 6ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 12/50\n",
      "809/809 [==============================] - 5s 6ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 13/50\n",
      "809/809 [==============================] - 5s 6ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 14/50\n",
      "809/809 [==============================] - 5s 6ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 15/50\n",
      "809/809 [==============================] - 5s 6ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 16/50\n",
      "809/809 [==============================] - 5s 6ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 17/50\n",
      "809/809 [==============================] - ETA: 0s - loss: 0.0017Restoring model weights from the end of the best epoch: 7.\n",
      "809/809 [==============================] - 5s 6ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 17: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para MERO en clúster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 5ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para MERO en clúster 1: 5669151.166442496, R2 Mensual: 0.6498653632791893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: MERO, cluster: 4\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 7s 38ms/step - loss: 0.0713 - val_loss: 0.0314\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0695 - val_loss: 0.0248\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0609 - val_loss: 0.0217\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0580 - val_loss: 0.0252\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0600 - val_loss: 0.0227\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0595 - val_loss: 0.0248\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0548 - val_loss: 0.0241\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0586 - val_loss: 0.0209\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0575 - val_loss: 0.0208\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0545 - val_loss: 0.0224\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0578 - val_loss: 0.0268\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0594 - val_loss: 0.0257\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0551 - val_loss: 0.0216\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0540 - val_loss: 0.0227\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0567 - val_loss: 0.0204\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0556 - val_loss: 0.0205\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0531 - val_loss: 0.0205\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0620 - val_loss: 0.0290\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0581 - val_loss: 0.0214\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0540 - val_loss: 0.0233\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0520 - val_loss: 0.0238\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0551 - val_loss: 0.0257\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0550 - val_loss: 0.0207\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0547 - val_loss: 0.0245\n",
      "Epoch 25/50\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.0510Restoring model weights from the end of the best epoch: 15.\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0501 - val_loss: 0.0228\n",
      "Epoch 25: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para MERO en clúster 4\n",
      "No se tienen datos suficientes para MERO en clúster 4 en los últimos seis meses de 2023\n",
      "Training model for species: OSTION, cluster: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "681/681 [==============================] - 11s 7ms/step - loss: 0.0065 - val_loss: 0.0022\n",
      "Epoch 2/50\n",
      "681/681 [==============================] - 4s 6ms/step - loss: 0.0062 - val_loss: 0.0028\n",
      "Epoch 3/50\n",
      "681/681 [==============================] - 4s 6ms/step - loss: 0.0061 - val_loss: 0.0031\n",
      "Epoch 4/50\n",
      "681/681 [==============================] - 4s 6ms/step - loss: 0.0060 - val_loss: 0.0012\n",
      "Epoch 5/50\n",
      "681/681 [==============================] - 4s 6ms/step - loss: 0.0059 - val_loss: 0.0016\n",
      "Epoch 6/50\n",
      "681/681 [==============================] - 4s 6ms/step - loss: 0.0059 - val_loss: 0.0021\n",
      "Epoch 7/50\n",
      "681/681 [==============================] - 4s 6ms/step - loss: 0.0058 - val_loss: 0.0020\n",
      "Epoch 8/50\n",
      "681/681 [==============================] - 4s 6ms/step - loss: 0.0057 - val_loss: 0.0079\n",
      "Epoch 9/50\n",
      "681/681 [==============================] - 4s 6ms/step - loss: 0.0058 - val_loss: 0.0019\n",
      "Epoch 10/50\n",
      "681/681 [==============================] - 4s 6ms/step - loss: 0.0056 - val_loss: 0.0029\n",
      "Epoch 11/50\n",
      "681/681 [==============================] - 4s 6ms/step - loss: 0.0058 - val_loss: 0.0019\n",
      "Epoch 12/50\n",
      "681/681 [==============================] - 4s 6ms/step - loss: 0.0054 - val_loss: 0.0029\n",
      "Epoch 13/50\n",
      "681/681 [==============================] - 4s 6ms/step - loss: 0.0056 - val_loss: 0.0015\n",
      "Epoch 14/50\n",
      "681/681 [==============================] - 4s 6ms/step - loss: 0.0053 - val_loss: 0.0012\n",
      "Epoch 15/50\n",
      "681/681 [==============================] - 4s 6ms/step - loss: 0.0058 - val_loss: 0.0013\n",
      "Epoch 16/50\n",
      "681/681 [==============================] - 4s 6ms/step - loss: 0.0058 - val_loss: 0.0017\n",
      "Epoch 17/50\n",
      "681/681 [==============================] - 4s 6ms/step - loss: 0.0053 - val_loss: 0.0014\n",
      "Epoch 18/50\n",
      "681/681 [==============================] - 4s 6ms/step - loss: 0.0052 - val_loss: 0.0016\n",
      "Epoch 19/50\n",
      "681/681 [==============================] - 4s 6ms/step - loss: 0.0054 - val_loss: 0.0017\n",
      "Epoch 20/50\n",
      "681/681 [==============================] - 4s 6ms/step - loss: 0.0058 - val_loss: 0.0016\n",
      "Epoch 21/50\n",
      "681/681 [==============================] - 4s 6ms/step - loss: 0.0053 - val_loss: 0.0027\n",
      "Epoch 22/50\n",
      "681/681 [==============================] - 4s 6ms/step - loss: 0.0050 - val_loss: 0.0025\n",
      "Epoch 23/50\n",
      "681/681 [==============================] - 4s 6ms/step - loss: 0.0050 - val_loss: 0.0014\n",
      "Epoch 24/50\n",
      "680/681 [============================>.] - ETA: 0s - loss: 0.0052Restoring model weights from the end of the best epoch: 14.\n",
      "681/681 [==============================] - 4s 6ms/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 24: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para OSTION en clúster 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para OSTION en clúster 7: 215700290.00406504, R2 Mensual: -2.7913377293314934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: OSTION, cluster: 0\n",
      "Error entrenando el modelo para especie: OSTION, clúster: 0. Error: tuple index out of range\n",
      "Training model for species: OSTION, cluster: 3\n",
      "Epoch 1/50\n",
      "1391/1391 [==============================] - 15s 7ms/step - loss: 0.0026 - val_loss: 6.7835e-04\n",
      "Epoch 2/50\n",
      "1391/1391 [==============================] - 8s 6ms/step - loss: 0.0026 - val_loss: 7.2091e-04\n",
      "Epoch 3/50\n",
      "1391/1391 [==============================] - 8s 6ms/step - loss: 0.0025 - val_loss: 5.7527e-04\n",
      "Epoch 4/50\n",
      "1391/1391 [==============================] - 8s 6ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 5/50\n",
      "1391/1391 [==============================] - 8s 6ms/step - loss: 0.0025 - val_loss: 8.2887e-04\n",
      "Epoch 6/50\n",
      "1391/1391 [==============================] - 8s 6ms/step - loss: 0.0025 - val_loss: 6.7279e-04\n",
      "Epoch 7/50\n",
      "1391/1391 [==============================] - 8s 6ms/step - loss: 0.0025 - val_loss: 6.1591e-04\n",
      "Epoch 8/50\n",
      "1391/1391 [==============================] - 8s 6ms/step - loss: 0.0025 - val_loss: 7.8667e-04\n",
      "Epoch 9/50\n",
      "1391/1391 [==============================] - 8s 6ms/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 10/50\n",
      "1391/1391 [==============================] - 8s 6ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 11/50\n",
      "1391/1391 [==============================] - 8s 6ms/step - loss: 0.0025 - val_loss: 5.3394e-04\n",
      "Epoch 12/50\n",
      "1391/1391 [==============================] - 8s 6ms/step - loss: 0.0025 - val_loss: 7.0204e-04\n",
      "Epoch 13/50\n",
      "1391/1391 [==============================] - 8s 6ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 14/50\n",
      "1391/1391 [==============================] - 8s 6ms/step - loss: 0.0025 - val_loss: 7.5595e-04\n",
      "Epoch 15/50\n",
      "1391/1391 [==============================] - 8s 6ms/step - loss: 0.0025 - val_loss: 7.1152e-04\n",
      "Epoch 16/50\n",
      "1391/1391 [==============================] - 8s 6ms/step - loss: 0.0025 - val_loss: 7.2033e-04\n",
      "Epoch 17/50\n",
      "1391/1391 [==============================] - 8s 6ms/step - loss: 0.0025 - val_loss: 6.6687e-04\n",
      "Epoch 18/50\n",
      "1391/1391 [==============================] - 8s 6ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 19/50\n",
      "1391/1391 [==============================] - 8s 6ms/step - loss: 0.0025 - val_loss: 8.3306e-04\n",
      "Epoch 20/50\n",
      "1391/1391 [==============================] - 8s 6ms/step - loss: 0.0025 - val_loss: 9.0755e-04\n",
      "Epoch 21/50\n",
      "1389/1391 [============================>.] - ETA: 0s - loss: 0.0025Restoring model weights from the end of the best epoch: 11.\n",
      "1391/1391 [==============================] - 8s 6ms/step - loss: 0.0025 - val_loss: 6.3531e-04\n",
      "Epoch 21: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para OSTION en clúster 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para OSTION en clúster 3: 371456300.56121284, R2 Mensual: 0.13965151365587058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: OSTION, cluster: 1\n",
      "Epoch 1/50\n",
      "1008/1008 [==============================] - 13s 7ms/step - loss: 0.0015 - val_loss: 9.1917e-04\n",
      "Epoch 2/50\n",
      "1008/1008 [==============================] - 6s 6ms/step - loss: 0.0014 - val_loss: 9.3568e-04\n",
      "Epoch 3/50\n",
      "1008/1008 [==============================] - 6s 6ms/step - loss: 0.0014 - val_loss: 9.2283e-04\n",
      "Epoch 4/50\n",
      "1008/1008 [==============================] - 6s 6ms/step - loss: 0.0014 - val_loss: 9.5793e-04\n",
      "Epoch 5/50\n",
      "1008/1008 [==============================] - 6s 6ms/step - loss: 0.0014 - val_loss: 9.3482e-04\n",
      "Epoch 6/50\n",
      "1008/1008 [==============================] - 6s 6ms/step - loss: 0.0014 - val_loss: 9.2838e-04\n",
      "Epoch 7/50\n",
      "1008/1008 [==============================] - 6s 6ms/step - loss: 0.0014 - val_loss: 9.0171e-04\n",
      "Epoch 8/50\n",
      "1008/1008 [==============================] - 6s 6ms/step - loss: 0.0014 - val_loss: 9.3576e-04\n",
      "Epoch 9/50\n",
      "1008/1008 [==============================] - 6s 6ms/step - loss: 0.0014 - val_loss: 9.2059e-04\n",
      "Epoch 10/50\n",
      "1008/1008 [==============================] - 6s 6ms/step - loss: 0.0014 - val_loss: 9.1881e-04\n",
      "Epoch 11/50\n",
      "1008/1008 [==============================] - 6s 6ms/step - loss: 0.0014 - val_loss: 9.2723e-04\n",
      "Epoch 12/50\n",
      "1008/1008 [==============================] - 6s 6ms/step - loss: 0.0014 - val_loss: 9.1333e-04\n",
      "Epoch 13/50\n",
      "1008/1008 [==============================] - 6s 6ms/step - loss: 0.0014 - val_loss: 9.3242e-04\n",
      "Epoch 14/50\n",
      "1008/1008 [==============================] - 6s 6ms/step - loss: 0.0014 - val_loss: 9.2068e-04\n",
      "Epoch 15/50\n",
      "1008/1008 [==============================] - 6s 6ms/step - loss: 0.0014 - val_loss: 9.2008e-04\n",
      "Epoch 16/50\n",
      "1008/1008 [==============================] - 6s 6ms/step - loss: 0.0014 - val_loss: 9.3331e-04\n",
      "Epoch 17/50\n",
      "1008/1008 [==============================] - ETA: 0s - loss: 0.0014Restoring model weights from the end of the best epoch: 7.\n",
      "1008/1008 [==============================] - 6s 6ms/step - loss: 0.0014 - val_loss: 9.2824e-04\n",
      "Epoch 17: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para OSTION en clúster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para OSTION en clúster 1: 20494908.813220978, R2 Mensual: 0.8394063165493593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: JAIBA, cluster: 7\n",
      "Epoch 1/50\n",
      "914/914 [==============================] - 16s 8ms/step - loss: 0.0042 - val_loss: 0.0202\n",
      "Epoch 2/50\n",
      "914/914 [==============================] - 6s 7ms/step - loss: 0.0037 - val_loss: 0.0193\n",
      "Epoch 3/50\n",
      "914/914 [==============================] - 6s 7ms/step - loss: 0.0036 - val_loss: 0.0171\n",
      "Epoch 4/50\n",
      "914/914 [==============================] - 6s 6ms/step - loss: 0.0032 - val_loss: 0.0145\n",
      "Epoch 5/50\n",
      "914/914 [==============================] - 6s 6ms/step - loss: 0.0032 - val_loss: 0.0161\n",
      "Epoch 6/50\n",
      "914/914 [==============================] - 5s 6ms/step - loss: 0.0030 - val_loss: 0.0155\n",
      "Epoch 7/50\n",
      "914/914 [==============================] - 5s 6ms/step - loss: 0.0030 - val_loss: 0.0159\n",
      "Epoch 8/50\n",
      "914/914 [==============================] - 5s 6ms/step - loss: 0.0030 - val_loss: 0.0144\n",
      "Epoch 9/50\n",
      "914/914 [==============================] - 5s 6ms/step - loss: 0.0027 - val_loss: 0.0174\n",
      "Epoch 10/50\n",
      "914/914 [==============================] - 5s 6ms/step - loss: 0.0031 - val_loss: 0.0130\n",
      "Epoch 11/50\n",
      "914/914 [==============================] - 5s 6ms/step - loss: 0.0029 - val_loss: 0.0145\n",
      "Epoch 12/50\n",
      "914/914 [==============================] - 5s 6ms/step - loss: 0.0028 - val_loss: 0.0158\n",
      "Epoch 13/50\n",
      "914/914 [==============================] - 5s 6ms/step - loss: 0.0029 - val_loss: 0.0134\n",
      "Epoch 14/50\n",
      "914/914 [==============================] - 6s 6ms/step - loss: 0.0028 - val_loss: 0.0131\n",
      "Epoch 15/50\n",
      "914/914 [==============================] - 6s 6ms/step - loss: 0.0028 - val_loss: 0.0137\n",
      "Epoch 16/50\n",
      "914/914 [==============================] - 6s 6ms/step - loss: 0.0028 - val_loss: 0.0128\n",
      "Epoch 17/50\n",
      "914/914 [==============================] - 6s 6ms/step - loss: 0.0027 - val_loss: 0.0134\n",
      "Epoch 18/50\n",
      "914/914 [==============================] - 6s 6ms/step - loss: 0.0027 - val_loss: 0.0141\n",
      "Epoch 19/50\n",
      "914/914 [==============================] - 6s 6ms/step - loss: 0.0027 - val_loss: 0.0157\n",
      "Epoch 20/50\n",
      "914/914 [==============================] - 6s 6ms/step - loss: 0.0028 - val_loss: 0.0161\n",
      "Epoch 21/50\n",
      "914/914 [==============================] - 6s 6ms/step - loss: 0.0027 - val_loss: 0.0162\n",
      "Epoch 22/50\n",
      "914/914 [==============================] - 6s 7ms/step - loss: 0.0027 - val_loss: 0.0122\n",
      "Epoch 23/50\n",
      "914/914 [==============================] - 6s 6ms/step - loss: 0.0027 - val_loss: 0.0145\n",
      "Epoch 24/50\n",
      "914/914 [==============================] - 5s 6ms/step - loss: 0.0027 - val_loss: 0.0133\n",
      "Epoch 25/50\n",
      "914/914 [==============================] - 5s 6ms/step - loss: 0.0028 - val_loss: 0.0132\n",
      "Epoch 26/50\n",
      "914/914 [==============================] - 5s 6ms/step - loss: 0.0026 - val_loss: 0.0149\n",
      "Epoch 27/50\n",
      "914/914 [==============================] - 5s 6ms/step - loss: 0.0027 - val_loss: 0.0125\n",
      "Epoch 28/50\n",
      "914/914 [==============================] - 5s 6ms/step - loss: 0.0027 - val_loss: 0.0145\n",
      "Epoch 29/50\n",
      "914/914 [==============================] - 6s 6ms/step - loss: 0.0028 - val_loss: 0.0146\n",
      "Epoch 30/50\n",
      "914/914 [==============================] - 5s 6ms/step - loss: 0.0027 - val_loss: 0.0147\n",
      "Epoch 31/50\n",
      "914/914 [==============================] - 6s 6ms/step - loss: 0.0027 - val_loss: 0.0132\n",
      "Epoch 32/50\n",
      "914/914 [==============================] - ETA: 0s - loss: 0.0027Restoring model weights from the end of the best epoch: 22.\n",
      "914/914 [==============================] - 6s 6ms/step - loss: 0.0027 - val_loss: 0.0131\n",
      "Epoch 32: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para JAIBA en clúster 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 5ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para JAIBA en clúster 7: 9821461.393098371, R2 Mensual: 0.5255540462827992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: JAIBA, cluster: 3\n",
      "Epoch 1/50\n",
      "5009/5009 [==============================] - 37s 6ms/step - loss: 0.0074 - val_loss: 0.0028\n",
      "Epoch 2/50\n",
      "5009/5009 [==============================] - 31s 6ms/step - loss: 0.0069 - val_loss: 0.0013\n",
      "Epoch 3/50\n",
      "5009/5009 [==============================] - 31s 6ms/step - loss: 0.0066 - val_loss: 0.0014\n",
      "Epoch 4/50\n",
      "5009/5009 [==============================] - 30s 6ms/step - loss: 0.0065 - val_loss: 0.0015\n",
      "Epoch 5/50\n",
      "5009/5009 [==============================] - 30s 6ms/step - loss: 0.0065 - val_loss: 0.0014\n",
      "Epoch 6/50\n",
      "5009/5009 [==============================] - 30s 6ms/step - loss: 0.0065 - val_loss: 0.0022\n",
      "Epoch 7/50\n",
      "5009/5009 [==============================] - 29s 6ms/step - loss: 0.0064 - val_loss: 0.0014\n",
      "Epoch 8/50\n",
      "5009/5009 [==============================] - 30s 6ms/step - loss: 0.0064 - val_loss: 0.0021\n",
      "Epoch 9/50\n",
      "5009/5009 [==============================] - 30s 6ms/step - loss: 0.0064 - val_loss: 0.0014\n",
      "Epoch 10/50\n",
      "5009/5009 [==============================] - 29s 6ms/step - loss: 0.0064 - val_loss: 0.0015\n",
      "Epoch 11/50\n",
      "5009/5009 [==============================] - 29s 6ms/step - loss: 0.0064 - val_loss: 0.0018\n",
      "Epoch 12/50\n",
      "5002/5009 [============================>.] - ETA: 0s - loss: 0.0063Restoring model weights from the end of the best epoch: 2.\n",
      "5009/5009 [==============================] - 29s 6ms/step - loss: 0.0063 - val_loss: 0.0014\n",
      "Epoch 12: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para JAIBA en clúster 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 1s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 5ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para JAIBA en clúster 3: 248392092.21664965, R2 Mensual: 0.9830576374391502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: JAIBA, cluster: 6\n",
      "Epoch 1/50\n",
      "5663/5663 [==============================] - 40s 6ms/step - loss: 0.0082 - val_loss: 0.0051\n",
      "Epoch 2/50\n",
      "5663/5663 [==============================] - 33s 6ms/step - loss: 0.0070 - val_loss: 0.0073\n",
      "Epoch 3/50\n",
      "5663/5663 [==============================] - 34s 6ms/step - loss: 0.0069 - val_loss: 0.0051\n",
      "Epoch 4/50\n",
      "5663/5663 [==============================] - 33s 6ms/step - loss: 0.0067 - val_loss: 0.0044\n",
      "Epoch 5/50\n",
      "5663/5663 [==============================] - 33s 6ms/step - loss: 0.0067 - val_loss: 0.0044\n",
      "Epoch 6/50\n",
      "5663/5663 [==============================] - 33s 6ms/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 7/50\n",
      "5663/5663 [==============================] - 33s 6ms/step - loss: 0.0067 - val_loss: 0.0046\n",
      "Epoch 8/50\n",
      "5663/5663 [==============================] - 33s 6ms/step - loss: 0.0067 - val_loss: 0.0044\n",
      "Epoch 9/50\n",
      "5663/5663 [==============================] - 33s 6ms/step - loss: 0.0067 - val_loss: 0.0044\n",
      "Epoch 10/50\n",
      "5663/5663 [==============================] - 33s 6ms/step - loss: 0.0067 - val_loss: 0.0047\n",
      "Epoch 11/50\n",
      "5663/5663 [==============================] - 33s 6ms/step - loss: 0.0067 - val_loss: 0.0044\n",
      "Epoch 12/50\n",
      "5663/5663 [==============================] - 33s 6ms/step - loss: 0.0066 - val_loss: 0.0048\n",
      "Epoch 13/50\n",
      "5663/5663 [==============================] - 33s 6ms/step - loss: 0.0066 - val_loss: 0.0044\n",
      "Epoch 14/50\n",
      "5663/5663 [==============================] - 33s 6ms/step - loss: 0.0066 - val_loss: 0.0048\n",
      "Epoch 15/50\n",
      "5656/5663 [============================>.] - ETA: 0s - loss: 0.0066Restoring model weights from the end of the best epoch: 5.\n",
      "5663/5663 [==============================] - 33s 6ms/step - loss: 0.0066 - val_loss: 0.0045\n",
      "Epoch 15: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para JAIBA en clúster 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para JAIBA en clúster 6: 769300439.6108327, R2 Mensual: 0.9833410633178018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: JAIBA, cluster: 5\n",
      "Epoch 1/50\n",
      "75/75 [==============================] - 7s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "71/75 [===========================>..] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "75/75 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para JAIBA en clúster 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "MSE Mensual para JAIBA en clúster 5: 10712054.333333334, R2 Mensual: -1.1758235381936815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: JAIBA, cluster: 2\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 75ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "11/15 [=====================>........] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "15/15 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para JAIBA en clúster 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 986ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "MSE Mensual para JAIBA en clúster 2: 21800.0, R2 Mensual: -3.4489795918367347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: JAIBA, cluster: 1\n",
      "Epoch 1/50\n",
      "42246/42246 [==============================] - 255s 6ms/step - loss: 3.4339e-05 - val_loss: 7.7117e-06\n",
      "Epoch 2/50\n",
      "42246/42246 [==============================] - 245s 6ms/step - loss: 3.3976e-05 - val_loss: 7.9267e-06\n",
      "Epoch 3/50\n",
      "42246/42246 [==============================] - 246s 6ms/step - loss: 3.3963e-05 - val_loss: 7.6981e-06\n",
      "Epoch 4/50\n",
      "42246/42246 [==============================] - 243s 6ms/step - loss: 3.3792e-05 - val_loss: 7.6621e-06\n",
      "Epoch 5/50\n",
      "42246/42246 [==============================] - 237s 6ms/step - loss: 3.4113e-05 - val_loss: 7.7787e-06\n",
      "Epoch 6/50\n",
      "42246/42246 [==============================] - 237s 6ms/step - loss: 3.3819e-05 - val_loss: 7.6972e-06\n",
      "Epoch 7/50\n",
      "42246/42246 [==============================] - 236s 6ms/step - loss: 3.4031e-05 - val_loss: 7.8095e-06\n",
      "Epoch 8/50\n",
      "42246/42246 [==============================] - 236s 6ms/step - loss: 3.4025e-05 - val_loss: 7.7469e-06\n",
      "Epoch 9/50\n",
      "42246/42246 [==============================] - 234s 6ms/step - loss: 3.3937e-05 - val_loss: 1.2622e-05\n",
      "Epoch 10/50\n",
      "42246/42246 [==============================] - 234s 6ms/step - loss: 3.4100e-05 - val_loss: 7.6594e-06\n",
      "Epoch 11/50\n",
      "42246/42246 [==============================] - 233s 6ms/step - loss: 3.3947e-05 - val_loss: 7.7915e-06\n",
      "Epoch 12/50\n",
      "42246/42246 [==============================] - 234s 6ms/step - loss: 3.4241e-05 - val_loss: 7.7871e-06\n",
      "Epoch 13/50\n",
      "42246/42246 [==============================] - 232s 5ms/step - loss: 3.4156e-05 - val_loss: 7.8180e-06\n",
      "Epoch 14/50\n",
      "42246/42246 [==============================] - 234s 6ms/step - loss: 3.4051e-05 - val_loss: 7.8726e-06\n",
      "Epoch 15/50\n",
      "42246/42246 [==============================] - 232s 5ms/step - loss: 3.4095e-05 - val_loss: 8.5216e-06\n",
      "Epoch 16/50\n",
      "42246/42246 [==============================] - 232s 5ms/step - loss: 3.4108e-05 - val_loss: 7.8870e-06\n",
      "Epoch 17/50\n",
      "42246/42246 [==============================] - 233s 6ms/step - loss: 3.4022e-05 - val_loss: 8.4389e-06\n",
      "Epoch 18/50\n",
      "42246/42246 [==============================] - 233s 6ms/step - loss: 3.3992e-05 - val_loss: 7.7070e-06\n",
      "Epoch 19/50\n",
      "42246/42246 [==============================] - 231s 5ms/step - loss: 3.4014e-05 - val_loss: 7.6537e-06\n",
      "Epoch 20/50\n",
      "42246/42246 [==============================] - 236s 6ms/step - loss: 3.3930e-05 - val_loss: 9.8634e-06\n",
      "Epoch 21/50\n",
      "42246/42246 [==============================] - 235s 6ms/step - loss: 3.3874e-05 - val_loss: 1.3033e-05\n",
      "Epoch 22/50\n",
      "42246/42246 [==============================] - 234s 6ms/step - loss: 3.3842e-05 - val_loss: 7.0848e-06\n",
      "Epoch 23/50\n",
      "42246/42246 [==============================] - 235s 6ms/step - loss: 3.4306e-05 - val_loss: 1.5564e-05\n",
      "Epoch 24/50\n",
      "42246/42246 [==============================] - 233s 6ms/step - loss: 3.3386e-05 - val_loss: 6.4490e-06\n",
      "Epoch 25/50\n",
      "42246/42246 [==============================] - 233s 6ms/step - loss: 3.3245e-05 - val_loss: 6.0200e-06\n",
      "Epoch 26/50\n",
      "42246/42246 [==============================] - 232s 5ms/step - loss: 3.2946e-05 - val_loss: 6.4632e-06\n",
      "Epoch 27/50\n",
      "42246/42246 [==============================] - 234s 6ms/step - loss: 3.2834e-05 - val_loss: 7.9457e-06\n",
      "Epoch 28/50\n",
      "42246/42246 [==============================] - 232s 5ms/step - loss: 3.3267e-05 - val_loss: 6.3217e-06\n",
      "Epoch 29/50\n",
      "42246/42246 [==============================] - 231s 5ms/step - loss: 3.2609e-05 - val_loss: 8.9732e-06\n",
      "Epoch 30/50\n",
      "42246/42246 [==============================] - 235s 6ms/step - loss: 3.2621e-05 - val_loss: 7.1178e-06\n",
      "Epoch 31/50\n",
      "42246/42246 [==============================] - 233s 6ms/step - loss: 3.2340e-05 - val_loss: 5.5783e-06\n",
      "Epoch 32/50\n",
      "42246/42246 [==============================] - 233s 6ms/step - loss: 3.2446e-05 - val_loss: 8.0894e-06\n",
      "Epoch 33/50\n",
      "42246/42246 [==============================] - 237s 6ms/step - loss: 3.2441e-05 - val_loss: 6.3389e-06\n",
      "Epoch 34/50\n",
      "42246/42246 [==============================] - 232s 5ms/step - loss: 3.2473e-05 - val_loss: 5.8616e-06\n",
      "Epoch 35/50\n",
      "42246/42246 [==============================] - 236s 6ms/step - loss: 3.2212e-05 - val_loss: 7.3592e-06\n",
      "Epoch 36/50\n",
      "42246/42246 [==============================] - 234s 6ms/step - loss: 3.2538e-05 - val_loss: 6.8029e-06\n",
      "Epoch 37/50\n",
      "42246/42246 [==============================] - 232s 6ms/step - loss: 3.2352e-05 - val_loss: 5.6502e-06\n",
      "Epoch 38/50\n",
      "42246/42246 [==============================] - 234s 6ms/step - loss: 3.2254e-05 - val_loss: 5.4989e-06\n",
      "Epoch 39/50\n",
      "42246/42246 [==============================] - 231s 5ms/step - loss: 3.2222e-05 - val_loss: 7.4224e-06\n",
      "Epoch 40/50\n",
      "42246/42246 [==============================] - 231s 5ms/step - loss: 3.2215e-05 - val_loss: 6.4502e-06\n",
      "Epoch 41/50\n",
      "42246/42246 [==============================] - 233s 6ms/step - loss: 3.2112e-05 - val_loss: 5.8784e-06\n",
      "Epoch 42/50\n",
      "42246/42246 [==============================] - 231s 5ms/step - loss: 3.2248e-05 - val_loss: 5.3887e-06\n",
      "Epoch 43/50\n",
      "42246/42246 [==============================] - 230s 5ms/step - loss: 3.2162e-05 - val_loss: 5.4763e-06\n",
      "Epoch 44/50\n",
      "42246/42246 [==============================] - 232s 5ms/step - loss: 3.2138e-05 - val_loss: 5.4945e-06\n",
      "Epoch 45/50\n",
      "42246/42246 [==============================] - 234s 6ms/step - loss: 3.2135e-05 - val_loss: 6.0200e-06\n",
      "Epoch 46/50\n",
      "42246/42246 [==============================] - 232s 5ms/step - loss: 3.2184e-05 - val_loss: 7.0124e-06\n",
      "Epoch 47/50\n",
      "42246/42246 [==============================] - 235s 6ms/step - loss: 3.2227e-05 - val_loss: 6.0804e-06\n",
      "Epoch 48/50\n",
      "42246/42246 [==============================] - 234s 6ms/step - loss: 3.1920e-05 - val_loss: 5.8429e-06\n",
      "Epoch 49/50\n",
      "42246/42246 [==============================] - 231s 5ms/step - loss: 3.2045e-05 - val_loss: 6.2900e-06\n",
      "Epoch 50/50\n",
      "42246/42246 [==============================] - 236s 6ms/step - loss: 3.1995e-05 - val_loss: 6.1850e-06\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para JAIBA en clúster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373/373 [==============================] - 2s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n",
      "373/373 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Mensual para JAIBA en clúster 1: 632586131327.2977, R2 Mensual: 0.3199457291747587\n",
      "Training model for species: JAIBA, cluster: 4\n",
      "Epoch 1/50\n",
      "682/682 [==============================] - 11s 7ms/step - loss: 0.0056 - val_loss: 0.0031\n",
      "Epoch 2/50\n",
      "682/682 [==============================] - 4s 6ms/step - loss: 0.0055 - val_loss: 0.0023\n",
      "Epoch 3/50\n",
      "682/682 [==============================] - 4s 6ms/step - loss: 0.0055 - val_loss: 0.0028\n",
      "Epoch 4/50\n",
      "682/682 [==============================] - 4s 6ms/step - loss: 0.0054 - val_loss: 0.0024\n",
      "Epoch 5/50\n",
      "682/682 [==============================] - 4s 6ms/step - loss: 0.0054 - val_loss: 0.0024\n",
      "Epoch 6/50\n",
      "682/682 [==============================] - 4s 6ms/step - loss: 0.0054 - val_loss: 0.0024\n",
      "Epoch 7/50\n",
      "682/682 [==============================] - 4s 6ms/step - loss: 0.0052 - val_loss: 0.0024\n",
      "Epoch 8/50\n",
      "682/682 [==============================] - 4s 6ms/step - loss: 0.0054 - val_loss: 0.0024\n",
      "Epoch 9/50\n",
      "682/682 [==============================] - 4s 6ms/step - loss: 0.0054 - val_loss: 0.0024\n",
      "Epoch 10/50\n",
      "682/682 [==============================] - 4s 6ms/step - loss: 0.0054 - val_loss: 0.0024\n",
      "Epoch 11/50\n",
      "682/682 [==============================] - 4s 6ms/step - loss: 0.0054 - val_loss: 0.0024\n",
      "Epoch 12/50\n",
      "676/682 [============================>.] - ETA: 0s - loss: 0.0053Restoring model weights from the end of the best epoch: 2.\n",
      "682/682 [==============================] - 4s 6ms/step - loss: 0.0053 - val_loss: 0.0024\n",
      "Epoch 12: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para JAIBA en clúster 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para JAIBA en clúster 4: 228595873.58608225, R2 Mensual: 0.7595639157451124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: LISA, cluster: 7\n",
      "Epoch 1/50\n",
      "3632/3632 [==============================] - 28s 6ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 2/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 3/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 4/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 5/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 6/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 7/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 8/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 9/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 10/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 11/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 12/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 13/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 14/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 15/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 16/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 17/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 18/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 19/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 20/50\n",
      "3632/3632 [==============================] - 20s 6ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 21/50\n",
      "3632/3632 [==============================] - 20s 6ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 22/50\n",
      "3632/3632 [==============================] - 20s 6ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 23/50\n",
      "3632/3632 [==============================] - 20s 6ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 24/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 25/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 26/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 27/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 28/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 29/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 30/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 31/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 32/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 33/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 34/50\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 35/50\n",
      "3624/3632 [============================>.] - ETA: 0s - loss: 0.0020Restoring model weights from the end of the best epoch: 25.\n",
      "3632/3632 [==============================] - 21s 6ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 35: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LISA en clúster 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para LISA en clúster 7: 14625346.96961593, R2 Mensual: 0.7950316504670287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: LISA, cluster: 0\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 7s 35ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "31/34 [==========================>...] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "34/34 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LISA en clúster 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 916ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "MSE Mensual para LISA en clúster 0: 2767882.5, R2 Mensual: -4255.643598615917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: LISA, cluster: 3\n",
      "Epoch 1/50\n",
      "9529/9529 [==============================] - 61s 6ms/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 2/50\n",
      "9529/9529 [==============================] - 54s 6ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 3/50\n",
      "9529/9529 [==============================] - 54s 6ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 4/50\n",
      "9529/9529 [==============================] - 54s 6ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 5/50\n",
      "9529/9529 [==============================] - 54s 6ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 6/50\n",
      "9529/9529 [==============================] - 54s 6ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 7/50\n",
      "9529/9529 [==============================] - 54s 6ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 8/50\n",
      "9529/9529 [==============================] - 54s 6ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 9/50\n",
      "9529/9529 [==============================] - 54s 6ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 10/50\n",
      "9529/9529 [==============================] - 54s 6ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 11/50\n",
      "9529/9529 [==============================] - 54s 6ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 12/50\n",
      "9529/9529 [==============================] - 54s 6ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 13/50\n",
      "9529/9529 [==============================] - 54s 6ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 14/50\n",
      "9529/9529 [==============================] - 54s 6ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 15/50\n",
      "9529/9529 [==============================] - 54s 6ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 16/50\n",
      "9529/9529 [==============================] - 54s 6ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 17/50\n",
      "9524/9529 [============================>.] - ETA: 0s - loss: 0.0012Restoring model weights from the end of the best epoch: 7.\n",
      "9529/9529 [==============================] - 54s 6ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 17: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LISA en clúster 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 4s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para LISA en clúster 3: 79820991.08185993, R2 Mensual: 0.6811762204605185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: LISA, cluster: 6\n",
      "Epoch 1/50\n",
      "840/840 [==============================] - 12s 7ms/step - loss: 0.0187 - val_loss: 0.0233\n",
      "Epoch 2/50\n",
      "840/840 [==============================] - 5s 6ms/step - loss: 0.0179 - val_loss: 0.0232\n",
      "Epoch 3/50\n",
      "840/840 [==============================] - 5s 6ms/step - loss: 0.0180 - val_loss: 0.0230\n",
      "Epoch 4/50\n",
      "840/840 [==============================] - 5s 6ms/step - loss: 0.0177 - val_loss: 0.0231\n",
      "Epoch 5/50\n",
      "840/840 [==============================] - 5s 6ms/step - loss: 0.0176 - val_loss: 0.0232\n",
      "Epoch 6/50\n",
      "840/840 [==============================] - 5s 6ms/step - loss: 0.0174 - val_loss: 0.0230\n",
      "Epoch 7/50\n",
      "840/840 [==============================] - 5s 6ms/step - loss: 0.0173 - val_loss: 0.0232\n",
      "Epoch 8/50\n",
      "840/840 [==============================] - 5s 6ms/step - loss: 0.0170 - val_loss: 0.0234\n",
      "Epoch 9/50\n",
      "840/840 [==============================] - 5s 6ms/step - loss: 0.0172 - val_loss: 0.0237\n",
      "Epoch 10/50\n",
      "840/840 [==============================] - 5s 6ms/step - loss: 0.0168 - val_loss: 0.0234\n",
      "Epoch 11/50\n",
      "840/840 [==============================] - 5s 6ms/step - loss: 0.0170 - val_loss: 0.0234\n",
      "Epoch 12/50\n",
      "840/840 [==============================] - 5s 6ms/step - loss: 0.0166 - val_loss: 0.0232\n",
      "Epoch 13/50\n",
      "840/840 [==============================] - 5s 6ms/step - loss: 0.0168 - val_loss: 0.0232\n",
      "Epoch 14/50\n",
      "840/840 [==============================] - 5s 6ms/step - loss: 0.0168 - val_loss: 0.0233\n",
      "Epoch 15/50\n",
      "840/840 [==============================] - 5s 6ms/step - loss: 0.0167 - val_loss: 0.0235\n",
      "Epoch 16/50\n",
      "831/840 [============================>.] - ETA: 0s - loss: 0.0163Restoring model weights from the end of the best epoch: 6.\n",
      "840/840 [==============================] - 5s 6ms/step - loss: 0.0163 - val_loss: 0.0242\n",
      "Epoch 16: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LISA en clúster 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para LISA en clúster 6: 3045974.8872343996, R2 Mensual: 0.9094131822193099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_29735/4225285831.py:60: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: LISA, cluster: 5\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 7s 502ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "1/3 [=========>....................] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LISA en clúster 5\n",
      "No se tienen datos suficientes para LISA en clúster 5 en los últimos seis meses de 2023\n",
      "Training model for species: LISA, cluster: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 7s 257ms/step - loss: 0.2735 - val_loss: 0.0322\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1606 - val_loss: 0.0181\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1178 - val_loss: 0.0285\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0719 - val_loss: 0.0378\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0510 - val_loss: 0.0481\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0333 - val_loss: 0.0765\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0260 - val_loss: 0.1193\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0234 - val_loss: 0.1416\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0196 - val_loss: 0.1541\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0152 - val_loss: 0.1597\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0162 - val_loss: 0.1624\n",
      "Epoch 12/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0087Restoring model weights from the end of the best epoch: 2.\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0134 - val_loss: 0.1587\n",
      "Epoch 12: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LISA en clúster 2\n",
      "No se tienen datos suficientes para LISA en clúster 2 en los últimos seis meses de 2023\n",
      "Training model for species: LISA, cluster: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5975/5975 [==============================] - 41s 6ms/step - loss: 0.0072 - val_loss: 0.0066\n",
      "Epoch 2/50\n",
      "5975/5975 [==============================] - 35s 6ms/step - loss: 0.0070 - val_loss: 0.0065\n",
      "Epoch 3/50\n",
      "4254/5975 [====================>.........] - ETA: 9s - loss: 0.0066"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining model for species: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspecies_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, cluster: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcluster_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m     model, scaler \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_save_moe_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspecies_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlook_back\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# Guardar los datos para las bandas de confianza\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     test_data_2023 \u001b[38;5;241m=\u001b[39m filtered_data[(filtered_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2023\u001b[39m) \u001b[38;5;241m&\u001b[39m (filtered_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)]\n",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m, in \u001b[0;36mtrain_and_save_moe_model\u001b[0;34m(data, species_name, cluster_label, look_back, epochs, batch_size)\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m create_moe_model((look_back, X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]))\n\u001b[1;32m      6\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 7\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Guardar el modelo y el scaler\u001b[39;00m\n\u001b[1;32m     10\u001b[0m model_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodelos_moe\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/conda/envs/cedo/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/envs/cedo/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/conda/envs/cedo/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/conda/envs/cedo/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/cedo/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/conda/envs/cedo/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/conda/envs/cedo/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/cedo/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/opt/conda/envs/cedo/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Obtener listas de especies y clústeres únicos\n",
    "unique_species = data['species'].unique()\n",
    "unique_clusters = data['Cluster_Label'].unique()\n",
    "\n",
    "# Definir la especie y clúster desde donde retomar el proceso y detenerlo\n",
    "start_species = 'BANDERA'\n",
    "start_cluster = 7.0\n",
    "stop_species = 'BANDERA'\n",
    "stop_cluster = 8.0\n",
    "\n",
    "# Inicializar banderas\n",
    "start_training = False\n",
    "stop_training = False\n",
    "\n",
    "\n",
    "\n",
    "for species_name in unique_species:\n",
    "    for cluster_label in unique_clusters:\n",
    "        # Activar la bandera cuando se alcance la especie y clúster deseados para iniciar\n",
    "        if species_name == start_species and cluster_label == start_cluster:\n",
    "            start_training = True\n",
    "        \n",
    "        # Detener el proceso cuando se alcance la especie y clúster deseados para detener\n",
    "        if species_name == stop_species and cluster_label == stop_cluster:\n",
    "            stop_training = True\n",
    "        \n",
    "        # Continuar solo si la bandera de inicio está activada y la de detener no lo está\n",
    "        if start_training and not stop_training:\n",
    "            # Filtrar los datos para obtener una especie y un clúster específico\n",
    "            filtered_data = data[(data['species'] == species_name) & (data['Cluster_Label'] == cluster_label)]\n",
    "            \n",
    "            if len(filtered_data) >= look_back:\n",
    "                filtered_data = filtered_data.sort_values('date')\n",
    "                try:\n",
    "                    print(f'Training model for species: {species_name}, cluster: {cluster_label}')\n",
    "                    model, scaler = train_and_save_moe_model(filtered_data, species_name, cluster_label, look_back)\n",
    "\n",
    "                    # Guardar los datos para las bandas de confianza\n",
    "                    test_data_2023 = filtered_data[(filtered_data['date'].dt.year == 2023) & (filtered_data['date'].dt.month >= 1)]\n",
    "                    if len(test_data_2023) >= look_back:\n",
    "                        predictions, lower_bound, upper_bound = predict_with_confidence_intervals(model, scaler, test_data_2023, look_back)\n",
    "                        real_values = test_data_2023['landed_w_kg'].values[look_back:]\n",
    "                        \n",
    "                        # Crear un DataFrame para los resultados\n",
    "                        results_df = pd.DataFrame({\n",
    "                            'date': test_data_2023['date'].values[look_back:],\n",
    "                            'real_values': real_values,\n",
    "                            'predictions': predictions,\n",
    "                            'lower_bound': lower_bound,\n",
    "                            'upper_bound': upper_bound\n",
    "                        })\n",
    "                        \n",
    "                        # Guardar los resultados\n",
    "                        results_directory = 'resultados_moe'\n",
    "                        os.makedirs(results_directory, exist_ok=True)\n",
    "                        results_path = os.path.join(results_directory, f'{species_name}_cluster_{cluster_label}_predictions.csv')\n",
    "                        results_df.to_csv(results_path, index=False)\n",
    "                        \n",
    "                        # Agrupar por mes y sumar los valores\n",
    "                        monthly_totals = results_df.set_index('date').resample('M').sum()\n",
    "                        \n",
    "                        # Calcular MSE y R2 para los totales mensuales\n",
    "                        mse = mean_squared_error(monthly_totals['real_values'], monthly_totals['predictions'])\n",
    "                        r2 = r2_score(monthly_totals['real_values'], monthly_totals['predictions'])\n",
    "                        print(f'MSE Mensual para {species_name} en clúster {cluster_label}: {mse}, R2 Mensual: {r2}')\n",
    "                        \n",
    "                        # Crear figura\n",
    "                        plt.figure(figsize=(10, 6))\n",
    "                        plt.plot(monthly_totals.index, monthly_totals['real_values'], color='blue', label='Real')\n",
    "                        plt.plot(monthly_totals.index, monthly_totals['predictions'], color='red', linestyle='--', label='Predicho')\n",
    "                        plt.fill_between(monthly_totals.index, monthly_totals['lower_bound'], monthly_totals['upper_bound'], color='gray', alpha=0.2, label='Intervalo de Confianza 95%')\n",
    "                        plt.title(f'Totales Mensuales de {species_name} en clúster {cluster_label} para los Últimos Seis Meses de 2023')\n",
    "                        plt.xlabel('Fecha')\n",
    "                        plt.ylabel('Peso Desembarcado (kg)')\n",
    "                        plt.legend()\n",
    "                        plot_path = os.path.join(results_directory, f'{species_name}_cluster_{cluster_label}_plot.png')\n",
    "                        plt.savefig(plot_path)\n",
    "                        plt.close()\n",
    "                    else:\n",
    "                        print(f'No se tienen datos suficientes para {species_name} en clúster {cluster_label} en los últimos seis meses de 2023')\n",
    "                except Exception as e:\n",
    "                    print(f'Error entrenando el modelo para especie: {species_name}, clúster: {cluster_label}. Error: {e}')\n",
    "        \n",
    "        # Salir del bucle si se alcanza el punto de detener\n",
    "        if stop_training:\n",
    "            break\n",
    "    if stop_training:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cedo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
