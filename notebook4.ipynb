{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 21:11:28.236813: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-27 21:11:28.239838: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-27 21:11:28.281413: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-27 21:11:28.281459: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-27 21:11:28.282932: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-27 21:11:28.291111: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-27 21:11:28.293060: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-27 21:11:29.152162: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Dense, Dropout, Input, Conv1D, Flatten, concatenate\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Definir look_back\n",
    "look_back = 6  # Cambia este valor según tus necesidades\n",
    "\n",
    "# Cargar el archivo y eliminar filas donde el clúster es NaN\n",
    "file_path = 'data/data.csv'  # Cambia esta ruta al archivo que has subido\n",
    "data = pd.read_csv(file_path)\n",
    "data = data.dropna(subset=['Cluster_Label'])\n",
    "# Convertir 'year' y 'month_no' a una sola columna de tipo fecha\n",
    "data['date'] = pd.to_datetime(data['year'].astype(str) + '-' + data['month_no'].astype(str))\n",
    "\n",
    "# Seleccionar las columnas necesarias para la serie temporal\n",
    "columns_to_keep = ['date', 'species', 'Cluster_Label', 'landed_w_kg', 'value_mxn',\n",
    "                   '0.49402499_m', '1.541375_m', '2.645669_m', '3.819495_m', '5.0782242_m',\n",
    "                   '6.4406142_m', '7.9295602_m', '9.5729971_m', 'mean_temp']\n",
    "data = data[columns_to_keep]\n",
    "\n",
    "# Filtrar los datos para obtener una especie y un clúster específico\n",
    "species_name = 'PARGO'  # Cambia esto a la especie que deseas usar\n",
    "cluster_label = 1  # Cambia esto al clúster que deseas usar\n",
    "filtered_data = data[(data['species'] == species_name) & (data['Cluster_Label'] == cluster_label)]\n",
    "\n",
    "# Ordenar por fecha\n",
    "filtered_data = filtered_data.sort_values('date')\n",
    "\n",
    "# Función para preparar los datos\n",
    "def prepare_data(group, look_back=6):\n",
    "    features = ['landed_w_kg','Cluster_Label', '0.49402499_m', '1.541375_m', '2.645669_m', '3.819495_m', \n",
    "                '5.0782242_m', '6.4406142_m', '7.9295602_m', '9.5729971_m', 'mean_temp']\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    group_scaled = scaler.fit_transform(group[features])\n",
    "    \n",
    "    X, y = [], []\n",
    "    for i in range(len(group_scaled) - look_back):\n",
    "        a = group_scaled[i:(i + look_back)]\n",
    "        X.append(a)\n",
    "        y.append(group_scaled[i + look_back, 0])  # La primera columna es 'landed_w_kg'\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2]))\n",
    "    return X, y, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crear el modelo LSTM\n",
    "def create_lstm_model(input_shape):\n",
    "    lstm_input = Input(shape=input_shape)\n",
    "    x = LSTM(50, return_sequences=True)(lstm_input)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = LSTM(25, activation='relu', return_sequences=True)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = LSTM(12, activation='linear')(x)\n",
    "    lstm_output = Dense(1, activation='linear')(x)\n",
    "    return Model(inputs=lstm_input, outputs=lstm_output)\n",
    "\n",
    "# Crear el modelo DNN\n",
    "def create_dnn_model(input_shape):\n",
    "    dnn_input = Input(shape=(input_shape[0], input_shape[1]))\n",
    "    x = Flatten()(dnn_input)\n",
    "    x = Dense(10, activation='relu')(x)\n",
    "    x = Dense(5, activation='relu')(x)\n",
    "    dnn_output = Dense(1, activation='linear')(x)\n",
    "    return Model(inputs=dnn_input, outputs=dnn_output)\n",
    "\n",
    "# Crear el modelo CNN\n",
    "def create_cnn_model(input_shape):\n",
    "    cnn_input = Input(shape=input_shape)\n",
    "    x = Conv1D(32, kernel_size=3, activation='relu')(cnn_input)\n",
    "    x = Flatten()(x)\n",
    "    cnn_output = Dense(1, activation='linear')(x)\n",
    "    return Model(inputs=cnn_input, outputs=cnn_output)\n",
    "\n",
    "# Crear el modelo Mixture of Experts (MoE)\n",
    "def create_moe_model(input_shape):\n",
    "    # Definir los expertos\n",
    "    lstm_model = create_lstm_model(input_shape)\n",
    "    dnn_model = create_dnn_model(input_shape)\n",
    "    cnn_model = create_cnn_model(input_shape)\n",
    "    \n",
    "    # Definir el gating network\n",
    "    moe_input = Input(shape=input_shape)\n",
    "    x = Flatten()(moe_input)\n",
    "    x = Dense(10, activation='relu')(x)\n",
    "    gate_output = Dense(3, activation='softmax')(x)  # Tres expertos\n",
    "\n",
    "    # Obtener las salidas de los expertos\n",
    "    lstm_output = lstm_model(moe_input)\n",
    "    dnn_output = dnn_model(moe_input)\n",
    "    cnn_output = cnn_model(moe_input)\n",
    "    \n",
    "    # Combinar las salidas usando el gating network\n",
    "    output = concatenate([lstm_output * gate_output[:, 0:1],\n",
    "                          dnn_output * gate_output[:, 1:2],\n",
    "                          cnn_output * gate_output[:, 2:3]], axis=1)\n",
    "    output = Dense(1, activation='linear')(output)\n",
    "    \n",
    "    model = Model(inputs=moe_input, outputs=output)\n",
    "    model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Función para entrenar y guardar el modelo MoE\n",
    "def train_and_save_moe_model(data, species_name, look_back=6, epochs=50, batch_size=1):\n",
    "    X, y, scaler = prepare_data(data, look_back)\n",
    "    model = create_moe_model((look_back, X.shape[2]))\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "    model.fit(X, y, validation_split=0.2, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[early_stopping])\n",
    "    \n",
    "    # Guardar el modelo y el scaler\n",
    "    model_directory = 'modelos_moe'\n",
    "    os.makedirs(model_directory, exist_ok=True)\n",
    "    model_path = os.path.join(model_directory, f'{species_name}_moe_model.h5')\n",
    "    scaler_path = os.path.join(model_directory, f'{species_name}_moe_scaler.pkl')\n",
    "    model.save(model_path)\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    \n",
    "    print(f'Modelo MoE y scaler guardados para {species_name}')\n",
    "    return model, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13066/13066 [==============================] - 70s 5ms/step - loss: 7.1201e-04 - val_loss: 7.3696e-04\n",
      "Epoch 2/50\n",
      "13066/13066 [==============================] - 66s 5ms/step - loss: 6.7154e-04 - val_loss: 6.9218e-04\n",
      "Epoch 3/50\n",
      "13066/13066 [==============================] - 65s 5ms/step - loss: 6.5647e-04 - val_loss: 6.7984e-04\n",
      "Epoch 4/50\n",
      "13066/13066 [==============================] - 65s 5ms/step - loss: 6.4231e-04 - val_loss: 6.8165e-04\n",
      "Epoch 5/50\n",
      "13066/13066 [==============================] - 65s 5ms/step - loss: 6.3931e-04 - val_loss: 6.9292e-04\n",
      "Epoch 6/50\n",
      "13066/13066 [==============================] - 64s 5ms/step - loss: 6.3472e-04 - val_loss: 6.8212e-04\n",
      "Epoch 7/50\n",
      "13066/13066 [==============================] - 64s 5ms/step - loss: 6.3162e-04 - val_loss: 6.3398e-04\n",
      "Epoch 8/50\n",
      "13066/13066 [==============================] - 64s 5ms/step - loss: 6.3222e-04 - val_loss: 6.3550e-04\n",
      "Epoch 9/50\n",
      "13066/13066 [==============================] - 65s 5ms/step - loss: 6.2935e-04 - val_loss: 6.5658e-04\n",
      "Epoch 10/50\n",
      " 2394/13066 [====>.........................] - ETA: 48s - loss: 9.5387e-04"
     ]
    }
   ],
   "source": [
    "\n",
    "# Entrenar el modelo MoE\n",
    "model, scaler = train_and_save_moe_model(filtered_data, species_name, look_back)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# Función para hacer predicciones con el modelo MoE\n",
    "def predict_with_moe_model(species_name, data, look_back=6):\n",
    "    model_path = f'modelos_moe/{species_name}_moe_model.h5'\n",
    "    scaler_path = f'modelos_moe/{species_name}_moe_scaler.pkl'\n",
    "    \n",
    "    model = load_model(model_path)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    \n",
    "    features = ['landed_w_kg','Cluster_Label', '0.49402499_m', '1.541375_m', '2.645669_m', '3.819495_m', \n",
    "                '5.0782242_m', '6.4406142_m', '7.9295602_m', '9.5729971_m', 'mean_temp']\n",
    "    group_scaled = scaler.transform(data[features])\n",
    "    \n",
    "    X = []\n",
    "    for i in range(len(group_scaled) - look_back):\n",
    "        a = group_scaled[i:(i + look_back)]\n",
    "        X.append(a)\n",
    "    X = np.array(X)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2]))\n",
    "    \n",
    "    prediction_scaled = model.predict(X)\n",
    "    prediction = scaler.inverse_transform(np.hstack((prediction_scaled, X[:, -1, 1:])))[:, 0]\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# Filtrar los datos para el año 2023 y realizar predicciones\n",
    "test_data_2023 = filtered_data[filtered_data['date'].dt.year == 2023]\n",
    "if len(test_data_2023) >= look_back:\n",
    "    predictions = predict_with_moe_model(species_name, test_data_2023, look_back)\n",
    "    real_values = test_data_2023['landed_w_kg'].values[look_back:]\n",
    "    \n",
    "    mse, r2 = mean_squared_error(real_values, predictions), r2_score(real_values, predictions)\n",
    "    print(f'MSE: {mse}, R2: {r2}')\n",
    "    \n",
    "    # Crear figura\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(real_values, color='blue', label='Real')\n",
    "    plt.plot(predictions, color='red', linestyle='--', label='Predicho')\n",
    "    plt.title(f'Pronóstico de {species_name} en 2023')\n",
    "    plt.xlabel('Tiempo')\n",
    "    plt.ylabel('Peso Desembarcado (kg)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f'No se tienen datos suficientes para {species_name} en 2023')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cedo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
