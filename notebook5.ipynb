{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import LSTM, Dense, Dropout, Input, Conv1D, Flatten, concatenate\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Definir look_back\n",
    "look_back = 6  \n",
    "\n",
    "# Cargar el archivo y eliminar filas donde el clúster es NaN\n",
    "file_path = 'data/data.csv'   # Cambia esta ruta al archivo que has subido\n",
    "data = pd.read_csv(file_path)\n",
    "data = data.dropna(subset=['Cluster_Label'])\n",
    "\n",
    "# Convertir 'year' y 'month_no' a una sola columna de tipo fecha\n",
    "data['date'] = pd.to_datetime(data['year'].astype(str) + '-' + data['month_no'].astype(str))\n",
    "\n",
    "# Seleccionar las columnas necesarias para la serie temporal\n",
    "columns_to_keep = ['date', 'species', 'Cluster_Label', 'landed_w_kg', \n",
    "                   '0.49402499_m', '1.541375_m', '2.645669_m', '3.819495_m', '5.0782242_m',\n",
    "                   '6.4406142_m', '7.9295602_m', '9.5729971_m', 'mean_temp']\n",
    "data = data[columns_to_keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para preparar los datos\n",
    "def prepare_data(group, look_back=6):\n",
    "    features = ['landed_w_kg','Cluster_Label', '0.49402499_m', '1.541375_m', '2.645669_m', '3.819495_m', \n",
    "                '5.0782242_m', '6.4406142_m', '7.9295602_m', '9.5729971_m', 'mean_temp']\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    group_scaled = scaler.fit_transform(group[features])\n",
    "    \n",
    "    X, y = [], []\n",
    "    for i in range(len(group_scaled) - look_back):\n",
    "        a = group_scaled[i:(i + look_back)]\n",
    "        X.append(a)\n",
    "        y.append(group_scaled[i + look_back, 0])  # La primera columna es 'landed_w_kg'\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2]))\n",
    "    return X, y, scaler\n",
    "\n",
    "# Crear el modelo LSTM\n",
    "def create_lstm_model(input_shape):\n",
    "    lstm_input = Input(shape=input_shape)\n",
    "    x = LSTM(50, return_sequences=True)(lstm_input)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = LSTM(25, activation='relu', return_sequences=True)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = LSTM(12, activation='linear')(x)\n",
    "    lstm_output = Dense(1, activation='linear')(x)\n",
    "    return Model(inputs=lstm_input, outputs=lstm_output)\n",
    "\n",
    "# Crear el modelo DNN\n",
    "def create_dnn_model(input_shape):\n",
    "    dnn_input = Input(shape=(input_shape[0], input_shape[1]))\n",
    "    x = Flatten()(dnn_input)\n",
    "    x = Dense(10, activation='relu')(x)\n",
    "    x = Dense(5, activation='relu')(x)\n",
    "    dnn_output = Dense(1, activation='linear')(x)\n",
    "    return Model(inputs=dnn_input, outputs=dnn_output)\n",
    "\n",
    "# Crear el modelo CNN\n",
    "def create_cnn_model(input_shape):\n",
    "    cnn_input = Input(shape=input_shape)\n",
    "    x = Conv1D(32, kernel_size=3, activation='relu')(cnn_input)\n",
    "    x = Flatten()(x)\n",
    "    cnn_output = Dense(1, activation='linear')(x)\n",
    "    return Model(inputs=cnn_input, outputs=cnn_output)\n",
    "\n",
    "# Crear el modelo Mixture of Experts (MoE)\n",
    "def create_moe_model(input_shape):\n",
    "    # Definir los expertos\n",
    "    lstm_model = create_lstm_model(input_shape)\n",
    "    dnn_model = create_dnn_model(input_shape)\n",
    "    cnn_model = create_cnn_model(input_shape)\n",
    "    \n",
    "    # Definir el gating network\n",
    "    moe_input = Input(shape=input_shape)\n",
    "    x = Flatten()(moe_input)\n",
    "    x = Dense(10, activation='relu')(x)\n",
    "    gate_output = Dense(3, activation='softmax')(x)  # Tres expertos\n",
    "\n",
    "    # Obtener las salidas de los expertos\n",
    "    lstm_output = lstm_model(moe_input)\n",
    "    dnn_output = dnn_model(moe_input)\n",
    "    cnn_output = cnn_model(moe_input)\n",
    "    \n",
    "    # Combinar las salidas usando el gating network\n",
    "    output = concatenate([lstm_output * gate_output[:, 0:1],\n",
    "                          dnn_output * gate_output[:, 1:2],\n",
    "                          cnn_output * gate_output[:, 2:3]], axis=1)\n",
    "    output = Dense(1, activation='linear')(output)\n",
    "    \n",
    "    model = Model(inputs=moe_input, outputs=output)\n",
    "    model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar y guardar el modelo MoE\n",
    "def train_and_save_moe_model(data, species_name, cluster_label, look_back=look_back, epochs=50, batch_size=1):\n",
    "    X, y, scaler = prepare_data(data, look_back)\n",
    "    model = create_moe_model((look_back, X.shape[2]))\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "    history = model.fit(X, y, validation_split=0.2, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[early_stopping])\n",
    "    \n",
    "    # Guardar el modelo y el scaler\n",
    "    model_directory = 'modelos_moe'\n",
    "    os.makedirs(model_directory, exist_ok=True)\n",
    "    model_path = os.path.join(model_directory, f'{species_name}_cluster_{cluster_label}_moe_model.h5')\n",
    "    scaler_path = os.path.join(model_directory, f'{species_name}_cluster_{cluster_label}_moe_scaler.pkl')\n",
    "    model.save(model_path)\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    \n",
    "    # Guardar los valores de monitoreo del entrenamiento\n",
    "    train_moe_directory = 'train_moe'\n",
    "    os.makedirs(train_moe_directory, exist_ok=True)\n",
    "    history_path = os.path.join(train_moe_directory, f'{species_name}_cluster_{cluster_label}_training_history.csv')\n",
    "    pd.DataFrame(history.history).to_csv(history_path, index=False)\n",
    "    \n",
    "    print(f'Modelo MoE, scaler y datos de entrenamiento guardados para {species_name} en clúster {cluster_label}')\n",
    "    return model, scaler\n",
    "\n",
    "# Función para hacer predicciones con bandas de confianza usando bootstrap\n",
    "def predict_with_confidence_intervals(model, scaler, data, look_back=6, n_bootstrap=100, alpha=0.01):\n",
    "    features = ['landed_w_kg','Cluster_Label', '0.49402499_m', '1.541375_m', '2.645669_m', '3.819495_m', \n",
    "                '5.0782242_m', '6.4406142_m', '7.9295602_m', '9.5729971_m', 'mean_temp']\n",
    "    group_scaled = scaler.transform(data[features])\n",
    "\n",
    "    X = []\n",
    "    for i in range(len(group_scaled) - look_back):\n",
    "        a = group_scaled[i:(i + look_back)]\n",
    "        X.append(a)\n",
    "    X = np.array(X)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2]))\n",
    "    \n",
    "    predictions = model.predict(X)\n",
    "    predictions = scaler.inverse_transform(np.hstack((predictions, X[:, -1, 1:])))[:, 0]\n",
    "    \n",
    "    # Bootstrap para bandas de confianza\n",
    "    bootstrap_predictions = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        indices = np.random.choice(range(len(X)), len(X), replace=True)\n",
    "        X_sample = X[indices]\n",
    "        pred_sample = model.predict(X_sample)\n",
    "        pred_sample = scaler.inverse_transform(np.hstack((pred_sample, X_sample[:, -1, 1:])))[:, 0]\n",
    "        bootstrap_predictions.append(pred_sample)\n",
    "    \n",
    "    bootstrap_predictions = np.array(bootstrap_predictions)\n",
    "    lower_bound = np.percentile(bootstrap_predictions, 100 * alpha / 2, axis=0)\n",
    "    upper_bound = np.percentile(bootstrap_predictions, 100 * (1 - alpha / 2), axis=0)\n",
    "    \n",
    "    return predictions, lower_bound, upper_bound\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: MOJARRA, cluster: 7.0\n",
      "Epoch 1/50\n",
      "18712/18712 [==============================] - 94s 5ms/step - loss: 5.9276e-04 - val_loss: 8.0594e-04\n",
      "Epoch 2/50\n",
      "18712/18712 [==============================] - 89s 5ms/step - loss: 5.1125e-04 - val_loss: 7.3812e-04\n",
      "Epoch 3/50\n",
      "18712/18712 [==============================] - 88s 5ms/step - loss: 5.0105e-04 - val_loss: 7.5179e-04\n",
      "Epoch 4/50\n",
      "18712/18712 [==============================] - 87s 5ms/step - loss: 4.9318e-04 - val_loss: 7.6189e-04\n",
      "Epoch 5/50\n",
      "18712/18712 [==============================] - 87s 5ms/step - loss: 4.8354e-04 - val_loss: 7.3254e-04\n",
      "Epoch 6/50\n",
      "18712/18712 [==============================] - 87s 5ms/step - loss: 4.8540e-04 - val_loss: 7.5158e-04\n",
      "Epoch 7/50\n",
      "18712/18712 [==============================] - 86s 5ms/step - loss: 4.8159e-04 - val_loss: 7.1317e-04\n",
      "Epoch 8/50\n",
      "18712/18712 [==============================] - 87s 5ms/step - loss: 4.8478e-04 - val_loss: 7.3145e-04\n",
      "Epoch 9/50\n",
      "18712/18712 [==============================] - 87s 5ms/step - loss: 4.7858e-04 - val_loss: 7.3962e-04\n",
      "Epoch 10/50\n",
      "18712/18712 [==============================] - 87s 5ms/step - loss: 4.7651e-04 - val_loss: 8.5891e-04\n",
      "Epoch 11/50\n",
      "18712/18712 [==============================] - 87s 5ms/step - loss: 4.8190e-04 - val_loss: 7.3451e-04\n",
      "Epoch 12/50\n",
      "18712/18712 [==============================] - 87s 5ms/step - loss: 4.7886e-04 - val_loss: 7.5455e-04\n",
      "Epoch 13/50\n",
      "18712/18712 [==============================] - 87s 5ms/step - loss: 4.8230e-04 - val_loss: 7.2369e-04\n",
      "Epoch 14/50\n",
      "18712/18712 [==============================] - 87s 5ms/step - loss: 4.8277e-04 - val_loss: 7.3877e-04\n",
      "Epoch 15/50\n",
      "18712/18712 [==============================] - 87s 5ms/step - loss: 4.8021e-04 - val_loss: 8.1532e-04\n",
      "Epoch 16/50\n",
      "18712/18712 [==============================] - 87s 5ms/step - loss: 4.7795e-04 - val_loss: 7.1196e-04\n",
      "Epoch 17/50\n",
      "18712/18712 [==============================] - 87s 5ms/step - loss: 4.8199e-04 - val_loss: 7.5944e-04\n",
      "Epoch 18/50\n",
      "18712/18712 [==============================] - 87s 5ms/step - loss: 4.8248e-04 - val_loss: 7.2554e-04\n",
      "Epoch 19/50\n",
      "18712/18712 [==============================] - 87s 5ms/step - loss: 4.8240e-04 - val_loss: 7.1378e-04\n",
      "Epoch 20/50\n",
      "18712/18712 [==============================] - 87s 5ms/step - loss: 4.7762e-04 - val_loss: 7.3823e-04\n",
      "Epoch 21/50\n",
      "18712/18712 [==============================] - 87s 5ms/step - loss: 4.8410e-04 - val_loss: 7.3760e-04\n",
      "Epoch 22/50\n",
      "18712/18712 [==============================] - 87s 5ms/step - loss: 4.7626e-04 - val_loss: 7.4142e-04\n",
      "Epoch 23/50\n",
      "18712/18712 [==============================] - 87s 5ms/step - loss: 4.6996e-04 - val_loss: 7.2403e-04\n",
      "Epoch 24/50\n",
      "18712/18712 [==============================] - 87s 5ms/step - loss: 4.8001e-04 - val_loss: 7.4932e-04\n",
      "Epoch 25/50\n",
      "18712/18712 [==============================] - 87s 5ms/step - loss: 4.7675e-04 - val_loss: 7.0733e-04\n",
      "Epoch 26/50\n",
      "18712/18712 [==============================] - 87s 5ms/step - loss: 4.7223e-04 - val_loss: 8.2156e-04\n",
      "Epoch 27/50\n",
      "18712/18712 [==============================] - 85s 5ms/step - loss: 4.7348e-04 - val_loss: 7.1603e-04\n",
      "Epoch 28/50\n",
      "18712/18712 [==============================] - 84s 4ms/step - loss: 4.7064e-04 - val_loss: 9.1620e-04\n",
      "Epoch 29/50\n",
      "18712/18712 [==============================] - 84s 4ms/step - loss: 4.7680e-04 - val_loss: 7.2905e-04\n",
      "Epoch 30/50\n",
      "18712/18712 [==============================] - 84s 4ms/step - loss: 4.6957e-04 - val_loss: 7.2313e-04\n",
      "Epoch 31/50\n",
      "18712/18712 [==============================] - 84s 4ms/step - loss: 4.7762e-04 - val_loss: 7.8210e-04\n",
      "Epoch 32/50\n",
      "18712/18712 [==============================] - 84s 4ms/step - loss: 4.7479e-04 - val_loss: 7.9191e-04\n",
      "Epoch 33/50\n",
      "18712/18712 [==============================] - 84s 4ms/step - loss: 4.7300e-04 - val_loss: 8.4923e-04\n",
      "Epoch 34/50\n",
      "18712/18712 [==============================] - 84s 5ms/step - loss: 4.8157e-04 - val_loss: 7.0655e-04\n",
      "Epoch 35/50\n",
      "18712/18712 [==============================] - 84s 4ms/step - loss: 4.7566e-04 - val_loss: 7.1805e-04\n",
      "Epoch 36/50\n",
      "18712/18712 [==============================] - 84s 4ms/step - loss: 4.7355e-04 - val_loss: 7.7935e-04\n",
      "Epoch 37/50\n",
      "18712/18712 [==============================] - 84s 5ms/step - loss: 4.8555e-04 - val_loss: 7.3540e-04\n",
      "Epoch 38/50\n",
      "18712/18712 [==============================] - 85s 5ms/step - loss: 4.7681e-04 - val_loss: 7.8740e-04\n",
      "Epoch 39/50\n",
      "18712/18712 [==============================] - 85s 5ms/step - loss: 4.6655e-04 - val_loss: 7.4108e-04\n",
      "Epoch 40/50\n",
      "18712/18712 [==============================] - 85s 5ms/step - loss: 4.7280e-04 - val_loss: 8.5561e-04\n",
      "Epoch 41/50\n",
      "18712/18712 [==============================] - 85s 5ms/step - loss: 4.6897e-04 - val_loss: 7.1410e-04\n",
      "Epoch 42/50\n",
      "18712/18712 [==============================] - 84s 4ms/step - loss: 4.6055e-04 - val_loss: 7.3677e-04\n",
      "Epoch 43/50\n",
      "18712/18712 [==============================] - 84s 5ms/step - loss: 4.7389e-04 - val_loss: 7.3109e-04\n",
      "Epoch 44/50\n",
      "18701/18712 [============================>.] - ETA: 0s - loss: 4.7361e-04Restoring model weights from the end of the best epoch: 34.\n",
      "18712/18712 [==============================] - 84s 5ms/step - loss: 4.7344e-04 - val_loss: 7.3062e-04\n",
      "Epoch 44: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para MOJARRA en clúster 7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 1s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_32729/3702398476.py:39: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Mensual para MOJARRA en clúster 7.0: 3397085592.088661, R2 Mensual: 0.9348040851770333\n",
      "Training model for species: MOJARRA, cluster: 0.0\n",
      "Epoch 1/50\n",
      "249/249 [==============================] - 6s 9ms/step - loss: 0.0046 - val_loss: 0.1204\n",
      "Epoch 2/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0045 - val_loss: 0.1198\n",
      "Epoch 3/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0042 - val_loss: 0.1161\n",
      "Epoch 4/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0039 - val_loss: 0.1153\n",
      "Epoch 5/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0037 - val_loss: 0.1143\n",
      "Epoch 6/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0035 - val_loss: 0.1168\n",
      "Epoch 7/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0031 - val_loss: 0.1149\n",
      "Epoch 8/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0028 - val_loss: 0.1183\n",
      "Epoch 9/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0027 - val_loss: 0.1170\n",
      "Epoch 10/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0025 - val_loss: 0.1175\n",
      "Epoch 11/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0019 - val_loss: 0.1194\n",
      "Epoch 12/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0022 - val_loss: 0.1191\n",
      "Epoch 13/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0019 - val_loss: 0.1138\n",
      "Epoch 14/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 0.1159\n",
      "Epoch 15/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 0.1092\n",
      "Epoch 16/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0022 - val_loss: 0.1028\n",
      "Epoch 17/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0015 - val_loss: 0.1078\n",
      "Epoch 18/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0015 - val_loss: 0.1085\n",
      "Epoch 19/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.1077\n",
      "Epoch 20/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.1059\n",
      "Epoch 21/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.1093\n",
      "Epoch 22/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.1020\n",
      "Epoch 23/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0953\n",
      "Epoch 24/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0991\n",
      "Epoch 25/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0963\n",
      "Epoch 26/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0026 - val_loss: 0.1158\n",
      "Epoch 27/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 0.1041\n",
      "Epoch 28/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0025 - val_loss: 0.1049\n",
      "Epoch 29/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0984\n",
      "Epoch 30/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0913\n",
      "Epoch 31/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0941\n",
      "Epoch 32/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0852\n",
      "Epoch 33/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0018 - val_loss: 0.0917\n",
      "Epoch 34/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0896\n",
      "Epoch 35/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0018 - val_loss: 0.0874\n",
      "Epoch 36/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0887\n",
      "Epoch 37/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0827\n",
      "Epoch 38/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0886\n",
      "Epoch 39/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0015 - val_loss: 0.0882\n",
      "Epoch 40/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0921\n",
      "Epoch 41/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 0.0869\n",
      "Epoch 42/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0906\n",
      "Epoch 43/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0823\n",
      "Epoch 44/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0889\n",
      "Epoch 45/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0889\n",
      "Epoch 46/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0831\n",
      "Epoch 47/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0858\n",
      "Epoch 48/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0914\n",
      "Epoch 49/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0865\n",
      "Epoch 50/50\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0805\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para MOJARRA en clúster 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 642ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "MSE Mensual para MOJARRA en clúster 0.0: 502017767.1679723, R2 Mensual: -1.25194909099719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_32729/3702398476.py:39: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: MOJARRA, cluster: 3.0\n",
      "Epoch 1/50\n",
      "8933/8933 [==============================] - 46s 5ms/step - loss: 9.6760e-04 - val_loss: 0.0012\n",
      "Epoch 2/50\n",
      "8933/8933 [==============================] - 42s 5ms/step - loss: 9.2552e-04 - val_loss: 0.0012\n",
      "Epoch 3/50\n",
      "8933/8933 [==============================] - 42s 5ms/step - loss: 9.2915e-04 - val_loss: 0.0012\n",
      "Epoch 4/50\n",
      "8933/8933 [==============================] - 42s 5ms/step - loss: 8.6581e-04 - val_loss: 0.0011\n",
      "Epoch 5/50\n",
      "8933/8933 [==============================] - 42s 5ms/step - loss: 8.4448e-04 - val_loss: 0.0012\n",
      "Epoch 6/50\n",
      "8933/8933 [==============================] - 42s 5ms/step - loss: 8.3875e-04 - val_loss: 0.0012\n",
      "Epoch 7/50\n",
      "8933/8933 [==============================] - 42s 5ms/step - loss: 7.9028e-04 - val_loss: 0.0011\n",
      "Epoch 8/50\n",
      "8933/8933 [==============================] - 42s 5ms/step - loss: 8.0855e-04 - val_loss: 0.0011\n",
      "Epoch 9/50\n",
      "8933/8933 [==============================] - 42s 5ms/step - loss: 7.5391e-04 - val_loss: 0.0011\n",
      "Epoch 10/50\n",
      "8933/8933 [==============================] - 42s 5ms/step - loss: 7.6401e-04 - val_loss: 0.0011\n",
      "Epoch 11/50\n",
      "8933/8933 [==============================] - 42s 5ms/step - loss: 7.3841e-04 - val_loss: 0.0012\n",
      "Epoch 12/50\n",
      "8933/8933 [==============================] - 42s 5ms/step - loss: 7.5689e-04 - val_loss: 0.0011\n",
      "Epoch 13/50\n",
      "8933/8933 [==============================] - 42s 5ms/step - loss: 7.4451e-04 - val_loss: 0.0012\n",
      "Epoch 14/50\n",
      "8933/8933 [==============================] - 42s 5ms/step - loss: 7.2772e-04 - val_loss: 0.0011\n",
      "Epoch 15/50\n",
      "8933/8933 [==============================] - 42s 5ms/step - loss: 7.3367e-04 - val_loss: 0.0011\n",
      "Epoch 16/50\n",
      "8933/8933 [==============================] - 42s 5ms/step - loss: 6.9724e-04 - val_loss: 0.0012\n",
      "Epoch 17/50\n",
      "8933/8933 [==============================] - 42s 5ms/step - loss: 7.2035e-04 - val_loss: 0.0012\n",
      "Epoch 18/50\n",
      "8933/8933 [==============================] - 42s 5ms/step - loss: 7.1279e-04 - val_loss: 0.0011\n",
      "Epoch 19/50\n",
      "8933/8933 [==============================] - 42s 5ms/step - loss: 7.5504e-04 - val_loss: 0.0012\n",
      "Epoch 20/50\n",
      "8933/8933 [==============================] - 42s 5ms/step - loss: 7.1142e-04 - val_loss: 0.0011\n",
      "Epoch 21/50\n",
      "8933/8933 [==============================] - 42s 5ms/step - loss: 7.3765e-04 - val_loss: 0.0011\n",
      "Epoch 22/50\n",
      "8933/8933 [==============================] - 42s 5ms/step - loss: 7.7596e-04 - val_loss: 0.0011\n",
      "Epoch 23/50\n",
      "8933/8933 [==============================] - 42s 5ms/step - loss: 7.4538e-04 - val_loss: 0.0011\n",
      "Epoch 24/50\n",
      "8933/8933 [==============================] - 42s 5ms/step - loss: 7.0698e-04 - val_loss: 0.0013\n",
      "Epoch 25/50\n",
      "8928/8933 [============================>.] - ETA: 0s - loss: 7.0491e-04Restoring model weights from the end of the best epoch: 15.\n",
      "8933/8933 [==============================] - 42s 5ms/step - loss: 7.0459e-04 - val_loss: 0.0012\n",
      "Epoch 25: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para MOJARRA en clúster 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 1s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para MOJARRA en clúster 3.0: 1102785480.895611, R2 Mensual: 0.7184337569352623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_32729/3702398476.py:39: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: MOJARRA, cluster: 6.0\n",
      "Epoch 1/50\n",
      "449/449 [==============================] - 6s 6ms/step - loss: 0.0081 - val_loss: 0.0037\n",
      "Epoch 2/50\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0079 - val_loss: 0.0036\n",
      "Epoch 3/50\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0078 - val_loss: 0.0034\n",
      "Epoch 4/50\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0078 - val_loss: 0.0035\n",
      "Epoch 5/50\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0078 - val_loss: 0.0035\n",
      "Epoch 6/50\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0076 - val_loss: 0.0036\n",
      "Epoch 7/50\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0077 - val_loss: 0.0034\n",
      "Epoch 8/50\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0077 - val_loss: 0.0035\n",
      "Epoch 9/50\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0077 - val_loss: 0.0035\n",
      "Epoch 10/50\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0076 - val_loss: 0.0036\n",
      "Epoch 11/50\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0075 - val_loss: 0.0038\n",
      "Epoch 12/50\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0075 - val_loss: 0.0035\n",
      "Epoch 13/50\n",
      "449/449 [==============================] - ETA: 0s - loss: 0.0074Restoring model weights from the end of the best epoch: 3.\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0074 - val_loss: 0.0034\n",
      "Epoch 13: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para MOJARRA en clúster 6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para MOJARRA en clúster 6.0: 609132.5409877446, R2 Mensual: 0.7762037183645354\n",
      "Training model for species: MOJARRA, cluster: 5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_32729/3702398476.py:39: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 4s 345ms/step - loss: 0.4552 - val_loss: 0.0373\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4265 - val_loss: 0.0249\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3931 - val_loss: 0.0176\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3729 - val_loss: 0.0124\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3470 - val_loss: 0.0084\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3355 - val_loss: 0.0051\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3253 - val_loss: 0.0026\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3026 - val_loss: 0.0011\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2981 - val_loss: 1.7660e-04\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2848 - val_loss: 1.1046e-04\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2611 - val_loss: 0.0014\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2482 - val_loss: 0.0043\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2286 - val_loss: 0.0112\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2065 - val_loss: 0.0209\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2204 - val_loss: 0.0440\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2284 - val_loss: 0.0668\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2245 - val_loss: 0.0819\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2224 - val_loss: 0.0980\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1862 - val_loss: 0.0721\n",
      "Epoch 20/50\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0889Restoring model weights from the end of the best epoch: 10.\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1499 - val_loss: 0.0673\n",
      "Epoch 20: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para MOJARRA en clúster 5.0\n",
      "No se tienen datos suficientes para MOJARRA en clúster 5.0 en los últimos seis meses de 2023\n",
      "Training model for species: MOJARRA, cluster: 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1609/1609 [==============================] - 12s 5ms/step - loss: 0.0092 - val_loss: 0.0073\n",
      "Epoch 2/50\n",
      "1609/1609 [==============================] - 8s 5ms/step - loss: 0.0080 - val_loss: 0.0074\n",
      "Epoch 3/50\n",
      "1609/1609 [==============================] - 8s 5ms/step - loss: 0.0078 - val_loss: 0.0074\n",
      "Epoch 4/50\n",
      "1609/1609 [==============================] - 8s 5ms/step - loss: 0.0077 - val_loss: 0.0076\n",
      "Epoch 5/50\n",
      "1609/1609 [==============================] - 8s 5ms/step - loss: 0.0077 - val_loss: 0.0075\n",
      "Epoch 6/50\n",
      "1609/1609 [==============================] - 8s 5ms/step - loss: 0.0075 - val_loss: 0.0074\n",
      "Epoch 7/50\n",
      "1609/1609 [==============================] - 8s 5ms/step - loss: 0.0075 - val_loss: 0.0073\n",
      "Epoch 8/50\n",
      "1609/1609 [==============================] - 8s 5ms/step - loss: 0.0074 - val_loss: 0.0077\n",
      "Epoch 9/50\n",
      "1609/1609 [==============================] - 8s 5ms/step - loss: 0.0073 - val_loss: 0.0086\n",
      "Epoch 10/50\n",
      "1609/1609 [==============================] - 8s 5ms/step - loss: 0.0073 - val_loss: 0.0077\n",
      "Epoch 11/50\n",
      "1609/1609 [==============================] - 8s 5ms/step - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 12/50\n",
      "1609/1609 [==============================] - 8s 5ms/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 13/50\n",
      "1609/1609 [==============================] - 8s 5ms/step - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 14/50\n",
      "1609/1609 [==============================] - 8s 5ms/step - loss: 0.0072 - val_loss: 0.0075\n",
      "Epoch 15/50\n",
      "1609/1609 [==============================] - 8s 5ms/step - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 16/50\n",
      "1609/1609 [==============================] - 8s 5ms/step - loss: 0.0071 - val_loss: 0.0092\n",
      "Epoch 17/50\n",
      "1609/1609 [==============================] - 8s 5ms/step - loss: 0.0070 - val_loss: 0.0072\n",
      "Epoch 18/50\n",
      "1609/1609 [==============================] - 8s 5ms/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 19/50\n",
      "1609/1609 [==============================] - 8s 5ms/step - loss: 0.0071 - val_loss: 0.0082\n",
      "Epoch 20/50\n",
      "1609/1609 [==============================] - 8s 5ms/step - loss: 0.0070 - val_loss: 0.0094\n",
      "Epoch 21/50\n",
      "1604/1609 [============================>.] - ETA: 0s - loss: 0.0069Restoring model weights from the end of the best epoch: 11.\n",
      "1609/1609 [==============================] - 8s 5ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 21: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para MOJARRA en clúster 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para MOJARRA en clúster 2.0: 80996046.81580743, R2 Mensual: 0.8398795039000688\n",
      "Training model for species: MOJARRA, cluster: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_32729/3702398476.py:39: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6177/6177 [==============================] - 34s 5ms/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 2/50\n",
      "6177/6177 [==============================] - 29s 5ms/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 3/50\n",
      "6177/6177 [==============================] - 29s 5ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 4/50\n",
      "6177/6177 [==============================] - 29s 5ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 5/50\n",
      "6177/6177 [==============================] - 29s 5ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 6/50\n",
      "6177/6177 [==============================] - 29s 5ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 7/50\n",
      "6177/6177 [==============================] - 29s 5ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 8/50\n",
      "6177/6177 [==============================] - 29s 5ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 9/50\n",
      "6177/6177 [==============================] - 29s 5ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 10/50\n",
      "6177/6177 [==============================] - 29s 5ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 11/50\n",
      "6177/6177 [==============================] - 29s 5ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 12/50\n",
      "6177/6177 [==============================] - 29s 5ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 13/50\n",
      "6177/6177 [==============================] - 29s 5ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 14/50\n",
      "6177/6177 [==============================] - 29s 5ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 15/50\n",
      "6177/6177 [==============================] - 29s 5ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 16/50\n",
      "6177/6177 [==============================] - 29s 5ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 17/50\n",
      "6177/6177 [==============================] - 29s 5ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 18/50\n",
      "6177/6177 [==============================] - 29s 5ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 19/50\n",
      "6177/6177 [==============================] - 29s 5ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 20/50\n",
      "6177/6177 [==============================] - 29s 5ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 21/50\n",
      "6177/6177 [==============================] - 29s 5ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 22/50\n",
      "6177/6177 [==============================] - 29s 5ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 23/50\n",
      "6177/6177 [==============================] - 29s 5ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 24/50\n",
      "6177/6177 [==============================] - 29s 5ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 25/50\n",
      "6174/6177 [============================>.] - ETA: 0s - loss: 0.0020Restoring model weights from the end of the best epoch: 15.\n",
      "6177/6177 [==============================] - 29s 5ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 25: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para MOJARRA en clúster 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para MOJARRA en clúster 1.0: 140222614.6766226, R2 Mensual: 0.9084039663136909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_32729/3702398476.py:39: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: MOJARRA, cluster: 4.0\n",
      "Epoch 1/50\n",
      "38/38 [==============================] - 5s 24ms/step - loss: 0.0313 - val_loss: 0.2318\n",
      "Epoch 2/50\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0275 - val_loss: 0.2659\n",
      "Epoch 3/50\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0277 - val_loss: 0.2379\n",
      "Epoch 4/50\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0264 - val_loss: 0.2559\n",
      "Epoch 5/50\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0239 - val_loss: 0.2547\n",
      "Epoch 6/50\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0221 - val_loss: 0.2259\n",
      "Epoch 7/50\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0220 - val_loss: 0.2074\n",
      "Epoch 8/50\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0223 - val_loss: 0.2066\n",
      "Epoch 9/50\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0196 - val_loss: 0.2751\n",
      "Epoch 10/50\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0199 - val_loss: 0.2623\n",
      "Epoch 11/50\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0183 - val_loss: 0.2132\n",
      "Epoch 12/50\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0163 - val_loss: 0.2623\n",
      "Epoch 13/50\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0164 - val_loss: 0.2353\n",
      "Epoch 14/50\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0152 - val_loss: 0.2596\n",
      "Epoch 15/50\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.2435\n",
      "Epoch 16/50\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.2107\n",
      "Epoch 17/50\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.2344\n",
      "Epoch 18/50\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0112Restoring model weights from the end of the best epoch: 8.\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0112 - val_loss: 0.2180\n",
      "Epoch 18: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para MOJARRA en clúster 4.0\n",
      "No se tienen datos suficientes para MOJARRA en clúster 4.0 en los últimos seis meses de 2023\n",
      "Training model for species: OTRAS, cluster: 7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23340/23340 [==============================] - 114s 5ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 2/50\n",
      "23340/23340 [==============================] - 110s 5ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 3/50\n",
      "23340/23340 [==============================] - 110s 5ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 4/50\n",
      "23340/23340 [==============================] - 110s 5ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 5/50\n",
      "23340/23340 [==============================] - 111s 5ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 6/50\n",
      "23340/23340 [==============================] - 111s 5ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 7/50\n",
      "23340/23340 [==============================] - 110s 5ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 8/50\n",
      "23340/23340 [==============================] - 108s 5ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 9/50\n",
      "23340/23340 [==============================] - 107s 5ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 10/50\n",
      "23340/23340 [==============================] - 107s 5ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 11/50\n",
      "23340/23340 [==============================] - 107s 5ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 12/50\n",
      "23340/23340 [==============================] - 106s 5ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 13/50\n",
      "23340/23340 [==============================] - 105s 4ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 14/50\n",
      "23340/23340 [==============================] - 104s 4ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 15/50\n",
      "23340/23340 [==============================] - 104s 4ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 16/50\n",
      "23340/23340 [==============================] - 104s 4ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 17/50\n",
      "23336/23340 [============================>.] - ETA: 0s - loss: 0.0019Restoring model weights from the end of the best epoch: 7.\n",
      "23340/23340 [==============================] - 104s 4ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 17: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para OTRAS en clúster 7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 1s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para OTRAS en clúster 7.0: 345829946.30796653, R2 Mensual: 0.35737279928540067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_32729/3702398476.py:39: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: OTRAS, cluster: 0.0\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 6s 13ms/step - loss: 0.0112 - val_loss: 1.3610e-04\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0103 - val_loss: 0.0012\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 1.2311e-04\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0014\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 3.3127e-04\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 1.6813e-04\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 5.7780e-04\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 1.8844e-04\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 2.4528e-04\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 2.4909e-04\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 8.1668e-04 - val_loss: 1.6850e-04\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 8.9373e-04 - val_loss: 2.0228e-04\n",
      "Epoch 13/50\n",
      "85/95 [=========================>....] - ETA: 0s - loss: 6.6872e-04Restoring model weights from the end of the best epoch: 3.\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.0656e-04 - val_loss: 2.0249e-04\n",
      "Epoch 13: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para OTRAS en clúster 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 637ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "MSE Mensual para OTRAS en clúster 0.0: 14704316.028120453, R2 Mensual: -0.023748862240136726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_32729/3702398476.py:39: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: OTRAS, cluster: 3.0\n",
      "Epoch 1/50\n",
      "22241/22241 [==============================] - 108s 5ms/step - loss: 8.3967e-04 - val_loss: 4.2464e-04\n",
      "Epoch 2/50\n",
      "22241/22241 [==============================] - 104s 5ms/step - loss: 8.2781e-04 - val_loss: 4.1557e-04\n",
      "Epoch 3/50\n",
      "22241/22241 [==============================] - 104s 5ms/step - loss: 8.1986e-04 - val_loss: 4.2215e-04\n",
      "Epoch 4/50\n",
      "22241/22241 [==============================] - 104s 5ms/step - loss: 8.0504e-04 - val_loss: 4.8958e-04\n",
      "Epoch 5/50\n",
      "22241/22241 [==============================] - 104s 5ms/step - loss: 7.8971e-04 - val_loss: 5.4333e-04\n",
      "Epoch 6/50\n",
      "22241/22241 [==============================] - 104s 5ms/step - loss: 7.7144e-04 - val_loss: 4.3337e-04\n",
      "Epoch 7/50\n",
      "22241/22241 [==============================] - 104s 5ms/step - loss: 7.6454e-04 - val_loss: 3.8786e-04\n",
      "Epoch 8/50\n",
      "22241/22241 [==============================] - 104s 5ms/step - loss: 7.6153e-04 - val_loss: 3.8183e-04\n",
      "Epoch 9/50\n",
      "22241/22241 [==============================] - 104s 5ms/step - loss: 7.5288e-04 - val_loss: 3.8558e-04\n",
      "Epoch 10/50\n",
      "22241/22241 [==============================] - 105s 5ms/step - loss: 7.4614e-04 - val_loss: 4.0876e-04\n",
      "Epoch 11/50\n",
      "22241/22241 [==============================] - 105s 5ms/step - loss: 7.4630e-04 - val_loss: 0.0017\n",
      "Epoch 12/50\n",
      "22241/22241 [==============================] - 105s 5ms/step - loss: 7.3761e-04 - val_loss: 4.4800e-04\n",
      "Epoch 13/50\n",
      "22241/22241 [==============================] - 104s 5ms/step - loss: 7.4349e-04 - val_loss: 3.7220e-04\n",
      "Epoch 14/50\n",
      "22241/22241 [==============================] - 104s 5ms/step - loss: 7.3963e-04 - val_loss: 3.8351e-04\n",
      "Epoch 15/50\n",
      "22241/22241 [==============================] - 104s 5ms/step - loss: 7.3832e-04 - val_loss: 4.0347e-04\n",
      "Epoch 16/50\n",
      "22241/22241 [==============================] - 104s 5ms/step - loss: 7.3501e-04 - val_loss: 3.8775e-04\n",
      "Epoch 17/50\n",
      "22241/22241 [==============================] - 104s 5ms/step - loss: 7.3172e-04 - val_loss: 3.7781e-04\n",
      "Epoch 18/50\n",
      "22241/22241 [==============================] - 104s 5ms/step - loss: 7.3142e-04 - val_loss: 3.7438e-04\n",
      "Epoch 19/50\n",
      "22241/22241 [==============================] - 102s 5ms/step - loss: 7.3023e-04 - val_loss: 4.4473e-04\n",
      "Epoch 20/50\n",
      "22241/22241 [==============================] - 101s 5ms/step - loss: 7.2747e-04 - val_loss: 3.7606e-04\n",
      "Epoch 21/50\n",
      "22241/22241 [==============================] - 101s 5ms/step - loss: 7.3152e-04 - val_loss: 3.7140e-04\n",
      "Epoch 22/50\n",
      "22241/22241 [==============================] - 101s 5ms/step - loss: 7.2524e-04 - val_loss: 4.0348e-04\n",
      "Epoch 23/50\n",
      "22241/22241 [==============================] - 101s 5ms/step - loss: 7.3174e-04 - val_loss: 3.9696e-04\n",
      "Epoch 24/50\n",
      "22241/22241 [==============================] - 101s 5ms/step - loss: 7.3416e-04 - val_loss: 3.9186e-04\n",
      "Epoch 25/50\n",
      "22241/22241 [==============================] - 100s 4ms/step - loss: 7.2693e-04 - val_loss: 3.6728e-04\n",
      "Epoch 26/50\n",
      "22241/22241 [==============================] - 99s 4ms/step - loss: 7.2462e-04 - val_loss: 3.7006e-04\n",
      "Epoch 27/50\n",
      "22241/22241 [==============================] - 99s 4ms/step - loss: 7.2637e-04 - val_loss: 3.8411e-04\n",
      "Epoch 28/50\n",
      "22241/22241 [==============================] - 99s 4ms/step - loss: 7.2206e-04 - val_loss: 3.8564e-04\n",
      "Epoch 29/50\n",
      "22241/22241 [==============================] - 99s 4ms/step - loss: 7.2244e-04 - val_loss: 3.9105e-04\n",
      "Epoch 30/50\n",
      "22241/22241 [==============================] - 98s 4ms/step - loss: 7.2401e-04 - val_loss: 3.6451e-04\n",
      "Epoch 31/50\n",
      "22241/22241 [==============================] - 99s 4ms/step - loss: 7.2873e-04 - val_loss: 3.7362e-04\n",
      "Epoch 32/50\n",
      "22241/22241 [==============================] - 99s 4ms/step - loss: 7.2683e-04 - val_loss: 3.9446e-04\n",
      "Epoch 33/50\n",
      "22241/22241 [==============================] - 99s 4ms/step - loss: 7.2115e-04 - val_loss: 3.6997e-04\n",
      "Epoch 34/50\n",
      "22241/22241 [==============================] - 99s 4ms/step - loss: 7.2553e-04 - val_loss: 3.7481e-04\n",
      "Epoch 35/50\n",
      "22241/22241 [==============================] - 99s 4ms/step - loss: 7.2405e-04 - val_loss: 4.0489e-04\n",
      "Epoch 36/50\n",
      "22241/22241 [==============================] - 98s 4ms/step - loss: 7.2198e-04 - val_loss: 3.8236e-04\n",
      "Epoch 37/50\n",
      "22241/22241 [==============================] - 99s 4ms/step - loss: 7.2452e-04 - val_loss: 3.7134e-04\n",
      "Epoch 38/50\n",
      "22241/22241 [==============================] - 99s 4ms/step - loss: 7.2403e-04 - val_loss: 4.5068e-04\n",
      "Epoch 39/50\n",
      "22241/22241 [==============================] - 98s 4ms/step - loss: 7.2295e-04 - val_loss: 3.6524e-04\n",
      "Epoch 40/50\n",
      "22241/22241 [==============================] - 99s 4ms/step - loss: 7.2080e-04 - val_loss: 3.6153e-04\n",
      "Epoch 41/50\n",
      "22241/22241 [==============================] - 99s 4ms/step - loss: 7.1943e-04 - val_loss: 4.0930e-04\n",
      "Epoch 42/50\n",
      "22241/22241 [==============================] - 99s 4ms/step - loss: 7.1862e-04 - val_loss: 3.7748e-04\n",
      "Epoch 43/50\n",
      "22241/22241 [==============================] - 99s 4ms/step - loss: 7.1856e-04 - val_loss: 3.8942e-04\n",
      "Epoch 44/50\n",
      "22241/22241 [==============================] - 99s 4ms/step - loss: 7.2138e-04 - val_loss: 3.6207e-04\n",
      "Epoch 45/50\n",
      "22241/22241 [==============================] - 99s 4ms/step - loss: 7.1959e-04 - val_loss: 3.7937e-04\n",
      "Epoch 46/50\n",
      "22241/22241 [==============================] - 99s 4ms/step - loss: 7.2018e-04 - val_loss: 3.9141e-04\n",
      "Epoch 47/50\n",
      "22241/22241 [==============================] - 99s 4ms/step - loss: 7.2099e-04 - val_loss: 3.6286e-04\n",
      "Epoch 48/50\n",
      "22241/22241 [==============================] - 99s 4ms/step - loss: 7.1895e-04 - val_loss: 3.6506e-04\n",
      "Epoch 49/50\n",
      "22241/22241 [==============================] - 99s 4ms/step - loss: 7.1767e-04 - val_loss: 3.8098e-04\n",
      "Epoch 50/50\n",
      "22241/22241 [==============================] - ETA: 0s - loss: 7.2021e-04Restoring model weights from the end of the best epoch: 40.\n",
      "22241/22241 [==============================] - 99s 4ms/step - loss: 7.2021e-04 - val_loss: 3.7024e-04\n",
      "Epoch 50: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para OTRAS en clúster 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 1s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "140/140 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para OTRAS en clúster 3.0: 92190296.90891892, R2 Mensual: 0.9027023957823674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_32729/3702398476.py:39: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: OTRAS, cluster: 6.0\n",
      "Epoch 1/50\n",
      "15015/15015 [==============================] - 73s 5ms/step - loss: 5.8316e-04 - val_loss: 4.3112e-05\n",
      "Epoch 2/50\n",
      "15015/15015 [==============================] - 68s 5ms/step - loss: 5.7523e-04 - val_loss: 4.1976e-05\n",
      "Epoch 3/50\n",
      "15015/15015 [==============================] - 68s 4ms/step - loss: 5.4521e-04 - val_loss: 4.0745e-05\n",
      "Epoch 4/50\n",
      "15015/15015 [==============================] - 68s 5ms/step - loss: 5.2610e-04 - val_loss: 4.5905e-05\n",
      "Epoch 5/50\n",
      "15015/15015 [==============================] - 68s 5ms/step - loss: 5.2445e-04 - val_loss: 4.0167e-05\n",
      "Epoch 6/50\n",
      "15015/15015 [==============================] - 68s 5ms/step - loss: 5.1423e-04 - val_loss: 5.2226e-05\n",
      "Epoch 7/50\n",
      "15015/15015 [==============================] - 68s 5ms/step - loss: 5.0442e-04 - val_loss: 5.9699e-05\n",
      "Epoch 8/50\n",
      "15015/15015 [==============================] - 68s 4ms/step - loss: 4.9079e-04 - val_loss: 4.2377e-05\n",
      "Epoch 9/50\n",
      "15015/15015 [==============================] - 67s 4ms/step - loss: 4.9787e-04 - val_loss: 4.1411e-05\n",
      "Epoch 10/50\n",
      "15015/15015 [==============================] - 67s 4ms/step - loss: 5.0544e-04 - val_loss: 4.2012e-05\n",
      "Epoch 11/50\n",
      "15015/15015 [==============================] - 68s 5ms/step - loss: 5.0751e-04 - val_loss: 4.3326e-05\n",
      "Epoch 12/50\n",
      "15015/15015 [==============================] - 70s 5ms/step - loss: 4.9342e-04 - val_loss: 4.1114e-05\n",
      "Epoch 13/50\n",
      "15015/15015 [==============================] - 68s 5ms/step - loss: 5.0232e-04 - val_loss: 4.2662e-05\n",
      "Epoch 14/50\n",
      "15015/15015 [==============================] - 68s 5ms/step - loss: 4.9532e-04 - val_loss: 1.4815e-04\n",
      "Epoch 15/50\n",
      "15010/15015 [============================>.] - ETA: 0s - loss: 4.9935e-04Restoring model weights from the end of the best epoch: 5.\n",
      "15015/15015 [==============================] - 68s 5ms/step - loss: 4.9939e-04 - val_loss: 4.8608e-05\n",
      "Epoch 15: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para OTRAS en clúster 6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 1s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "113/113 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para OTRAS en clúster 6.0: 588487662.194926, R2 Mensual: 0.49374424187328014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_32729/3702398476.py:39: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: OTRAS, cluster: 5.0\n",
      "Epoch 1/50\n",
      "4021/4021 [==============================] - 24s 5ms/step - loss: 0.0088 - val_loss: 0.0011\n",
      "Epoch 2/50\n",
      "4021/4021 [==============================] - 20s 5ms/step - loss: 0.0078 - val_loss: 0.0057\n",
      "Epoch 3/50\n",
      "4021/4021 [==============================] - 19s 5ms/step - loss: 0.0077 - val_loss: 0.0010\n",
      "Epoch 4/50\n",
      "4021/4021 [==============================] - 19s 5ms/step - loss: 0.0075 - val_loss: 0.0014\n",
      "Epoch 5/50\n",
      "4021/4021 [==============================] - 19s 5ms/step - loss: 0.0074 - val_loss: 9.7629e-04\n",
      "Epoch 6/50\n",
      "4021/4021 [==============================] - 19s 5ms/step - loss: 0.0074 - val_loss: 8.2064e-04\n",
      "Epoch 7/50\n",
      "4021/4021 [==============================] - 19s 5ms/step - loss: 0.0073 - val_loss: 8.4784e-04\n",
      "Epoch 8/50\n",
      "4021/4021 [==============================] - 19s 5ms/step - loss: 0.0072 - val_loss: 8.3789e-04\n",
      "Epoch 9/50\n",
      "4021/4021 [==============================] - 19s 5ms/step - loss: 0.0072 - val_loss: 0.0010\n",
      "Epoch 10/50\n",
      "4021/4021 [==============================] - 19s 5ms/step - loss: 0.0072 - val_loss: 8.6128e-04\n",
      "Epoch 11/50\n",
      "4021/4021 [==============================] - 19s 5ms/step - loss: 0.0072 - val_loss: 0.0026\n",
      "Epoch 12/50\n",
      "4021/4021 [==============================] - 19s 5ms/step - loss: 0.0072 - val_loss: 0.0012\n",
      "Epoch 13/50\n",
      "4021/4021 [==============================] - 19s 5ms/step - loss: 0.0072 - val_loss: 0.0011\n",
      "Epoch 14/50\n",
      "4021/4021 [==============================] - 19s 5ms/step - loss: 0.0071 - val_loss: 8.7670e-04\n",
      "Epoch 15/50\n",
      "4021/4021 [==============================] - 19s 5ms/step - loss: 0.0071 - val_loss: 0.0011\n",
      "Epoch 16/50\n",
      "4021/4021 [==============================] - 19s 5ms/step - loss: 0.0071 - val_loss: 8.1837e-04\n",
      "Epoch 17/50\n",
      "4021/4021 [==============================] - 19s 5ms/step - loss: 0.0071 - val_loss: 8.5738e-04\n",
      "Epoch 18/50\n",
      "4021/4021 [==============================] - 19s 5ms/step - loss: 0.0071 - val_loss: 8.7931e-04\n",
      "Epoch 19/50\n",
      "4021/4021 [==============================] - 19s 5ms/step - loss: 0.0070 - val_loss: 9.1939e-04\n",
      "Epoch 20/50\n",
      "4021/4021 [==============================] - 19s 5ms/step - loss: 0.0071 - val_loss: 0.0012\n",
      "Epoch 21/50\n",
      "4021/4021 [==============================] - 19s 5ms/step - loss: 0.0071 - val_loss: 8.5518e-04\n",
      "Epoch 22/50\n",
      "4021/4021 [==============================] - 19s 5ms/step - loss: 0.0071 - val_loss: 0.0010\n",
      "Epoch 23/50\n",
      "4021/4021 [==============================] - 19s 5ms/step - loss: 0.0071 - val_loss: 8.6200e-04\n",
      "Epoch 24/50\n",
      "4021/4021 [==============================] - 19s 5ms/step - loss: 0.0070 - val_loss: 8.4679e-04\n",
      "Epoch 25/50\n",
      "4021/4021 [==============================] - 19s 5ms/step - loss: 0.0070 - val_loss: 0.0011\n",
      "Epoch 26/50\n",
      "4013/4021 [============================>.] - ETA: 0s - loss: 0.0070Restoring model weights from the end of the best epoch: 16.\n",
      "4021/4021 [==============================] - 19s 5ms/step - loss: 0.0070 - val_loss: 0.0010\n",
      "Epoch 26: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para OTRAS en clúster 5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para OTRAS en clúster 5.0: 2275966281.8037767, R2 Mensual: 0.7650037316631452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_32729/3702398476.py:39: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: OTRAS, cluster: 2.0\n",
      "Epoch 1/50\n",
      "84/84 [==============================] - 5s 13ms/step - loss: 0.0119 - val_loss: 2.3501e-05\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.0117 - val_loss: 1.7923e-04\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 3.5536e-04\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.0111 - val_loss: 5.8987e-04\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.0110 - val_loss: 0.0012\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.0105 - val_loss: 7.0819e-04\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.0108 - val_loss: 0.0017\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.0104 - val_loss: 9.9784e-04\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.0101 - val_loss: 0.0015\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.0025\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0097  Restoring model weights from the end of the best epoch: 1.\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.0027\n",
      "Epoch 11: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para OTRAS en clúster 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 646ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "MSE Mensual para OTRAS en clúster 2.0: 1520245.0149767743, R2 Mensual: -0.2468781930535262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_32729/3702398476.py:39: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: OTRAS, cluster: 1.0\n",
      "Epoch 1/50\n",
      "18632/18632 [==============================] - 93s 5ms/step - loss: 3.6396e-04 - val_loss: 2.9167e-04\n",
      "Epoch 2/50\n",
      "18632/18632 [==============================] - 88s 5ms/step - loss: 3.6458e-04 - val_loss: 2.9087e-04\n",
      "Epoch 3/50\n",
      "18632/18632 [==============================] - 88s 5ms/step - loss: 3.6488e-04 - val_loss: 2.9387e-04\n",
      "Epoch 4/50\n",
      "18632/18632 [==============================] - 88s 5ms/step - loss: 3.6392e-04 - val_loss: 2.9207e-04\n",
      "Epoch 5/50\n",
      "18632/18632 [==============================] - 88s 5ms/step - loss: 3.6364e-04 - val_loss: 2.8744e-04\n",
      "Epoch 6/50\n",
      "18632/18632 [==============================] - 87s 5ms/step - loss: 3.6261e-04 - val_loss: 2.8593e-04\n",
      "Epoch 7/50\n",
      "18632/18632 [==============================] - 87s 5ms/step - loss: 3.5861e-04 - val_loss: 2.8800e-04\n",
      "Epoch 8/50\n",
      "18632/18632 [==============================] - 89s 5ms/step - loss: 3.5723e-04 - val_loss: 2.6475e-04\n",
      "Epoch 9/50\n",
      "18632/18632 [==============================] - 92s 5ms/step - loss: 3.5831e-04 - val_loss: 2.8393e-04\n",
      "Epoch 10/50\n",
      "18632/18632 [==============================] - 91s 5ms/step - loss: 3.5407e-04 - val_loss: 2.4978e-04\n",
      "Epoch 11/50\n",
      "18632/18632 [==============================] - 89s 5ms/step - loss: 3.5231e-04 - val_loss: 2.5640e-04\n",
      "Epoch 12/50\n",
      "18632/18632 [==============================] - 89s 5ms/step - loss: 3.5051e-04 - val_loss: 2.2896e-04\n",
      "Epoch 13/50\n",
      "18632/18632 [==============================] - 90s 5ms/step - loss: 3.4838e-04 - val_loss: 2.6007e-04\n",
      "Epoch 14/50\n",
      "18632/18632 [==============================] - 89s 5ms/step - loss: 3.5071e-04 - val_loss: 2.5226e-04\n",
      "Epoch 15/50\n",
      "18632/18632 [==============================] - 88s 5ms/step - loss: 3.5093e-04 - val_loss: 2.5155e-04\n",
      "Epoch 16/50\n",
      "18632/18632 [==============================] - 88s 5ms/step - loss: 3.4719e-04 - val_loss: 2.5939e-04\n",
      "Epoch 17/50\n",
      "18632/18632 [==============================] - 87s 5ms/step - loss: 3.5148e-04 - val_loss: 2.4582e-04\n",
      "Epoch 18/50\n",
      "18632/18632 [==============================] - 87s 5ms/step - loss: 3.4882e-04 - val_loss: 2.4447e-04\n",
      "Epoch 19/50\n",
      "18632/18632 [==============================] - 87s 5ms/step - loss: 3.5008e-04 - val_loss: 2.4587e-04\n",
      "Epoch 20/50\n",
      "18632/18632 [==============================] - 87s 5ms/step - loss: 3.5028e-04 - val_loss: 6.7113e-04\n",
      "Epoch 21/50\n",
      "18632/18632 [==============================] - 86s 5ms/step - loss: 3.4929e-04 - val_loss: 2.5044e-04\n",
      "Epoch 22/50\n",
      "18628/18632 [============================>.] - ETA: 0s - loss: 3.4857e-04Restoring model weights from the end of the best epoch: 12.\n",
      "18632/18632 [==============================] - 85s 5ms/step - loss: 3.4850e-04 - val_loss: 2.4951e-04\n",
      "Epoch 22: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para OTRAS en clúster 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 1s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para OTRAS en clúster 1.0: 75215734450.83524, R2 Mensual: 0.31131939946417664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_32729/3702398476.py:39: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: OTRAS, cluster: 4.0\n",
      "Epoch 1/50\n",
      "205/205 [==============================] - 5s 8ms/step - loss: 0.0176 - val_loss: 0.0019\n",
      "Epoch 2/50\n",
      "205/205 [==============================] - 1s 5ms/step - loss: 0.0162 - val_loss: 0.0021\n",
      "Epoch 3/50\n",
      "205/205 [==============================] - 1s 5ms/step - loss: 0.0156 - val_loss: 0.0048\n",
      "Epoch 4/50\n",
      "205/205 [==============================] - 1s 5ms/step - loss: 0.0145 - val_loss: 0.0049\n",
      "Epoch 5/50\n",
      "205/205 [==============================] - 1s 5ms/step - loss: 0.0145 - val_loss: 0.0095\n",
      "Epoch 6/50\n",
      "205/205 [==============================] - 1s 5ms/step - loss: 0.0139 - val_loss: 0.0089\n",
      "Epoch 7/50\n",
      "205/205 [==============================] - 1s 5ms/step - loss: 0.0136 - val_loss: 0.0033\n",
      "Epoch 8/50\n",
      "205/205 [==============================] - 1s 5ms/step - loss: 0.0135 - val_loss: 0.0045\n",
      "Epoch 9/50\n",
      "205/205 [==============================] - 1s 5ms/step - loss: 0.0127 - val_loss: 0.0036\n",
      "Epoch 10/50\n",
      "205/205 [==============================] - 1s 5ms/step - loss: 0.0132 - val_loss: 0.0061\n",
      "Epoch 11/50\n",
      "194/205 [===========================>..] - ETA: 0s - loss: 0.0134Restoring model weights from the end of the best epoch: 1.\n",
      "205/205 [==============================] - 1s 5ms/step - loss: 0.0128 - val_loss: 0.0057\n",
      "Epoch 11: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para OTRAS en clúster 4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "MSE Mensual para OTRAS en clúster 4.0: 22235535.318674445, R2 Mensual: -21.966630654609375\n",
      "Training model for species: LOBINA, cluster: 7.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_32729/3702398476.py:39: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50\n",
      "172/172 [==============================] - 5s 9ms/step - loss: 0.0049 - val_loss: 0.0420\n",
      "Epoch 2/50\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 0.0049 - val_loss: 0.0370\n",
      "Epoch 3/50\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0358\n",
      "Epoch 4/50\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 0.0043 - val_loss: 0.0377\n",
      "Epoch 5/50\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 0.0043 - val_loss: 0.0364\n",
      "Epoch 6/50\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 0.0042 - val_loss: 0.0352\n",
      "Epoch 7/50\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 0.0040 - val_loss: 0.0354\n",
      "Epoch 8/50\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 0.0041 - val_loss: 0.0361\n",
      "Epoch 9/50\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 0.0041 - val_loss: 0.0369\n",
      "Epoch 10/50\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 0.0039 - val_loss: 0.0373\n",
      "Epoch 11/50\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 0.0039 - val_loss: 0.0376\n",
      "Epoch 12/50\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 0.0039 - val_loss: 0.0352\n",
      "Epoch 13/50\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 0.0038 - val_loss: 0.0359\n",
      "Epoch 14/50\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 0.0036 - val_loss: 0.0363\n",
      "Epoch 15/50\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 0.0035 - val_loss: 0.0360\n",
      "Epoch 16/50\n",
      "169/172 [============================>.] - ETA: 0s - loss: 0.0034Restoring model weights from the end of the best epoch: 6.\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 0.0034 - val_loss: 0.0365\n",
      "Epoch 16: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LOBINA en clúster 7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para LOBINA en clúster 7.0: 128292.35350104596, R2 Mensual: -4.152671237167373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_32729/3702398476.py:39: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: LOBINA, cluster: 3.0\n",
      "Epoch 1/50\n",
      "267/267 [==============================] - 6s 7ms/step - loss: 0.0174 - val_loss: 0.0039\n",
      "Epoch 2/50\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0169 - val_loss: 0.0025\n",
      "Epoch 3/50\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0167 - val_loss: 0.0025\n",
      "Epoch 4/50\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0166 - val_loss: 0.0024\n",
      "Epoch 5/50\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0165 - val_loss: 0.0023\n",
      "Epoch 6/50\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0162 - val_loss: 0.0021\n",
      "Epoch 7/50\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0159 - val_loss: 0.0021\n",
      "Epoch 8/50\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0160 - val_loss: 0.0026\n",
      "Epoch 9/50\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0157 - val_loss: 0.0025\n",
      "Epoch 10/50\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0154 - val_loss: 0.0028\n",
      "Epoch 11/50\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0153 - val_loss: 0.0022\n",
      "Epoch 12/50\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0150 - val_loss: 0.0023\n",
      "Epoch 13/50\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0151 - val_loss: 0.0024\n",
      "Epoch 14/50\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0146 - val_loss: 0.0081\n",
      "Epoch 15/50\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0146 - val_loss: 0.0026\n",
      "Epoch 16/50\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0144 - val_loss: 0.0050\n",
      "Epoch 17/50\n",
      "265/267 [============================>.] - ETA: 0s - loss: 0.0142Restoring model weights from the end of the best epoch: 7.\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0141 - val_loss: 0.0055\n",
      "Epoch 17: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LOBINA en clúster 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 650ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "MSE Mensual para LOBINA en clúster 3.0: 30070.5077995083, R2 Mensual: -12.566475298553604\n",
      "Training model for species: LOBINA, cluster: 6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_32729/3702398476.py:39: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.4820 - val_loss: 1.1966\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3476 - val_loss: 1.1619\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2298 - val_loss: 1.1300\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1257 - val_loss: 1.0998\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0303 - val_loss: 1.0712\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9502 - val_loss: 1.0441\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8770 - val_loss: 1.0185\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8095 - val_loss: 0.9939\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7511 - val_loss: 0.9720\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6933 - val_loss: 0.9508\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6427 - val_loss: 0.9298\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5956 - val_loss: 0.9093\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5477 - val_loss: 0.8890\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5007 - val_loss: 0.8688\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4604 - val_loss: 0.8476\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4130 - val_loss: 0.8257\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3719 - val_loss: 0.8037\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3322 - val_loss: 0.7813\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2911 - val_loss: 0.7584\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2555 - val_loss: 0.7349\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2180 - val_loss: 0.7107\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1859 - val_loss: 0.6853\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1515 - val_loss: 0.6583\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1239 - val_loss: 0.6297\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0920 - val_loss: 0.5991\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0676 - val_loss: 0.5649\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0431 - val_loss: 0.5257\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0279 - val_loss: 0.4806\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0075 - val_loss: 0.4292\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0048 - val_loss: 0.3717\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.0127e-04 - val_loss: 0.3170\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0017 - val_loss: 0.2685\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0150 - val_loss: 0.2485\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0325 - val_loss: 0.2556\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0328 - val_loss: 0.2764\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0289 - val_loss: 0.3040\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0284 - val_loss: 0.3343\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0204 - val_loss: 0.3639\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0194 - val_loss: 0.3915\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0121 - val_loss: 0.4155\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0107 - val_loss: 0.4365\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0036 - val_loss: 0.4537\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0035Restoring model weights from the end of the best epoch: 33.\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0035 - val_loss: 0.4682\n",
      "Epoch 43: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LOBINA en clúster 6.0\n",
      "No se tienen datos suficientes para LOBINA en clúster 6.0 en los últimos seis meses de 2023\n",
      "Training model for species: LOBINA, cluster: 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "132/132 [==============================] - 5s 10ms/step - loss: 0.0301 - val_loss: 0.0361\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0267 - val_loss: 7.6323e-04\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0251 - val_loss: 0.0090\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0253 - val_loss: 0.0127\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0245 - val_loss: 0.0016\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0255 - val_loss: 0.0020\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0245 - val_loss: 0.0010\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0237 - val_loss: 0.0011\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0242 - val_loss: 7.0676e-04\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0239 - val_loss: 0.0022\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0235 - val_loss: 0.0039\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0240 - val_loss: 0.0029\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0220 - val_loss: 0.0011\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0230 - val_loss: 0.0071\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0225 - val_loss: 0.0013\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0232 - val_loss: 0.0012\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0217 - val_loss: 0.0034\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0211 - val_loss: 6.0949e-04\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0219 - val_loss: 0.0039\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0216 - val_loss: 9.8721e-04\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0215 - val_loss: 6.6186e-04\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0226 - val_loss: 0.0027\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0222 - val_loss: 0.0022\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0208 - val_loss: 0.0033\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0210 - val_loss: 9.1792e-04\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0208 - val_loss: 7.7009e-04\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0208 - val_loss: 0.0014\n",
      "Epoch 28/50\n",
      "124/132 [===========================>..] - ETA: 0s - loss: 0.0171Restoring model weights from the end of the best epoch: 18.\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0206 - val_loss: 0.0015\n",
      "Epoch 28: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LOBINA en clúster 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 665ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "MSE Mensual para LOBINA en clúster 2.0: 3072.0360781239788, R2 Mensual: 0.929907014301494\n",
      "Training model for species: LOBINA, cluster: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_32729/3702398476.py:39: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "530/530 [==============================] - 7s 6ms/step - loss: 0.0193 - val_loss: 0.0365\n",
      "Epoch 2/50\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0155 - val_loss: 0.0344\n",
      "Epoch 3/50\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0149 - val_loss: 0.0312\n",
      "Epoch 4/50\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0145 - val_loss: 0.0255\n",
      "Epoch 5/50\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0147 - val_loss: 0.0391\n",
      "Epoch 6/50\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0140 - val_loss: 0.0362\n",
      "Epoch 7/50\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0139 - val_loss: 0.0254\n",
      "Epoch 8/50\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0139 - val_loss: 0.0309\n",
      "Epoch 9/50\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0138 - val_loss: 0.0263\n",
      "Epoch 10/50\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0136 - val_loss: 0.0305\n",
      "Epoch 11/50\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0136 - val_loss: 0.0298\n",
      "Epoch 12/50\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0140 - val_loss: 0.0352\n",
      "Epoch 13/50\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0136 - val_loss: 0.0281\n",
      "Epoch 14/50\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0138 - val_loss: 0.0350\n",
      "Epoch 15/50\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0133 - val_loss: 0.0284\n",
      "Epoch 16/50\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0141 - val_loss: 0.0392\n",
      "Epoch 17/50\n",
      "529/530 [============================>.] - ETA: 0s - loss: 0.0135Restoring model weights from the end of the best epoch: 7.\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.0135 - val_loss: 0.0344\n",
      "Epoch 17: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LOBINA en clúster 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para LOBINA en clúster 1.0: 320219.70340355224, R2 Mensual: 0.977261677495712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_32729/3702398476.py:39: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: GUACHINANGO, cluster: 7.0\n",
      "Epoch 1/50\n",
      "4964/4964 [==============================] - 28s 5ms/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 2/50\n",
      "4964/4964 [==============================] - 23s 5ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 3/50\n",
      "4964/4964 [==============================] - 23s 5ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 4/50\n",
      "4964/4964 [==============================] - 23s 5ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 5/50\n",
      "4964/4964 [==============================] - 23s 5ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 6/50\n",
      "4964/4964 [==============================] - 23s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 7/50\n",
      "4964/4964 [==============================] - 23s 5ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 8/50\n",
      "4964/4964 [==============================] - 23s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 9/50\n",
      "4964/4964 [==============================] - 23s 5ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 10/50\n",
      "4964/4964 [==============================] - 23s 5ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 11/50\n",
      "4964/4964 [==============================] - 23s 5ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 12/50\n",
      "4964/4964 [==============================] - 23s 5ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 13/50\n",
      "4964/4964 [==============================] - 23s 5ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 14/50\n",
      "4964/4964 [==============================] - 23s 5ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 15/50\n",
      "4958/4964 [============================>.] - ETA: 0s - loss: 0.0019Restoring model weights from the end of the best epoch: 5.\n",
      "4964/4964 [==============================] - 23s 5ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 15: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para GUACHINANGO en clúster 7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para GUACHINANGO en clúster 7.0: 15539867.476305678, R2 Mensual: 0.8045741760574863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_32729/3702398476.py:39: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: GUACHINANGO, cluster: 0.0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m filtered_data \u001b[38;5;241m=\u001b[39m filtered_data\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining model for species: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspecies_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, cluster: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcluster_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m model, scaler \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_save_moe_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspecies_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlook_back\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Guardar los datos para las bandas de confianza\u001b[39;00m\n\u001b[1;32m     18\u001b[0m test_data_2023 \u001b[38;5;241m=\u001b[39m filtered_data[(filtered_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2023\u001b[39m) \u001b[38;5;241m&\u001b[39m (filtered_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)]\n",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m, in \u001b[0;36mtrain_and_save_moe_model\u001b[0;34m(data, species_name, cluster_label, look_back, epochs, batch_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_and_save_moe_model\u001b[39m(data, species_name, cluster_label, look_back\u001b[38;5;241m=\u001b[39mlook_back, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     X, y, scaler \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlook_back\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     model \u001b[38;5;241m=\u001b[39m create_moe_model((look_back, X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]))\n\u001b[1;32m      6\u001b[0m     early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[6], line 14\u001b[0m, in \u001b[0;36mprepare_data\u001b[0;34m(group, look_back)\u001b[0m\n\u001b[1;32m     12\u001b[0m     y\u001b[38;5;241m.\u001b[39mappend(group_scaled[i \u001b[38;5;241m+\u001b[39m look_back, \u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# La primera columna es 'landed_w_kg'\u001b[39;00m\n\u001b[1;32m     13\u001b[0m X, y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X), np\u001b[38;5;241m.\u001b[39marray(y)\n\u001b[0;32m---> 14\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(X, (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y, scaler\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# Obtener listas de especies y clústeres únicos\n",
    "unique_species = data['species'].unique()\n",
    "unique_clusters = data['Cluster_Label'].unique()\n",
    "\n",
    "# Definir la especie y clúster desde donde retomar el proceso\n",
    "resume_species = 'GUACHINANGO'\n",
    "resume_cluster = 7.0\n",
    "\n",
    "# Inicializar banderas\n",
    "resume_training = False\n",
    "\n",
    "for species_name in unique_species:\n",
    "    for cluster_label in unique_clusters:\n",
    "        # Activar la bandera cuando se alcance la especie y clúster deseados\n",
    "        if species_name == resume_species and cluster_label == resume_cluster:\n",
    "            resume_training = True\n",
    "        \n",
    "        # Continuar solo si la bandera está activada\n",
    "        if resume_training:\n",
    "            # Filtrar los datos para obtener una especie y un clúster específico\n",
    "            filtered_data = data[(data['species'] == species_name) & (data['Cluster_Label'] == cluster_label)]\n",
    "            \n",
    "            if len(filtered_data) >= look_back:\n",
    "                filtered_data = filtered_data.sort_values('date')\n",
    "                try:\n",
    "                    print(f'Training model for species: {species_name}, cluster: {cluster_label}')\n",
    "                    model, scaler = train_and_save_moe_model(filtered_data, species_name, cluster_label, look_back)\n",
    "\n",
    "                    # Guardar los datos para las bandas de confianza\n",
    "                    test_data_2023 = filtered_data[(filtered_data['date'].dt.year == 2023) & (filtered_data['date'].dt.month >= 1)]\n",
    "                    if len(test_data_2023) >= look_back:\n",
    "                        predictions, lower_bound, upper_bound = predict_with_confidence_intervals(model, scaler, test_data_2023, look_back)\n",
    "                        real_values = test_data_2023['landed_w_kg'].values[look_back:]\n",
    "                        \n",
    "                        # Crear un DataFrame para los resultados\n",
    "                        results_df = pd.DataFrame({\n",
    "                            'date': test_data_2023['date'].values[look_back:],\n",
    "                            'real_values': real_values,\n",
    "                            'predictions': predictions,\n",
    "                            'lower_bound': lower_bound,\n",
    "                            'upper_bound': upper_bound\n",
    "                        })\n",
    "                        \n",
    "                        # Guardar los resultados\n",
    "                        results_directory = 'resultados_moe'\n",
    "                        os.makedirs(results_directory, exist_ok=True)\n",
    "                        results_path = os.path.join(results_directory, f'{species_name}_cluster_{cluster_label}_predictions.csv')\n",
    "                        results_df.to_csv(results_path, index=False)\n",
    "                        \n",
    "                        # Agrupar por mes y sumar los valores\n",
    "                        monthly_totals = results_df.set_index('date').resample('M').sum()\n",
    "                        \n",
    "                        # Calcular MSE y R2 para los totales mensuales\n",
    "                        mse = mean_squared_error(monthly_totals['real_values'], monthly_totals['predictions'])\n",
    "                        r2 = r2_score(monthly_totals['real_values'], monthly_totals['predictions'])\n",
    "                        print(f'MSE Mensual para {species_name} en clúster {cluster_label}: {mse}, R2 Mensual: {r2}')\n",
    "                        \n",
    "                        # Crear figura\n",
    "                        plt.figure(figsize=(10, 6))\n",
    "                        plt.plot(monthly_totals.index, monthly_totals['real_values'], color='blue', label='Real')\n",
    "                        plt.plot(monthly_totals.index, monthly_totals['predictions'], color='red', linestyle='--', label='Predicho')\n",
    "                        plt.fill_between(monthly_totals.index, monthly_totals['lower_bound'], monthly_totals['upper_bound'], color='gray', alpha=0.2, label='Intervalo de Confianza 95%')\n",
    "                        plt.title(f'Totales Mensuales de {species_name} en clúster {cluster_label} para los Últimos Seis Meses de 2023')\n",
    "                        plt.xlabel('Fecha')\n",
    "                        plt.ylabel('Peso Desembarcado (kg)')\n",
    "                        plt.legend()\n",
    "                        plot_path = os.path.join(results_directory, f'{species_name}_cluster_{cluster_label}_plot.png')\n",
    "                        plt.savefig(plot_path)\n",
    "                        plt.close()\n",
    "                    else:\n",
    "                        print(f'No se tienen datos suficientes para {species_name} en clúster {cluster_label} en los últimos seis meses de 2023')\n",
    "                except Exception as e:\n",
    "                    print(f'Error entrenando el modelo para especie: {species_name}, clúster: {cluster_label}. Error: {e}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cedo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
