{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-19 18:30:21.729547: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-19 18:30:21.732287: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-19 18:30:21.770846: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-19 18:30:21.770873: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-19 18:30:21.771713: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-19 18:30:21.777563: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-19 18:30:21.778302: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-19 18:30:22.534054: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import LSTM, Dense, Dropout, Input, Conv1D, Flatten, concatenate\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Definir look_back\n",
    "look_back = 6  \n",
    "\n",
    "# Cargar el archivo y eliminar filas donde el clúster es NaN\n",
    "file_path = 'data/data.csv'   # Cambia esta ruta al archivo que has subido\n",
    "data = pd.read_csv(file_path)\n",
    "data = data.dropna(subset=['Cluster_Label'])\n",
    "\n",
    "# Convertir 'year' y 'month_no' a una sola columna de tipo fecha\n",
    "data['date'] = pd.to_datetime(data['year'].astype(str) + '-' + data['month_no'].astype(str))\n",
    "\n",
    "# Seleccionar las columnas necesarias para la serie temporal\n",
    "columns_to_keep = ['date', 'species', 'Cluster_Label', 'landed_w_kg',\n",
    "                   'mean_temp_30m','mean_temp_10m','thetao_sfc=6',\n",
    "                   'thetao_sfc=7.92956018447876','thetao_sfc=9.572997093200684','thetao_sfc=11.40499973297119',\n",
    "                   'thetao_sfc=13.46714019775391','thetao_sfc=15.8100700378418','thetao_sfc=18.49555969238281',\n",
    "                   'thetao_sfc=21.59881973266602','thetao_sfc=25.21141052246094','thetao_sfc=29.44473075866699']\n",
    "data = data[columns_to_keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para preparar los datos\n",
    "def prepare_data(group, look_back=6):\n",
    "    features = ['landed_w_kg','Cluster_Label', 'mean_temp_30m','mean_temp_10m','thetao_sfc=6',\n",
    "                   'thetao_sfc=7.92956018447876','thetao_sfc=9.572997093200684','thetao_sfc=11.40499973297119',\n",
    "                   'thetao_sfc=13.46714019775391','thetao_sfc=15.8100700378418','thetao_sfc=18.49555969238281',\n",
    "                   'thetao_sfc=21.59881973266602','thetao_sfc=25.21141052246094','thetao_sfc=29.44473075866699']\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    group_scaled = scaler.fit_transform(group[features])\n",
    "    \n",
    "    X, y = [], []\n",
    "    for i in range(len(group_scaled) - look_back):\n",
    "        a = group_scaled[i:(i + look_back)]\n",
    "        X.append(a)\n",
    "        y.append(group_scaled[i + look_back, 0])  # La primera columna es 'landed_w_kg'\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2]))\n",
    "    return X, y, scaler\n",
    "\n",
    "# Crear el modelo LSTM\n",
    "def create_lstm_model(input_shape):\n",
    "    lstm_input = Input(shape=input_shape)\n",
    "    x = LSTM(50, return_sequences=True)(lstm_input)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = LSTM(25, activation='relu', return_sequences=True)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = LSTM(12, activation='linear')(x)\n",
    "    lstm_output = Dense(1, activation='linear')(x)\n",
    "    return Model(inputs=lstm_input, outputs=lstm_output)\n",
    "\n",
    "# Crear el modelo DNN\n",
    "def create_dnn_model(input_shape):\n",
    "    dnn_input = Input(shape=(input_shape[0], input_shape[1]))\n",
    "    x = Flatten()(dnn_input)\n",
    "    x = Dense(10, activation='relu')(x)\n",
    "    x = Dense(5, activation='relu')(x)\n",
    "    dnn_output = Dense(1, activation='linear')(x)\n",
    "    return Model(inputs=dnn_input, outputs=dnn_output)\n",
    "\n",
    "# Crear el modelo CNN\n",
    "def create_cnn_model(input_shape):\n",
    "    cnn_input = Input(shape=input_shape)\n",
    "    x = Conv1D(32, kernel_size=3, activation='relu')(cnn_input)\n",
    "    x = Flatten()(x)\n",
    "    cnn_output = Dense(1, activation='linear')(x)\n",
    "    return Model(inputs=cnn_input, outputs=cnn_output)\n",
    "\n",
    "# Crear el modelo Mixture of Experts (MoE)\n",
    "def create_moe_model(input_shape):\n",
    "    # Definir los expertos\n",
    "    lstm_model = create_lstm_model(input_shape)\n",
    "    dnn_model = create_dnn_model(input_shape)\n",
    "    cnn_model = create_cnn_model(input_shape)\n",
    "    \n",
    "    # Definir el gating network\n",
    "    moe_input = Input(shape=input_shape)\n",
    "    x = Flatten()(moe_input)\n",
    "    x = Dense(10, activation='relu')(x)\n",
    "    gate_output = Dense(3, activation='softmax')(x)  # Tres expertos\n",
    "\n",
    "    # Obtener las salidas de los expertos\n",
    "    lstm_output = lstm_model(moe_input)\n",
    "    dnn_output = dnn_model(moe_input)\n",
    "    cnn_output = cnn_model(moe_input)\n",
    "    \n",
    "    # Combinar las salidas usando el gating network\n",
    "    output = concatenate([lstm_output * gate_output[:, 0:1],\n",
    "                          dnn_output * gate_output[:, 1:2],\n",
    "                          cnn_output * gate_output[:, 2:3]], axis=1)\n",
    "    output = Dense(1, activation='linear')(output)\n",
    "    \n",
    "    model = Model(inputs=moe_input, outputs=output)\n",
    "    model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar y guardar el modelo MoE\n",
    "def train_and_save_moe_model(data, species_name, cluster_label, look_back=look_back, epochs=50, batch_size=1):\n",
    "    X, y, scaler = prepare_data(data, look_back)\n",
    "    model = create_moe_model((look_back, X.shape[2]))\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "    history = model.fit(X, y, validation_split=0.2, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[early_stopping])\n",
    "    \n",
    "    # Guardar el modelo y el scaler\n",
    "    model_directory = 'modelos_moe'\n",
    "    os.makedirs(model_directory, exist_ok=True)\n",
    "    model_path = os.path.join(model_directory, f'{species_name}_cluster_{cluster_label}_moe_model.h5')\n",
    "    scaler_path = os.path.join(model_directory, f'{species_name}_cluster_{cluster_label}_moe_scaler.pkl')\n",
    "    model.save(model_path)\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    \n",
    "    # Guardar los valores de monitoreo del entrenamiento\n",
    "    train_moe_directory = 'train_moe'\n",
    "    os.makedirs(train_moe_directory, exist_ok=True)\n",
    "    history_path = os.path.join(train_moe_directory, f'{species_name}_cluster_{cluster_label}_training_history.csv')\n",
    "    pd.DataFrame(history.history).to_csv(history_path, index=False)\n",
    "    \n",
    "    print(f'Modelo MoE, scaler y datos de entrenamiento guardados para {species_name} en clúster {cluster_label}')\n",
    "    return model, scaler\n",
    "\n",
    "# Función para hacer predicciones con bandas de confianza usando bootstrap\n",
    "def predict_with_confidence_intervals(model, scaler, data, look_back=6, n_bootstrap=100, alpha=0.01):\n",
    "    features = ['landed_w_kg','Cluster_Label','mean_temp_30m','mean_temp_10m','thetao_sfc=6',\n",
    "                   'thetao_sfc=7.92956018447876','thetao_sfc=9.572997093200684','thetao_sfc=11.40499973297119',\n",
    "                   'thetao_sfc=13.46714019775391','thetao_sfc=15.8100700378418','thetao_sfc=18.49555969238281',\n",
    "                   'thetao_sfc=21.59881973266602','thetao_sfc=25.21141052246094','thetao_sfc=29.44473075866699']\n",
    "    group_scaled = scaler.transform(data[features])\n",
    "\n",
    "    X = []\n",
    "    for i in range(len(group_scaled) - look_back):\n",
    "        a = group_scaled[i:(i + look_back)]\n",
    "        X.append(a)\n",
    "    X = np.array(X)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2]))\n",
    "    \n",
    "    predictions = model.predict(X)\n",
    "    predictions = scaler.inverse_transform(np.hstack((predictions, X[:, -1, 1:])))[:, 0]\n",
    "    \n",
    "    # Bootstrap para bandas de confianza\n",
    "    bootstrap_predictions = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        indices = np.random.choice(range(len(X)), len(X), replace=True)\n",
    "        X_sample = X[indices]\n",
    "        pred_sample = model.predict(X_sample)\n",
    "        pred_sample = scaler.inverse_transform(np.hstack((pred_sample, X_sample[:, -1, 1:])))[:, 0]\n",
    "        bootstrap_predictions.append(pred_sample)\n",
    "    \n",
    "    bootstrap_predictions = np.array(bootstrap_predictions)\n",
    "    lower_bound = np.percentile(bootstrap_predictions, 100 * alpha / 2, axis=0)\n",
    "    upper_bound = np.percentile(bootstrap_predictions, 100 * (1 - alpha / 2), axis=0)\n",
    "    \n",
    "    return predictions, lower_bound, upper_bound\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: BERRUGATA, cluster: 7\n",
      "Epoch 1/50\n",
      "3231/3231 [==============================] - 20s 5ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 2/50\n",
      "3231/3231 [==============================] - 15s 5ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 3/50\n",
      "3231/3231 [==============================] - 15s 5ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 4/50\n",
      "3231/3231 [==============================] - 15s 5ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 5/50\n",
      "3231/3231 [==============================] - 15s 5ms/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 6/50\n",
      "3231/3231 [==============================] - 15s 5ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 7/50\n",
      "3231/3231 [==============================] - 15s 5ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 8/50\n",
      "3231/3231 [==============================] - 15s 5ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 9/50\n",
      "3231/3231 [==============================] - 15s 5ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 10/50\n",
      "3231/3231 [==============================] - 15s 5ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 11/50\n",
      "3231/3231 [==============================] - 15s 5ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 12/50\n",
      "3231/3231 [==============================] - 15s 5ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 13/50\n",
      "3231/3231 [==============================] - 15s 5ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 14/50\n",
      "3231/3231 [==============================] - 15s 5ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 15/50\n",
      "3231/3231 [==============================] - 15s 5ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 16/50\n",
      "3231/3231 [==============================] - 15s 5ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 17/50\n",
      "3231/3231 [==============================] - 15s 5ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 18/50\n",
      "3231/3231 [==============================] - 15s 5ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 19/50\n",
      "3231/3231 [==============================] - 15s 5ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 20/50\n",
      "3231/3231 [==============================] - 15s 5ms/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 21/50\n",
      "3231/3231 [==============================] - 15s 5ms/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 22/50\n",
      "3231/3231 [==============================] - 15s 5ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 23/50\n",
      "3231/3231 [==============================] - 15s 5ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 24/50\n",
      "3231/3231 [==============================] - 15s 5ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 25/50\n",
      "3231/3231 [==============================] - 15s 5ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 26/50\n",
      "3222/3231 [============================>.] - ETA: 0s - loss: 0.0037Restoring model weights from the end of the best epoch: 16.\n",
      "3231/3231 [==============================] - 15s 5ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 26: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BERRUGATA en clúster 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para BERRUGATA en clúster 7: 3381959.1648402377, R2 Mensual: 0.8850967284851329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1498818/2783649223.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: BERRUGATA, cluster: 0\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 4s 96ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "1/8 [==>...........................] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BERRUGATA en clúster 0\n",
      "No se tienen datos suficientes para BERRUGATA en clúster 0 en los últimos seis meses de 2023\n",
      "Training model for species: BERRUGATA, cluster: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7143/7143 [==============================] - 38s 5ms/step - loss: 0.0023 - val_loss: 8.8700e-04\n",
      "Epoch 2/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0021 - val_loss: 8.1805e-04\n",
      "Epoch 3/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0021 - val_loss: 8.2907e-04\n",
      "Epoch 4/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0020 - val_loss: 9.2906e-04\n",
      "Epoch 5/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0020 - val_loss: 8.1834e-04\n",
      "Epoch 6/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0020 - val_loss: 8.7541e-04\n",
      "Epoch 7/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0020 - val_loss: 7.8831e-04\n",
      "Epoch 8/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0020 - val_loss: 8.8504e-04\n",
      "Epoch 9/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0020 - val_loss: 8.1892e-04\n",
      "Epoch 10/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0020 - val_loss: 7.7790e-04\n",
      "Epoch 11/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0020 - val_loss: 7.8310e-04\n",
      "Epoch 12/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 13/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0020 - val_loss: 7.9453e-04\n",
      "Epoch 14/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0020 - val_loss: 7.9913e-04\n",
      "Epoch 15/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 8.0403e-04\n",
      "Epoch 16/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0020 - val_loss: 8.3249e-04\n",
      "Epoch 17/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0020 - val_loss: 7.7717e-04\n",
      "Epoch 18/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 9.9026e-04\n",
      "Epoch 19/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 8.1172e-04\n",
      "Epoch 20/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0020 - val_loss: 8.3925e-04\n",
      "Epoch 21/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 7.8274e-04\n",
      "Epoch 22/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 8.0121e-04\n",
      "Epoch 23/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 7.7604e-04\n",
      "Epoch 24/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 7.6145e-04\n",
      "Epoch 25/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 7.7311e-04\n",
      "Epoch 26/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 7.9091e-04\n",
      "Epoch 27/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 7.7545e-04\n",
      "Epoch 28/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 7.7171e-04\n",
      "Epoch 29/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 8.1939e-04\n",
      "Epoch 30/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 7.5488e-04\n",
      "Epoch 31/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 7.6878e-04\n",
      "Epoch 32/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 7.5306e-04\n",
      "Epoch 33/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 7.7063e-04\n",
      "Epoch 34/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 35/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 7.5559e-04\n",
      "Epoch 36/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 8.8988e-04\n",
      "Epoch 37/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 7.5490e-04\n",
      "Epoch 38/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 7.5536e-04\n",
      "Epoch 39/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 7.5454e-04\n",
      "Epoch 40/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 7.5391e-04\n",
      "Epoch 41/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 7.6923e-04\n",
      "Epoch 42/50\n",
      "7143/7143 [==============================] - 35s 5ms/step - loss: 0.0019 - val_loss: 7.4615e-04\n",
      "Epoch 43/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 7.8198e-04\n",
      "Epoch 44/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 7.9044e-04\n",
      "Epoch 45/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 7.6888e-04\n",
      "Epoch 46/50\n",
      "7143/7143 [==============================] - 35s 5ms/step - loss: 0.0019 - val_loss: 7.7495e-04\n",
      "Epoch 47/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 7.4508e-04\n",
      "Epoch 48/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 8.7556e-04\n",
      "Epoch 49/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 7.7746e-04\n",
      "Epoch 50/50\n",
      "7143/7143 [==============================] - 34s 5ms/step - loss: 0.0019 - val_loss: 7.8136e-04\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BERRUGATA en clúster 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 1s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "MSE Mensual para BERRUGATA en clúster 3: 276203357.948142, R2 Mensual: -0.0724291386257212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1498818/2783649223.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: BERRUGATA, cluster: 6\n",
      "Epoch 1/50\n",
      "3978/3978 [==============================] - 24s 5ms/step - loss: 0.0086 - val_loss: 0.0110\n",
      "Epoch 2/50\n",
      "3978/3978 [==============================] - 19s 5ms/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 3/50\n",
      "3978/3978 [==============================] - 19s 5ms/step - loss: 0.0076 - val_loss: 0.0114\n",
      "Epoch 4/50\n",
      "3978/3978 [==============================] - 19s 5ms/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 5/50\n",
      "3978/3978 [==============================] - 19s 5ms/step - loss: 0.0074 - val_loss: 0.0104\n",
      "Epoch 6/50\n",
      "3978/3978 [==============================] - 19s 5ms/step - loss: 0.0074 - val_loss: 0.0108\n",
      "Epoch 7/50\n",
      "3978/3978 [==============================] - 19s 5ms/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 8/50\n",
      "3978/3978 [==============================] - 19s 5ms/step - loss: 0.0072 - val_loss: 0.0107\n",
      "Epoch 9/50\n",
      "3978/3978 [==============================] - 19s 5ms/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 10/50\n",
      "3978/3978 [==============================] - 19s 5ms/step - loss: 0.0072 - val_loss: 0.0106\n",
      "Epoch 11/50\n",
      "3978/3978 [==============================] - 19s 5ms/step - loss: 0.0071 - val_loss: 0.0112\n",
      "Epoch 12/50\n",
      "3978/3978 [==============================] - 19s 5ms/step - loss: 0.0072 - val_loss: 0.0108\n",
      "Epoch 13/50\n",
      "3978/3978 [==============================] - 19s 5ms/step - loss: 0.0071 - val_loss: 0.0106\n",
      "Epoch 14/50\n",
      "3977/3978 [============================>.] - ETA: 0s - loss: 0.0071Restoring model weights from the end of the best epoch: 4.\n",
      "3978/3978 [==============================] - 19s 5ms/step - loss: 0.0071 - val_loss: 0.0110\n",
      "Epoch 14: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BERRUGATA en clúster 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 2ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 2ms/step\n",
      "28/28 [==============================] - 0s 2ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 2ms/step\n",
      "28/28 [==============================] - 0s 2ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para BERRUGATA en clúster 6: 16780906886.13173, R2 Mensual: 0.9472615545537011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1498818/2783649223.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: BERRUGATA, cluster: 5\n",
      "Epoch 1/50\n",
      "368/368 [==============================] - 6s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "368/368 [==============================] - 2s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "368/368 [==============================] - 2s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "368/368 [==============================] - 2s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "368/368 [==============================] - 2s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "368/368 [==============================] - 2s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "368/368 [==============================] - 2s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "368/368 [==============================] - 2s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "368/368 [==============================] - 2s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "364/368 [============================>.] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "368/368 [==============================] - 2s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BERRUGATA en clúster 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 4ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para BERRUGATA en clúster 5: 84206073023.18182, R2 Mensual: -0.3333463951061608\n",
      "Training model for species: BERRUGATA, cluster: 2\n",
      "Error entrenando el modelo para especie: BERRUGATA, clúster: 2. Error: tuple index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1498818/2783649223.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: BERRUGATA, cluster: 1\n",
      "Epoch 1/50\n",
      "3777/3777 [==============================] - 22s 5ms/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 2/50\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 3/50\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 4/50\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 5/50\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 6/50\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 7/50\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 8/50\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 9/50\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 10/50\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 11/50\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 12/50\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 13/50\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 14/50\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 15/50\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 16/50\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 17/50\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 18/50\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 19/50\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 20/50\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 21/50\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 22/50\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 23/50\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 24/50\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 25/50\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 26/50\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 27/50\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 28/50\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 29/50\n",
      "3775/3777 [============================>.] - ETA: 0s - loss: 0.0042Restoring model weights from the end of the best epoch: 19.\n",
      "3777/3777 [==============================] - 18s 5ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 29: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BERRUGATA en clúster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 2ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para BERRUGATA en clúster 1: 490529564.9215219, R2 Mensual: 0.9503746960343461\n",
      "Training model for species: BERRUGATA, cluster: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1498818/2783649223.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 5s 79ms/step - loss: 0.0781 - val_loss: 0.2693\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0689 - val_loss: 0.2542\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0618 - val_loss: 0.2593\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0582 - val_loss: 0.2509\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0539 - val_loss: 0.2406\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0556 - val_loss: 0.2182\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0517 - val_loss: 0.2359\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0496 - val_loss: 0.2175\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0463 - val_loss: 0.2386\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0408 - val_loss: 0.2366\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0399 - val_loss: 0.2190\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0338 - val_loss: 0.2388\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0302 - val_loss: 0.2355\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0300 - val_loss: 0.2512\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0280 - val_loss: 0.2366\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0301 - val_loss: 0.2606\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0284 - val_loss: 0.2447\n",
      "Epoch 18/50\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 2.2369e-04Restoring model weights from the end of the best epoch: 8.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0225 - val_loss: 0.2657\n",
      "Epoch 18: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BERRUGATA en clúster 4\n",
      "No se tienen datos suficientes para BERRUGATA en clúster 4 en los últimos seis meses de 2023\n",
      "Training model for species: ROBALO, cluster: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12775/12775 [==============================] - 66s 5ms/step - loss: 6.2729e-04 - val_loss: 8.1740e-04\n",
      "Epoch 2/50\n",
      "12775/12775 [==============================] - 61s 5ms/step - loss: 5.9239e-04 - val_loss: 7.0775e-04\n",
      "Epoch 3/50\n",
      "12775/12775 [==============================] - 61s 5ms/step - loss: 5.6463e-04 - val_loss: 7.4654e-04\n",
      "Epoch 4/50\n",
      "12775/12775 [==============================] - 61s 5ms/step - loss: 5.4811e-04 - val_loss: 6.8292e-04\n",
      "Epoch 5/50\n",
      "12775/12775 [==============================] - 61s 5ms/step - loss: 5.3795e-04 - val_loss: 7.6115e-04\n",
      "Epoch 6/50\n",
      "12775/12775 [==============================] - 61s 5ms/step - loss: 5.4720e-04 - val_loss: 7.0868e-04\n",
      "Epoch 7/50\n",
      "12775/12775 [==============================] - 61s 5ms/step - loss: 5.3185e-04 - val_loss: 7.1491e-04\n",
      "Epoch 8/50\n",
      "12775/12775 [==============================] - 60s 5ms/step - loss: 5.2983e-04 - val_loss: 7.4489e-04\n",
      "Epoch 9/50\n",
      "12775/12775 [==============================] - 60s 5ms/step - loss: 5.2995e-04 - val_loss: 6.3842e-04\n",
      "Epoch 10/50\n",
      "12775/12775 [==============================] - 60s 5ms/step - loss: 5.2649e-04 - val_loss: 6.6714e-04\n",
      "Epoch 11/50\n",
      "12775/12775 [==============================] - 60s 5ms/step - loss: 5.2646e-04 - val_loss: 6.6696e-04\n",
      "Epoch 12/50\n",
      "12775/12775 [==============================] - 60s 5ms/step - loss: 5.2413e-04 - val_loss: 6.9995e-04\n",
      "Epoch 13/50\n",
      "12775/12775 [==============================] - 59s 5ms/step - loss: 5.1969e-04 - val_loss: 7.9340e-04\n",
      "Epoch 14/50\n",
      "12775/12775 [==============================] - 59s 5ms/step - loss: 5.2488e-04 - val_loss: 6.7158e-04\n",
      "Epoch 15/50\n",
      "12775/12775 [==============================] - 59s 5ms/step - loss: 5.2865e-04 - val_loss: 6.6073e-04\n",
      "Epoch 16/50\n",
      "12775/12775 [==============================] - 59s 5ms/step - loss: 5.2707e-04 - val_loss: 9.8003e-04\n",
      "Epoch 17/50\n",
      "12775/12775 [==============================] - 59s 5ms/step - loss: 5.2937e-04 - val_loss: 6.8161e-04\n",
      "Epoch 18/50\n",
      "12775/12775 [==============================] - 58s 5ms/step - loss: 5.2676e-04 - val_loss: 6.7313e-04\n",
      "Epoch 19/50\n",
      "12772/12775 [============================>.] - ETA: 0s - loss: 5.2100e-04Restoring model weights from the end of the best epoch: 9.\n",
      "12775/12775 [==============================] - 59s 5ms/step - loss: 5.2405e-04 - val_loss: 6.8636e-04\n",
      "Epoch 19: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para ROBALO en clúster 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "MSE Mensual para ROBALO en clúster 7: 9546687.284105897, R2 Mensual: 0.8242178565264536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1498818/2783649223.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: ROBALO, cluster: 0\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 5s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "112/112 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para ROBALO en clúster 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "MSE Mensual para ROBALO en clúster 0: 8271745.0, R2 Mensual: -2.672931201129266\n",
      "Training model for species: ROBALO, cluster: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1498818/2783649223.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3492/3492 [==============================] - 21s 5ms/step - loss: 0.0036 - val_loss: 0.0016\n",
      "Epoch 2/50\n",
      "3492/3492 [==============================] - 17s 5ms/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 3/50\n",
      "3492/3492 [==============================] - 17s 5ms/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 4/50\n",
      "3492/3492 [==============================] - 17s 5ms/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 5/50\n",
      "3492/3492 [==============================] - 17s 5ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 6/50\n",
      "3492/3492 [==============================] - 17s 5ms/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 7/50\n",
      "3492/3492 [==============================] - 17s 5ms/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 8/50\n",
      "3492/3492 [==============================] - 17s 5ms/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 9/50\n",
      "3492/3492 [==============================] - 16s 5ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 10/50\n",
      "3492/3492 [==============================] - 17s 5ms/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 11/50\n",
      "3492/3492 [==============================] - 17s 5ms/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 12/50\n",
      "3492/3492 [==============================] - 17s 5ms/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 13/50\n",
      "3492/3492 [==============================] - 17s 5ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 14/50\n",
      "3492/3492 [==============================] - 17s 5ms/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 15/50\n",
      "3492/3492 [==============================] - 17s 5ms/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 16/50\n",
      "3492/3492 [==============================] - 17s 5ms/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 17/50\n",
      "3492/3492 [==============================] - 17s 5ms/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 18/50\n",
      "3492/3492 [==============================] - 17s 5ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 19/50\n",
      "3492/3492 [==============================] - 17s 5ms/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 20/50\n",
      "3492/3492 [==============================] - 17s 5ms/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 21/50\n",
      "3492/3492 [==============================] - 17s 5ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 22/50\n",
      "3492/3492 [==============================] - 16s 5ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 23/50\n",
      "3492/3492 [==============================] - 17s 5ms/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 24/50\n",
      "3492/3492 [==============================] - 17s 5ms/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 25/50\n",
      "3492/3492 [==============================] - 17s 5ms/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 26/50\n",
      "3492/3492 [==============================] - 17s 5ms/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 27/50\n",
      "3492/3492 [==============================] - 17s 5ms/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 28/50\n",
      "3492/3492 [==============================] - 16s 5ms/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 29/50\n",
      "3492/3492 [==============================] - ETA: 0s - loss: 0.0030Restoring model weights from the end of the best epoch: 19.\n",
      "3492/3492 [==============================] - 17s 5ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 29: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para ROBALO en clúster 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para ROBALO en clúster 3: 26706641.41141193, R2 Mensual: 0.7918904191171416\n",
      "Training model for species: ROBALO, cluster: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1498818/2783649223.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "36/36 [==============================] - 4s 24ms/step - loss: 0.0556 - val_loss: 0.0081\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0471 - val_loss: 0.0085\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0404 - val_loss: 0.0078\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0368 - val_loss: 0.0101\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0347 - val_loss: 0.0095\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0330 - val_loss: 0.0129\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0321 - val_loss: 0.0081\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0299 - val_loss: 0.0094\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0262 - val_loss: 0.0118\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0250 - val_loss: 0.0126\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0240 - val_loss: 0.0126\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0221 - val_loss: 0.0165\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0203Restoring model weights from the end of the best epoch: 3.\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0203 - val_loss: 0.0119\n",
      "Epoch 13: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para ROBALO en clúster 6\n",
      "No se tienen datos suficientes para ROBALO en clúster 6 en los últimos seis meses de 2023\n",
      "Training model for species: ROBALO, cluster: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1930/1930 [==============================] - 13s 5ms/step - loss: 0.0016 - val_loss: 5.8370e-04\n",
      "Epoch 2/50\n",
      "1930/1930 [==============================] - 9s 5ms/step - loss: 0.0015 - val_loss: 5.5707e-04\n",
      "Epoch 3/50\n",
      "1930/1930 [==============================] - 9s 5ms/step - loss: 0.0015 - val_loss: 6.3477e-04\n",
      "Epoch 4/50\n",
      "1930/1930 [==============================] - 9s 5ms/step - loss: 0.0015 - val_loss: 5.5574e-04\n",
      "Epoch 5/50\n",
      "1930/1930 [==============================] - 9s 5ms/step - loss: 0.0014 - val_loss: 5.6736e-04\n",
      "Epoch 6/50\n",
      "1930/1930 [==============================] - 9s 5ms/step - loss: 0.0014 - val_loss: 5.5792e-04\n",
      "Epoch 7/50\n",
      "1930/1930 [==============================] - 9s 5ms/step - loss: 0.0014 - val_loss: 6.7716e-04\n",
      "Epoch 8/50\n",
      "1930/1930 [==============================] - 9s 5ms/step - loss: 0.0014 - val_loss: 5.6475e-04\n",
      "Epoch 9/50\n",
      "1930/1930 [==============================] - 9s 5ms/step - loss: 0.0014 - val_loss: 5.5707e-04\n",
      "Epoch 10/50\n",
      "1930/1930 [==============================] - 9s 5ms/step - loss: 0.0014 - val_loss: 6.2793e-04\n",
      "Epoch 11/50\n",
      "1930/1930 [==============================] - 9s 5ms/step - loss: 0.0014 - val_loss: 5.7511e-04\n",
      "Epoch 12/50\n",
      "1930/1930 [==============================] - 9s 5ms/step - loss: 0.0014 - val_loss: 6.0434e-04\n",
      "Epoch 13/50\n",
      "1930/1930 [==============================] - 9s 5ms/step - loss: 0.0014 - val_loss: 5.9321e-04\n",
      "Epoch 14/50\n",
      "1919/1930 [============================>.] - ETA: 0s - loss: 0.0014Restoring model weights from the end of the best epoch: 4.\n",
      "1930/1930 [==============================] - 9s 5ms/step - loss: 0.0014 - val_loss: 5.9038e-04\n",
      "Epoch 14: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para ROBALO en clúster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para ROBALO en clúster 1: 3741777.2963397917, R2 Mensual: 0.33179686789224816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1498818/2783649223.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: ROBALO, cluster: 4\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 4s 81ms/step - loss: 0.0521 - val_loss: 0.2909\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0293 - val_loss: 0.2891\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0277 - val_loss: 0.3075\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0241 - val_loss: 0.2928\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0228 - val_loss: 0.2731\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.2654\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.2818\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.2835\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.2668\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.2704\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.2764\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.2758\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0145 - val_loss: 0.2801\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.2785\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.2759\n",
      "Epoch 16/50\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 1.9134e-04Restoring model weights from the end of the best epoch: 6.\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.2908\n",
      "Epoch 16: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para ROBALO en clúster 4\n",
      "No se tienen datos suficientes para ROBALO en clúster 4 en los últimos seis meses de 2023\n",
      "Training model for species: BAQUETA, cluster: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "196/196 [==============================] - 5s 9ms/step - loss: 0.0069 - val_loss: 0.0014\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.0064 - val_loss: 0.0014\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.0060 - val_loss: 0.0015\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.0059 - val_loss: 0.0015\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.0058 - val_loss: 0.0014\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.0058 - val_loss: 0.0015\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.0056 - val_loss: 0.0024\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.0055 - val_loss: 0.0014\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.0056 - val_loss: 0.0015\n",
      "Epoch 12/50\n",
      "192/196 [============================>.] - ETA: 0s - loss: 0.0057Restoring model weights from the end of the best epoch: 2.\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.0056 - val_loss: 0.0016\n",
      "Epoch 12: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BAQUETA en clúster 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 588ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "MSE Mensual para BAQUETA en clúster 7: 31078.56069004562, R2 Mensual: 0.30525691617595485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1498818/2783649223.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: BAQUETA, cluster: 3\n",
      "Epoch 1/50\n",
      "3809/3809 [==============================] - 23s 5ms/step - loss: 0.0018 - val_loss: 9.3793e-04\n",
      "Epoch 2/50\n",
      "3809/3809 [==============================] - 18s 5ms/step - loss: 0.0017 - val_loss: 8.8122e-04\n",
      "Epoch 3/50\n",
      "3809/3809 [==============================] - 18s 5ms/step - loss: 0.0017 - val_loss: 8.9643e-04\n",
      "Epoch 4/50\n",
      "3809/3809 [==============================] - 18s 5ms/step - loss: 0.0017 - val_loss: 8.0184e-04\n",
      "Epoch 5/50\n",
      "3809/3809 [==============================] - 18s 5ms/step - loss: 0.0017 - val_loss: 8.8415e-04\n",
      "Epoch 6/50\n",
      "3809/3809 [==============================] - 18s 5ms/step - loss: 0.0016 - val_loss: 8.0531e-04\n",
      "Epoch 7/50\n",
      "3809/3809 [==============================] - 18s 5ms/step - loss: 0.0016 - val_loss: 9.1102e-04\n",
      "Epoch 8/50\n",
      "3809/3809 [==============================] - 18s 5ms/step - loss: 0.0016 - val_loss: 8.0024e-04\n",
      "Epoch 9/50\n",
      "3809/3809 [==============================] - 18s 5ms/step - loss: 0.0016 - val_loss: 8.1108e-04\n",
      "Epoch 10/50\n",
      "3809/3809 [==============================] - 18s 5ms/step - loss: 0.0016 - val_loss: 7.6883e-04\n",
      "Epoch 11/50\n",
      "3809/3809 [==============================] - 18s 5ms/step - loss: 0.0016 - val_loss: 8.0742e-04\n",
      "Epoch 12/50\n",
      "3809/3809 [==============================] - 18s 5ms/step - loss: 0.0016 - val_loss: 8.4971e-04\n",
      "Epoch 13/50\n",
      "3809/3809 [==============================] - 18s 5ms/step - loss: 0.0016 - val_loss: 8.6572e-04\n",
      "Epoch 14/50\n",
      "3809/3809 [==============================] - 18s 5ms/step - loss: 0.0016 - val_loss: 7.8764e-04\n",
      "Epoch 15/50\n",
      "3809/3809 [==============================] - 18s 5ms/step - loss: 0.0016 - val_loss: 9.1745e-04\n",
      "Epoch 16/50\n",
      "3809/3809 [==============================] - 18s 5ms/step - loss: 0.0016 - val_loss: 8.4317e-04\n",
      "Epoch 17/50\n",
      "3809/3809 [==============================] - 18s 5ms/step - loss: 0.0016 - val_loss: 8.1840e-04\n",
      "Epoch 18/50\n",
      "3809/3809 [==============================] - 18s 5ms/step - loss: 0.0016 - val_loss: 8.0112e-04\n",
      "Epoch 19/50\n",
      "3809/3809 [==============================] - 18s 5ms/step - loss: 0.0016 - val_loss: 7.7819e-04\n",
      "Epoch 20/50\n",
      "3803/3809 [============================>.] - ETA: 0s - loss: 0.0016Restoring model weights from the end of the best epoch: 10.\n",
      "3809/3809 [==============================] - 18s 5ms/step - loss: 0.0016 - val_loss: 8.2945e-04\n",
      "Epoch 20: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BAQUETA en clúster 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 4ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para BAQUETA en clúster 3: 45070148.896470524, R2 Mensual: 0.642208626417015\n",
      "Training model for species: BAQUETA, cluster: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1498818/2783649223.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4692/4692 [==============================] - 26s 5ms/step - loss: 0.0148 - val_loss: 0.0065\n",
      "Epoch 2/50\n",
      "4692/4692 [==============================] - 22s 5ms/step - loss: 0.0141 - val_loss: 0.0062\n",
      "Epoch 3/50\n",
      "4692/4692 [==============================] - 22s 5ms/step - loss: 0.0140 - val_loss: 0.0106\n",
      "Epoch 4/50\n",
      "4692/4692 [==============================] - 22s 5ms/step - loss: 0.0139 - val_loss: 0.0065\n",
      "Epoch 5/50\n",
      "4692/4692 [==============================] - 22s 5ms/step - loss: 0.0138 - val_loss: 0.0070\n",
      "Epoch 6/50\n",
      "4692/4692 [==============================] - 22s 5ms/step - loss: 0.0137 - val_loss: 0.0062\n",
      "Epoch 7/50\n",
      "4692/4692 [==============================] - 22s 5ms/step - loss: 0.0136 - val_loss: 0.0063\n",
      "Epoch 8/50\n",
      "4692/4692 [==============================] - 22s 5ms/step - loss: 0.0137 - val_loss: 0.0070\n",
      "Epoch 9/50\n",
      "4692/4692 [==============================] - 22s 5ms/step - loss: 0.0137 - val_loss: 0.0062\n",
      "Epoch 10/50\n",
      "4692/4692 [==============================] - 22s 5ms/step - loss: 0.0136 - val_loss: 0.0068\n",
      "Epoch 11/50\n",
      "4692/4692 [==============================] - 22s 5ms/step - loss: 0.0135 - val_loss: 0.0064\n",
      "Epoch 12/50\n",
      "4692/4692 [==============================] - 22s 5ms/step - loss: 0.0137 - val_loss: 0.0067\n",
      "Epoch 13/50\n",
      "4692/4692 [==============================] - 22s 5ms/step - loss: 0.0136 - val_loss: 0.0064\n",
      "Epoch 14/50\n",
      "4692/4692 [==============================] - 22s 5ms/step - loss: 0.0136 - val_loss: 0.0064\n",
      "Epoch 15/50\n",
      "4692/4692 [==============================] - 22s 5ms/step - loss: 0.0135 - val_loss: 0.0063\n",
      "Epoch 16/50\n",
      "4691/4692 [============================>.] - ETA: 0s - loss: 0.0135Restoring model weights from the end of the best epoch: 6.\n",
      "4692/4692 [==============================] - 22s 5ms/step - loss: 0.0135 - val_loss: 0.0066\n",
      "Epoch 16: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BAQUETA en clúster 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para BAQUETA en clúster 6: 42339514.70064306, R2 Mensual: 0.9686301721893462\n",
      "Training model for species: BAQUETA, cluster: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1498818/2783649223.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 4s 326ms/step - loss: 0.0244 - val_loss: 0.0543\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0160 - val_loss: 0.0624\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0148 - val_loss: 0.0697\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0147 - val_loss: 0.0832\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0107 - val_loss: 0.0844\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0109 - val_loss: 0.0836\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0086 - val_loss: 0.0785\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0692\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0064 - val_loss: 0.0616\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0058 - val_loss: 0.0552\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0051 - val_loss: 0.0524\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0045 - val_loss: 0.0529\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0522\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0029 - val_loss: 0.0516\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0028 - val_loss: 0.0513\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0515\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0019 - val_loss: 0.0480\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0449\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0412\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0372\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 9.1929e-04 - val_loss: 0.0349\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 5.0319e-04 - val_loss: 0.0354\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.2615e-04 - val_loss: 0.0348\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2.3310e-04 - val_loss: 0.0343\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.5732e-04 - val_loss: 0.0337\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.1768e-05 - val_loss: 0.0328\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 8.5891e-05 - val_loss: 0.0316\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 4.6946e-05 - val_loss: 0.0300\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2.2551e-05 - val_loss: 0.0286\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.8610e-05 - val_loss: 0.0281\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.5918e-05 - val_loss: 0.0283\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 9.4368e-06 - val_loss: 0.0287\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.5112e-05 - val_loss: 0.0287\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.0974e-05 - val_loss: 0.0286\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.4846e-05 - val_loss: 0.0287\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.2543e-05 - val_loss: 0.0286\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 7.2570e-06 - val_loss: 0.0286\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 4.8520e-05 - val_loss: 0.0287\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.0228e-05 - val_loss: 0.0292\n",
      "Epoch 40/50\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.9207e-06Restoring model weights from the end of the best epoch: 30.\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 4.0200e-06 - val_loss: 0.0295\n",
      "Epoch 40: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BAQUETA en clúster 5\n",
      "Error entrenando el modelo para especie: BAQUETA, clúster: 5. Error: tuple index out of range\n",
      "Training model for species: BAQUETA, cluster: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 4s 33ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "13/23 [===============>..............] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "23/23 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BAQUETA en clúster 2\n",
      "No se tienen datos suficientes para BAQUETA en clúster 2 en los últimos seis meses de 2023\n",
      "Training model for species: BAQUETA, cluster: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5121/5121 [==============================] - 31s 5ms/step - loss: 0.0066 - val_loss: 0.0043\n",
      "Epoch 2/50\n",
      "5121/5121 [==============================] - 25s 5ms/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 3/50\n",
      "5121/5121 [==============================] - 25s 5ms/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 4/50\n",
      "5121/5121 [==============================] - 25s 5ms/step - loss: 0.0061 - val_loss: 0.0041\n",
      "Epoch 5/50\n",
      "5121/5121 [==============================] - 25s 5ms/step - loss: 0.0060 - val_loss: 0.0040\n",
      "Epoch 6/50\n",
      "5121/5121 [==============================] - 25s 5ms/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 7/50\n",
      "5121/5121 [==============================] - 25s 5ms/step - loss: 0.0059 - val_loss: 0.0040\n",
      "Epoch 8/50\n",
      "5121/5121 [==============================] - 25s 5ms/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 9/50\n",
      "5121/5121 [==============================] - 25s 5ms/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 10/50\n",
      "5121/5121 [==============================] - 24s 5ms/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 11/50\n",
      "5121/5121 [==============================] - 25s 5ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 12/50\n",
      "5121/5121 [==============================] - 25s 5ms/step - loss: 0.0058 - val_loss: 0.0039\n",
      "Epoch 13/50\n",
      "5121/5121 [==============================] - 25s 5ms/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 14/50\n",
      "5121/5121 [==============================] - 25s 5ms/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 15/50\n",
      "5121/5121 [==============================] - 25s 5ms/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 16/50\n",
      "5121/5121 [==============================] - 25s 5ms/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 17/50\n",
      "5121/5121 [==============================] - 25s 5ms/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 18/50\n",
      "5121/5121 [==============================] - 25s 5ms/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 19/50\n",
      "5121/5121 [==============================] - 25s 5ms/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 20/50\n",
      "5121/5121 [==============================] - 24s 5ms/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 21/50\n",
      "5121/5121 [==============================] - 25s 5ms/step - loss: 0.0057 - val_loss: 0.0040\n",
      "Epoch 22/50\n",
      "5114/5121 [============================>.] - ETA: 0s - loss: 0.0057Restoring model weights from the end of the best epoch: 12.\n",
      "5121/5121 [==============================] - 25s 5ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 22: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BAQUETA en clúster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 1s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "MSE Mensual para BAQUETA en clúster 1: 49397301.21998436, R2 Mensual: 0.837326993165263\n",
      "Training model for species: BAQUETA, cluster: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1498818/2783649223.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 4s 74ms/step - loss: 0.1016 - val_loss: 0.3729\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.2494\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.2572\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.2889\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.2891\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.2723\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.2673\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.2593\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.2599\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.2650\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.2623\n",
      "Epoch 12/50\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.7635e-04Restoring model weights from the end of the best epoch: 2.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0029 - val_loss: 0.2597\n",
      "Epoch 12: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BAQUETA en clúster 4\n",
      "No se tienen datos suficientes para BAQUETA en clúster 4 en los últimos seis meses de 2023\n",
      "Training model for species: LENGUADO, cluster: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "301/301 [==============================] - 5s 7ms/step - loss: 0.0113 - val_loss: 0.0079\n",
      "Epoch 2/50\n",
      "301/301 [==============================] - 1s 5ms/step - loss: 0.0108 - val_loss: 0.0088\n",
      "Epoch 3/50\n",
      "301/301 [==============================] - 1s 5ms/step - loss: 0.0104 - val_loss: 0.0076\n",
      "Epoch 4/50\n",
      "301/301 [==============================] - 1s 5ms/step - loss: 0.0104 - val_loss: 0.0078\n",
      "Epoch 5/50\n",
      "301/301 [==============================] - 1s 5ms/step - loss: 0.0103 - val_loss: 0.0124\n",
      "Epoch 6/50\n",
      "301/301 [==============================] - 2s 5ms/step - loss: 0.0107 - val_loss: 0.0090\n",
      "Epoch 7/50\n",
      "301/301 [==============================] - 1s 5ms/step - loss: 0.0105 - val_loss: 0.0078\n",
      "Epoch 8/50\n",
      "301/301 [==============================] - 1s 5ms/step - loss: 0.0104 - val_loss: 0.0079\n",
      "Epoch 9/50\n",
      "301/301 [==============================] - 1s 5ms/step - loss: 0.0102 - val_loss: 0.0078\n",
      "Epoch 10/50\n",
      "301/301 [==============================] - 1s 5ms/step - loss: 0.0102 - val_loss: 0.0077\n",
      "Epoch 11/50\n",
      "301/301 [==============================] - 1s 5ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 12/50\n",
      "301/301 [==============================] - 1s 5ms/step - loss: 0.0104 - val_loss: 0.0077\n",
      "Epoch 13/50\n",
      "294/301 [============================>.] - ETA: 0s - loss: 0.0104Restoring model weights from the end of the best epoch: 3.\n",
      "301/301 [==============================] - 1s 5ms/step - loss: 0.0105 - val_loss: 0.0085\n",
      "Epoch 13: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LENGUADO en clúster 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para LENGUADO en clúster 7: 191154.70903869122, R2 Mensual: 0.9147060691593998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1498818/2783649223.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: LENGUADO, cluster: 3\n",
      "Epoch 1/50\n",
      "2143/2143 [==============================] - 14s 5ms/step - loss: 0.0043 - val_loss: 3.9449e-04\n",
      "Epoch 2/50\n",
      "2143/2143 [==============================] - 10s 5ms/step - loss: 0.0041 - val_loss: 2.4330e-04\n",
      "Epoch 3/50\n",
      "2143/2143 [==============================] - 10s 5ms/step - loss: 0.0041 - val_loss: 2.5609e-04\n",
      "Epoch 4/50\n",
      "2143/2143 [==============================] - 10s 5ms/step - loss: 0.0041 - val_loss: 2.6898e-04\n",
      "Epoch 5/50\n",
      "2143/2143 [==============================] - 10s 5ms/step - loss: 0.0041 - val_loss: 2.4051e-04\n",
      "Epoch 6/50\n",
      "2143/2143 [==============================] - 10s 5ms/step - loss: 0.0040 - val_loss: 5.2196e-04\n",
      "Epoch 7/50\n",
      "2143/2143 [==============================] - 10s 5ms/step - loss: 0.0040 - val_loss: 3.7578e-04\n",
      "Epoch 8/50\n",
      "2143/2143 [==============================] - 10s 5ms/step - loss: 0.0039 - val_loss: 2.7150e-04\n",
      "Epoch 9/50\n",
      "2143/2143 [==============================] - 10s 5ms/step - loss: 0.0038 - val_loss: 3.2914e-04\n",
      "Epoch 10/50\n",
      "2143/2143 [==============================] - 10s 5ms/step - loss: 0.0038 - val_loss: 2.4918e-04\n",
      "Epoch 11/50\n",
      "2143/2143 [==============================] - 10s 5ms/step - loss: 0.0039 - val_loss: 2.5705e-04\n",
      "Epoch 12/50\n",
      "2143/2143 [==============================] - 10s 5ms/step - loss: 0.0038 - val_loss: 2.7766e-04\n",
      "Epoch 13/50\n",
      "2143/2143 [==============================] - 10s 5ms/step - loss: 0.0038 - val_loss: 5.4812e-04\n",
      "Epoch 14/50\n",
      "2143/2143 [==============================] - 10s 5ms/step - loss: 0.0039 - val_loss: 2.6767e-04\n",
      "Epoch 15/50\n",
      "2142/2143 [============================>.] - ETA: 0s - loss: 0.0037Restoring model weights from the end of the best epoch: 5.\n",
      "2143/2143 [==============================] - 10s 5ms/step - loss: 0.0037 - val_loss: 3.5573e-04\n",
      "Epoch 15: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LENGUADO en clúster 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para LENGUADO en clúster 3: 154050329.83706912, R2 Mensual: 0.4110531815538703\n",
      "Training model for species: LENGUADO, cluster: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1498818/2783649223.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6611/6611 [==============================] - 37s 5ms/step - loss: 1.6146e-04 - val_loss: 2.1008e-07\n",
      "Epoch 2/50\n",
      "6611/6611 [==============================] - 32s 5ms/step - loss: 1.5447e-04 - val_loss: 3.9389e-07\n",
      "Epoch 3/50\n",
      "6611/6611 [==============================] - 32s 5ms/step - loss: 1.5579e-04 - val_loss: 1.8979e-07\n",
      "Epoch 4/50\n",
      "6611/6611 [==============================] - 31s 5ms/step - loss: 1.5320e-04 - val_loss: 1.7892e-06\n",
      "Epoch 5/50\n",
      "6611/6611 [==============================] - 31s 5ms/step - loss: 1.5526e-04 - val_loss: 1.4097e-07\n",
      "Epoch 6/50\n",
      "6611/6611 [==============================] - 32s 5ms/step - loss: 1.5762e-04 - val_loss: 1.3867e-07\n",
      "Epoch 7/50\n",
      "6611/6611 [==============================] - 32s 5ms/step - loss: 1.5592e-04 - val_loss: 1.2969e-06\n",
      "Epoch 8/50\n",
      "6611/6611 [==============================] - 32s 5ms/step - loss: 1.5450e-04 - val_loss: 1.4796e-07\n",
      "Epoch 9/50\n",
      "6611/6611 [==============================] - 31s 5ms/step - loss: 1.5464e-04 - val_loss: 2.1972e-07\n",
      "Epoch 10/50\n",
      "6611/6611 [==============================] - 32s 5ms/step - loss: 1.5587e-04 - val_loss: 3.6386e-07\n",
      "Epoch 11/50\n",
      "6611/6611 [==============================] - 32s 5ms/step - loss: 1.5272e-04 - val_loss: 9.1397e-07\n",
      "Epoch 12/50\n",
      "6611/6611 [==============================] - 32s 5ms/step - loss: 1.5577e-04 - val_loss: 2.0876e-07\n",
      "Epoch 13/50\n",
      "6611/6611 [==============================] - 31s 5ms/step - loss: 1.5628e-04 - val_loss: 2.4998e-07\n",
      "Epoch 14/50\n",
      "6611/6611 [==============================] - 32s 5ms/step - loss: 1.5612e-04 - val_loss: 1.5330e-07\n",
      "Epoch 15/50\n",
      "6611/6611 [==============================] - 31s 5ms/step - loss: 1.5604e-04 - val_loss: 1.9814e-07\n",
      "Epoch 16/50\n",
      "6605/6611 [============================>.] - ETA: 0s - loss: 1.5582e-04Restoring model weights from the end of the best epoch: 6.\n",
      "6611/6611 [==============================] - 31s 5ms/step - loss: 1.5568e-04 - val_loss: 1.7082e-07\n",
      "Epoch 16: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LENGUADO en clúster 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 1s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 2ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 2ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 2ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 2ms/step\n",
      "60/60 [==============================] - 0s 2ms/step\n",
      "60/60 [==============================] - 0s 2ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "60/60 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para LENGUADO en clúster 6: 2800458522.777119, R2 Mensual: 0.4907266684704805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1498818/2783649223.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: LENGUADO, cluster: 5\n",
      "Epoch 1/50\n",
      "136/136 [==============================] - 5s 10ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "136/136 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "136/136 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "136/136 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "136/136 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "136/136 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "136/136 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "136/136 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "136/136 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "134/136 [============================>.] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "136/136 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LENGUADO en clúster 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para LENGUADO en clúster 5: 71589156.0, R2 Mensual: -0.6248789582548717\n",
      "Training model for species: LENGUADO, cluster: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1498818/2783649223.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "35/35 [==============================] - 4s 24ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "24/35 [===================>..........] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "35/35 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LENGUADO en clúster 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 566ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "MSE Mensual para LENGUADO en clúster 2: 3038049.0, R2 Mensual: nan\n",
      "Training model for species: LENGUADO, cluster: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1498818/2783649223.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n",
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/sklearn/metrics/_regression.py:1187: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5294/5294 [==============================] - 29s 5ms/step - loss: 0.0055 - val_loss: 0.0032\n",
      "Epoch 2/50\n",
      "5294/5294 [==============================] - 26s 5ms/step - loss: 0.0054 - val_loss: 0.0033\n",
      "Epoch 3/50\n",
      "5294/5294 [==============================] - 25s 5ms/step - loss: 0.0054 - val_loss: 0.0033\n",
      "Epoch 4/50\n",
      "5294/5294 [==============================] - 25s 5ms/step - loss: 0.0053 - val_loss: 0.0032\n",
      "Epoch 5/50\n",
      "5294/5294 [==============================] - 26s 5ms/step - loss: 0.0053 - val_loss: 0.0031\n",
      "Epoch 6/50\n",
      "5294/5294 [==============================] - 25s 5ms/step - loss: 0.0053 - val_loss: 0.0033\n",
      "Epoch 7/50\n",
      "5294/5294 [==============================] - 25s 5ms/step - loss: 0.0053 - val_loss: 0.0034\n",
      "Epoch 8/50\n",
      "5294/5294 [==============================] - 25s 5ms/step - loss: 0.0053 - val_loss: 0.0031\n",
      "Epoch 9/50\n",
      "5294/5294 [==============================] - 25s 5ms/step - loss: 0.0053 - val_loss: 0.0032\n",
      "Epoch 10/50\n",
      "5294/5294 [==============================] - 25s 5ms/step - loss: 0.0053 - val_loss: 0.0031\n",
      "Epoch 11/50\n",
      "5294/5294 [==============================] - 25s 5ms/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 12/50\n",
      "5294/5294 [==============================] - 25s 5ms/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 13/50\n",
      "5294/5294 [==============================] - 25s 5ms/step - loss: 0.0052 - val_loss: 0.0031\n",
      "Epoch 14/50\n",
      "5294/5294 [==============================] - 25s 5ms/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 15/50\n",
      "5294/5294 [==============================] - 25s 5ms/step - loss: 0.0052 - val_loss: 0.0032\n",
      "Epoch 16/50\n",
      "5294/5294 [==============================] - 25s 5ms/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 17/50\n",
      "5294/5294 [==============================] - 25s 5ms/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 18/50\n",
      "5294/5294 [==============================] - 25s 5ms/step - loss: 0.0052 - val_loss: 0.0031\n",
      "Epoch 19/50\n",
      "5294/5294 [==============================] - 25s 5ms/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 20/50\n",
      "5294/5294 [==============================] - 25s 5ms/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 21/50\n",
      "5294/5294 [==============================] - 25s 5ms/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 22/50\n",
      "5294/5294 [==============================] - 25s 5ms/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 23/50\n",
      "5294/5294 [==============================] - 25s 5ms/step - loss: 0.0052 - val_loss: 0.0031\n",
      "Epoch 24/50\n",
      "5294/5294 [==============================] - 25s 5ms/step - loss: 0.0051 - val_loss: 0.0030\n",
      "Epoch 25/50\n",
      "5294/5294 [==============================] - 25s 5ms/step - loss: 0.0052 - val_loss: 0.0032\n",
      "Epoch 26/50\n",
      "5294/5294 [==============================] - 26s 5ms/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 27/50\n",
      "5294/5294 [==============================] - 25s 5ms/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 28/50\n",
      "5294/5294 [==============================] - 25s 5ms/step - loss: 0.0051 - val_loss: 0.0030\n",
      "Epoch 29/50\n",
      "5294/5294 [==============================] - 25s 5ms/step - loss: 0.0051 - val_loss: 0.0030\n",
      "Epoch 30/50\n",
      "5294/5294 [==============================] - 26s 5ms/step - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 31/50\n",
      "5284/5294 [============================>.] - ETA: 0s - loss: 0.0051Restoring model weights from the end of the best epoch: 21.\n",
      "5294/5294 [==============================] - 25s 5ms/step - loss: 0.0051 - val_loss: 0.0030\n",
      "Epoch 31: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LENGUADO en clúster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 1s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "MSE Mensual para LENGUADO en clúster 1: 219719950.58004296, R2 Mensual: 0.8462538704017313\n",
      "Training model for species: LENGUADO, cluster: 4"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1498818/2783649223.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50\n",
      "27/27 [==============================] - 4s 30ms/step - loss: 0.0278 - val_loss: 0.2019\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0228 - val_loss: 0.2041\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0248 - val_loss: 0.1974\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0221 - val_loss: 0.1941\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0222 - val_loss: 0.2189\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0194 - val_loss: 0.1887\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0209 - val_loss: 0.2138\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0189 - val_loss: 0.1955\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0217 - val_loss: 0.2346\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0191 - val_loss: 0.1977\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0182 - val_loss: 0.1896\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0189 - val_loss: 0.2285\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0218 - val_loss: 0.1877\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0175 - val_loss: 0.2123\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0182 - val_loss: 0.2058\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0173 - val_loss: 0.1869\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0192 - val_loss: 0.1687\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0224 - val_loss: 0.1768\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0194 - val_loss: 0.2084\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0207 - val_loss: 0.1882\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0186 - val_loss: 0.1779\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0164 - val_loss: 0.1746\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0189 - val_loss: 0.1907\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0173 - val_loss: 0.1861\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0150 - val_loss: 0.1728\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0167 - val_loss: 0.1862\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0148 - val_loss: 0.1647\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0177 - val_loss: 0.1755\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.1606\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0163 - val_loss: 0.1635\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.1871\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0148 - val_loss: 0.1927\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0148 - val_loss: 0.1553\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0156 - val_loss: 0.2141\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0165 - val_loss: 0.1640\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.1652\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.1765\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.1697\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0187 - val_loss: 0.1541\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.1851\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.1707\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.1562\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.1479\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.1624\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0126 - val_loss: 0.1632\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0126 - val_loss: 0.1770\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0128 - val_loss: 0.1652\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0127 - val_loss: 0.1660\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0126 - val_loss: 0.1654\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0129 - val_loss: 0.1461\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LENGUADO en clúster 4\n",
      "No se tienen datos suficientes para LENGUADO en clúster 4 en los últimos seis meses de 2023\n",
      "Training model for species: CABRILLA, cluster: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "128/128 [==============================] - 6s 10ms/step - loss: 0.0078 - val_loss: 0.1054\n",
      "Epoch 2/50\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.0063 - val_loss: 0.1171\n",
      "Epoch 3/50\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.0056 - val_loss: 0.1162\n",
      "Epoch 4/50\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.0055 - val_loss: 0.0991\n",
      "Epoch 5/50\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.0055 - val_loss: 0.1122\n",
      "Epoch 6/50\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.0050 - val_loss: 0.1172\n",
      "Epoch 7/50\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.0048 - val_loss: 0.1024\n",
      "Epoch 8/50\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.0051 - val_loss: 0.1045\n",
      "Epoch 9/50\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.0050 - val_loss: 0.1153\n",
      "Epoch 10/50\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.1054\n",
      "Epoch 11/50\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.0048 - val_loss: 0.1027\n",
      "Epoch 12/50\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.1057\n",
      "Epoch 13/50\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.0047 - val_loss: 0.1018\n",
      "Epoch 14/50\n",
      "117/128 [==========================>...] - ETA: 0s - loss: 0.0040Restoring model weights from the end of the best epoch: 4.\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.1008\n",
      "Epoch 14: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CABRILLA en clúster 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 634ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "MSE Mensual para CABRILLA en clúster 7: 244392.2080951625, R2 Mensual: 0.5912174987280501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1498818/2783649223.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: CABRILLA, cluster: 3\n",
      "Epoch 1/50\n",
      "2036/2036 [==============================] - 14s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 2/50\n",
      "2036/2036 [==============================] - 10s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 3/50\n",
      "2036/2036 [==============================] - 10s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 4/50\n",
      "2036/2036 [==============================] - 10s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 5/50\n",
      "2036/2036 [==============================] - 10s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 6/50\n",
      "2036/2036 [==============================] - 10s 5ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 7/50\n",
      "2036/2036 [==============================] - 10s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 8/50\n",
      "2036/2036 [==============================] - 10s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 9/50\n",
      "2036/2036 [==============================] - 10s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 10/50\n",
      "2036/2036 [==============================] - 10s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 11/50\n",
      "2036/2036 [==============================] - 9s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 12/50\n",
      "2036/2036 [==============================] - 10s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 13/50\n",
      "2036/2036 [==============================] - 10s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 14/50\n",
      "2036/2036 [==============================] - 9s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 15/50\n",
      "2036/2036 [==============================] - 10s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 16/50\n",
      "2036/2036 [==============================] - 10s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 17/50\n",
      "2036/2036 [==============================] - 10s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 18/50\n",
      "2036/2036 [==============================] - 10s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 19/50\n",
      "2036/2036 [==============================] - 9s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 20/50\n",
      "2036/2036 [==============================] - 9s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 21/50\n",
      "2036/2036 [==============================] - 10s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 22/50\n",
      "2036/2036 [==============================] - 10s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 23/50\n",
      "2036/2036 [==============================] - 10s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 24/50\n",
      "2036/2036 [==============================] - 9s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 25/50\n",
      "2036/2036 [==============================] - 9s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 26/50\n",
      "2036/2036 [==============================] - 10s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 27/50\n",
      "2036/2036 [==============================] - ETA: 0s - loss: 0.0020Restoring model weights from the end of the best epoch: 17.\n",
      "2036/2036 [==============================] - 10s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 27: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CABRILLA en clúster 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 4ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para CABRILLA en clúster 3: 6691703.857411988, R2 Mensual: 0.6726784483262132\n",
      "Training model for species: CABRILLA, cluster: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1498818/2783649223.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3169/3169 [==============================] - 19s 5ms/step - loss: 3.4405e-04 - val_loss: 1.2068e-06\n",
      "Epoch 2/50\n",
      "3169/3169 [==============================] - 15s 5ms/step - loss: 3.2939e-04 - val_loss: 3.0282e-07\n",
      "Epoch 3/50\n",
      "3169/3169 [==============================] - 15s 5ms/step - loss: 3.2758e-04 - val_loss: 3.8562e-07\n",
      "Epoch 4/50\n",
      "3169/3169 [==============================] - 14s 5ms/step - loss: 3.2597e-04 - val_loss: 2.0163e-07\n",
      "Epoch 5/50\n",
      "3169/3169 [==============================] - 15s 5ms/step - loss: 3.2434e-04 - val_loss: 1.8611e-07\n",
      "Epoch 6/50\n",
      "3169/3169 [==============================] - 15s 5ms/step - loss: 3.2437e-04 - val_loss: 1.5501e-07\n",
      "Epoch 7/50\n",
      "3169/3169 [==============================] - 15s 5ms/step - loss: 3.2336e-04 - val_loss: 1.7967e-07\n",
      "Epoch 8/50\n",
      "3169/3169 [==============================] - 15s 5ms/step - loss: 3.2205e-04 - val_loss: 1.7797e-07\n",
      "Epoch 9/50\n",
      "3169/3169 [==============================] - 14s 5ms/step - loss: 3.2516e-04 - val_loss: 1.5112e-07\n",
      "Epoch 10/50\n",
      "3169/3169 [==============================] - 14s 5ms/step - loss: 3.2492e-04 - val_loss: 2.4567e-07\n",
      "Epoch 11/50\n",
      "3169/3169 [==============================] - 15s 5ms/step - loss: 3.2544e-04 - val_loss: 1.5252e-07\n",
      "Epoch 12/50\n",
      "3169/3169 [==============================] - 15s 5ms/step - loss: 3.2566e-04 - val_loss: 1.6038e-07\n",
      "Epoch 13/50\n",
      "3169/3169 [==============================] - 15s 5ms/step - loss: 3.2503e-04 - val_loss: 1.6049e-07\n",
      "Epoch 14/50\n",
      "3169/3169 [==============================] - 15s 5ms/step - loss: 3.2511e-04 - val_loss: 2.0526e-07\n",
      "Epoch 15/50\n",
      "3169/3169 [==============================] - 15s 5ms/step - loss: 3.2563e-04 - val_loss: 1.8184e-07\n",
      "Epoch 16/50\n",
      "3169/3169 [==============================] - 15s 5ms/step - loss: 3.2454e-04 - val_loss: 1.6411e-07\n",
      "Epoch 17/50\n",
      "3169/3169 [==============================] - 15s 5ms/step - loss: 3.2492e-04 - val_loss: 1.6152e-07\n",
      "Epoch 18/50\n",
      "3169/3169 [==============================] - 15s 5ms/step - loss: 3.2510e-04 - val_loss: 1.9069e-07\n",
      "Epoch 19/50\n",
      "3163/3169 [============================>.] - ETA: 0s - loss: 3.2499e-04Restoring model weights from the end of the best epoch: 9.\n",
      "3169/3169 [==============================] - 15s 5ms/step - loss: 3.2437e-04 - val_loss: 2.2151e-07\n",
      "Epoch 19: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CABRILLA en clúster 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 1s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "MSE Mensual para CABRILLA en clúster 6: 203178800.75966248, R2 Mensual: -2.2788742429403532\n",
      "Training model for species: CABRILLA, cluster: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1498818/2783649223.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "65/65 [==============================] - 5s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "65/65 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "65/65 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "65/65 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "65/65 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "65/65 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "65/65 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "65/65 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "62/65 [===========================>..] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "65/65 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CABRILLA en clúster 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 604ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "MSE Mensual para CABRILLA en clúster 5: 4159712.285714286, R2 Mensual: -0.49588755854338196\n",
      "Training model for species: CABRILLA, cluster: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1498818/2783649223.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 4s 167ms/step - loss: 0.1208 - val_loss: nan\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1034 - val_loss: nan\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0936 - val_loss: nan\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0850 - val_loss: nan\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0729 - val_loss: nan\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0688 - val_loss: nan\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0598 - val_loss: nan\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0522 - val_loss: nan\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0422 - val_loss: nan\n",
      "Epoch 10/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0059Restoring model weights from the end of the best epoch: 1.\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0382 - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CABRILLA en clúster 2\n",
      "No se tienen datos suficientes para CABRILLA en clúster 2 en los últimos seis meses de 2023\n",
      "Training model for species: CABRILLA, cluster: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3871/3871 [==============================] - 24s 5ms/step - loss: 0.0063 - val_loss: 0.0025\n",
      "Epoch 2/50\n",
      "3871/3871 [==============================] - 18s 5ms/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 3/50\n",
      "3871/3871 [==============================] - 18s 5ms/step - loss: 0.0057 - val_loss: 0.0024\n",
      "Epoch 4/50\n",
      "3871/3871 [==============================] - 18s 5ms/step - loss: 0.0056 - val_loss: 0.0025\n",
      "Epoch 5/50\n",
      "3871/3871 [==============================] - 18s 5ms/step - loss: 0.0055 - val_loss: 0.0033\n",
      "Epoch 6/50\n",
      "3871/3871 [==============================] - 18s 5ms/step - loss: 0.0054 - val_loss: 0.0025\n",
      "Epoch 7/50\n",
      "3871/3871 [==============================] - 18s 5ms/step - loss: 0.0055 - val_loss: 0.0029\n",
      "Epoch 8/50\n",
      "3871/3871 [==============================] - 18s 5ms/step - loss: 0.0055 - val_loss: 0.0024\n",
      "Epoch 9/50\n",
      "3871/3871 [==============================] - 18s 5ms/step - loss: 0.0054 - val_loss: 0.0024\n",
      "Epoch 10/50\n",
      "3871/3871 [==============================] - 19s 5ms/step - loss: 0.0054 - val_loss: 0.0024\n",
      "Epoch 11/50\n",
      "3871/3871 [==============================] - 18s 5ms/step - loss: 0.0054 - val_loss: 0.0024\n",
      "Epoch 12/50\n",
      "3871/3871 [==============================] - 18s 5ms/step - loss: 0.0054 - val_loss: 0.0025\n",
      "Epoch 13/50\n",
      "3871/3871 [==============================] - 18s 5ms/step - loss: 0.0054 - val_loss: 0.0026\n",
      "Epoch 14/50\n",
      "3871/3871 [==============================] - 19s 5ms/step - loss: 0.0054 - val_loss: 0.0031\n",
      "Epoch 15/50\n",
      "3871/3871 [==============================] - 18s 5ms/step - loss: 0.0053 - val_loss: 0.0024\n",
      "Epoch 16/50\n",
      "3871/3871 [==============================] - 18s 5ms/step - loss: 0.0054 - val_loss: 0.0025\n",
      "Epoch 17/50\n",
      "3871/3871 [==============================] - 18s 5ms/step - loss: 0.0054 - val_loss: 0.0024\n",
      "Epoch 18/50\n",
      "3871/3871 [==============================] - 19s 5ms/step - loss: 0.0053 - val_loss: 0.0024\n",
      "Epoch 19/50\n",
      "3871/3871 [==============================] - 19s 5ms/step - loss: 0.0052 - val_loss: 0.0026\n",
      "Epoch 20/50\n",
      "3863/3871 [============================>.] - ETA: 0s - loss: 0.0052Restoring model weights from the end of the best epoch: 10.\n",
      "3871/3871 [==============================] - 19s 5ms/step - loss: 0.0052 - val_loss: 0.0028\n",
      "Epoch 20: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CABRILLA en clúster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 1s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para CABRILLA en clúster 1: 21548641.145824917, R2 Mensual: 0.5322139170687092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1498818/2783649223.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    }
   ],
   "source": [
    "# Obtener listas de especies y clústeres únicos\n",
    "unique_species = data['species'].unique()\n",
    "unique_clusters = data['Cluster_Label'].unique()\n",
    "\n",
    "# Definir la especie y clúster desde donde retomar el proceso y detenerlo\n",
    "start_species = 'BERRUGATA'\n",
    "start_cluster = 7.0\n",
    "stop_species = 'CABRILLA'\n",
    "stop_cluster = 4.0\n",
    "\n",
    "# Inicializar banderas\n",
    "start_training = False\n",
    "stop_training = False\n",
    "\n",
    "for species_name in unique_species:\n",
    "    for cluster_label in unique_clusters:\n",
    "        # Activar la bandera cuando se alcance la especie y clúster deseados para iniciar\n",
    "        if species_name == start_species and cluster_label == start_cluster:\n",
    "            start_training = True\n",
    "        \n",
    "        # Detener el proceso cuando se alcance la especie y clúster deseados para detener\n",
    "        if species_name == stop_species and cluster_label == stop_cluster:\n",
    "            stop_training = True\n",
    "        \n",
    "        # Continuar solo si la bandera de inicio está activada y la de detener no lo está\n",
    "        if start_training and not stop_training:\n",
    "            # Filtrar los datos para obtener una especie y un clúster específico\n",
    "            filtered_data = data[(data['species'] == species_name) & (data['Cluster_Label'] == cluster_label)]\n",
    "            \n",
    "            if len(filtered_data) >= look_back:\n",
    "                filtered_data = filtered_data.sort_values('date')\n",
    "                try:\n",
    "                    print(f'Training model for species: {species_name}, cluster: {cluster_label}')\n",
    "                    model, scaler = train_and_save_moe_model(filtered_data, species_name, cluster_label, look_back)\n",
    "\n",
    "                    # Guardar los datos para las bandas de confianza\n",
    "                    test_data_2023 = filtered_data[(filtered_data['date'].dt.year == 2023) & (filtered_data['date'].dt.month >= 1)]\n",
    "                    if len(test_data_2023) >= look_back:\n",
    "                        predictions, lower_bound, upper_bound = predict_with_confidence_intervals(model, scaler, test_data_2023, look_back)\n",
    "                        real_values = test_data_2023['landed_w_kg'].values[look_back:]\n",
    "                        \n",
    "                        # Crear un DataFrame para los resultados\n",
    "                        results_df = pd.DataFrame({\n",
    "                            'date': test_data_2023['date'].values[look_back:],\n",
    "                            'real_values': real_values,\n",
    "                            'predictions': predictions,\n",
    "                            'lower_bound': lower_bound,\n",
    "                            'upper_bound': upper_bound\n",
    "                        })\n",
    "                        \n",
    "                        # Guardar los resultados\n",
    "                        results_directory = 'resultados_moe'\n",
    "                        os.makedirs(results_directory, exist_ok=True)\n",
    "                        results_path = os.path.join(results_directory, f'{species_name}_cluster_{cluster_label}_predictions.csv')\n",
    "                        results_df.to_csv(results_path, index=False)\n",
    "                        \n",
    "                        # Agrupar por mes y sumar los valores\n",
    "                        monthly_totals = results_df.set_index('date').resample('M').sum()\n",
    "                        \n",
    "                        # Calcular MSE y R2 para los totales mensuales\n",
    "                        mse = mean_squared_error(monthly_totals['real_values'], monthly_totals['predictions'])\n",
    "                        r2 = r2_score(monthly_totals['real_values'], monthly_totals['predictions'])\n",
    "                        print(f'MSE Mensual para {species_name} en clúster {cluster_label}: {mse}, R2 Mensual: {r2}')\n",
    "                        \n",
    "                        # Crear figura\n",
    "                        plt.figure(figsize=(10, 6))\n",
    "                        plt.plot(monthly_totals.index, monthly_totals['real_values'], color='blue', label='Real')\n",
    "                        plt.plot(monthly_totals.index, monthly_totals['predictions'], color='red', linestyle='--', label='Predicho')\n",
    "                        plt.fill_between(monthly_totals.index, monthly_totals['lower_bound'], monthly_totals['upper_bound'], color='gray', alpha=0.2, label='Intervalo de Confianza 95%')\n",
    "                        plt.title(f'Totales Mensuales de {species_name} en clúster {cluster_label} para los Últimos Seis Meses de 2023')\n",
    "                        plt.xlabel('Fecha')\n",
    "                        plt.ylabel('Peso Desembarcado (kg)')\n",
    "                        plt.legend()\n",
    "                        plot_path = os.path.join(results_directory, f'{species_name}_cluster_{cluster_label}_plot.png')\n",
    "                        plt.savefig(plot_path)\n",
    "                        plt.close()\n",
    "                    else:\n",
    "                        print(f'No se tienen datos suficientes para {species_name} en clúster {cluster_label} en los últimos seis meses de 2023')\n",
    "                except Exception as e:\n",
    "                    print(f'Error entrenando el modelo para especie: {species_name}, clúster: {cluster_label}. Error: {e}')\n",
    "        \n",
    "        # Salir del bucle si se alcanza el punto de detener\n",
    "        if stop_training:\n",
    "            break\n",
    "    if stop_training:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cedo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
