{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 05:55:12.175709: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-08 05:55:12.178845: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-08 05:55:12.219428: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-08 05:55:12.219457: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-08 05:55:12.220582: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-08 05:55:12.227404: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-08 05:55:12.228741: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-08 05:55:13.111632: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import LSTM, Dense, Dropout, Input, Conv1D, Flatten, concatenate\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Definir look_back\n",
    "look_back = 6  \n",
    "\n",
    "# Cargar el archivo y eliminar filas donde el clúster es NaN\n",
    "file_path = 'data/data.csv'   # Cambia esta ruta al archivo que has subido\n",
    "data = pd.read_csv(file_path)\n",
    "data = data.dropna(subset=['Cluster_Label'])\n",
    "\n",
    "# Convertir 'year' y 'month_no' a una sola columna de tipo fecha\n",
    "data['date'] = pd.to_datetime(data['year'].astype(str) + '-' + data['month_no'].astype(str))\n",
    "\n",
    "# Seleccionar las columnas necesarias para la serie temporal\n",
    "columns_to_keep = ['date', 'species', 'Cluster_Label', 'landed_w_kg',\n",
    "                   'mean_temp_30m','mean_temp_10m','thetao_sfc=6',\n",
    "                   'thetao_sfc=7.92956018447876','thetao_sfc=9.572997093200684','thetao_sfc=11.40499973297119',\n",
    "                   'thetao_sfc=13.46714019775391','thetao_sfc=15.8100700378418','thetao_sfc=18.49555969238281',\n",
    "                   'thetao_sfc=21.59881973266602','thetao_sfc=25.21141052246094','thetao_sfc=29.44473075866699']\n",
    "data = data[columns_to_keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para preparar los datos\n",
    "def prepare_data(group, look_back=6):\n",
    "    features = ['landed_w_kg','Cluster_Label', 'mean_temp_30m','mean_temp_10m','thetao_sfc=6',\n",
    "                   'thetao_sfc=7.92956018447876','thetao_sfc=9.572997093200684','thetao_sfc=11.40499973297119',\n",
    "                   'thetao_sfc=13.46714019775391','thetao_sfc=15.8100700378418','thetao_sfc=18.49555969238281',\n",
    "                   'thetao_sfc=21.59881973266602','thetao_sfc=25.21141052246094','thetao_sfc=29.44473075866699']\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    group_scaled = scaler.fit_transform(group[features])\n",
    "    \n",
    "    X, y = [], []\n",
    "    for i in range(len(group_scaled) - look_back):\n",
    "        a = group_scaled[i:(i + look_back)]\n",
    "        X.append(a)\n",
    "        y.append(group_scaled[i + look_back, 0])  # La primera columna es 'landed_w_kg'\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2]))\n",
    "    return X, y, scaler\n",
    "\n",
    "# Crear el modelo LSTM\n",
    "def create_lstm_model(input_shape):\n",
    "    lstm_input = Input(shape=input_shape)\n",
    "    x = LSTM(50, return_sequences=True)(lstm_input)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = LSTM(25, activation='relu', return_sequences=True)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = LSTM(12, activation='linear')(x)\n",
    "    lstm_output = Dense(1, activation='linear')(x)\n",
    "    return Model(inputs=lstm_input, outputs=lstm_output)\n",
    "\n",
    "# Crear el modelo DNN\n",
    "def create_dnn_model(input_shape):\n",
    "    dnn_input = Input(shape=(input_shape[0], input_shape[1]))\n",
    "    x = Flatten()(dnn_input)\n",
    "    x = Dense(10, activation='relu')(x)\n",
    "    x = Dense(5, activation='relu')(x)\n",
    "    dnn_output = Dense(1, activation='linear')(x)\n",
    "    return Model(inputs=dnn_input, outputs=dnn_output)\n",
    "\n",
    "# Crear el modelo CNN\n",
    "def create_cnn_model(input_shape):\n",
    "    cnn_input = Input(shape=input_shape)\n",
    "    x = Conv1D(32, kernel_size=3, activation='relu')(cnn_input)\n",
    "    x = Flatten()(x)\n",
    "    cnn_output = Dense(1, activation='linear')(x)\n",
    "    return Model(inputs=cnn_input, outputs=cnn_output)\n",
    "\n",
    "# Crear el modelo Mixture of Experts (MoE)\n",
    "def create_moe_model(input_shape):\n",
    "    # Definir los expertos\n",
    "    lstm_model = create_lstm_model(input_shape)\n",
    "    dnn_model = create_dnn_model(input_shape)\n",
    "    cnn_model = create_cnn_model(input_shape)\n",
    "    \n",
    "    # Definir el gating network\n",
    "    moe_input = Input(shape=input_shape)\n",
    "    x = Flatten()(moe_input)\n",
    "    x = Dense(10, activation='relu')(x)\n",
    "    gate_output = Dense(3, activation='softmax')(x)  # Tres expertos\n",
    "\n",
    "    # Obtener las salidas de los expertos\n",
    "    lstm_output = lstm_model(moe_input)\n",
    "    dnn_output = dnn_model(moe_input)\n",
    "    cnn_output = cnn_model(moe_input)\n",
    "    \n",
    "    # Combinar las salidas usando el gating network\n",
    "    output = concatenate([lstm_output * gate_output[:, 0:1],\n",
    "                          dnn_output * gate_output[:, 1:2],\n",
    "                          cnn_output * gate_output[:, 2:3]], axis=1)\n",
    "    output = Dense(1, activation='linear')(output)\n",
    "    \n",
    "    model = Model(inputs=moe_input, outputs=output)\n",
    "    model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar y guardar el modelo MoE\n",
    "def train_and_save_moe_model(data, species_name, cluster_label, look_back=look_back, epochs=50, batch_size=1):\n",
    "    X, y, scaler = prepare_data(data, look_back)\n",
    "    model = create_moe_model((look_back, X.shape[2]))\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "    history = model.fit(X, y, validation_split=0.2, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[early_stopping])\n",
    "    \n",
    "    # Guardar el modelo y el scaler\n",
    "    model_directory = 'modelos_moe'\n",
    "    os.makedirs(model_directory, exist_ok=True)\n",
    "    model_path = os.path.join(model_directory, f'{species_name}_cluster_{cluster_label}_moe_model.h5')\n",
    "    scaler_path = os.path.join(model_directory, f'{species_name}_cluster_{cluster_label}_moe_scaler.pkl')\n",
    "    model.save(model_path)\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    \n",
    "    # Guardar los valores de monitoreo del entrenamiento\n",
    "    train_moe_directory = 'train_moe'\n",
    "    os.makedirs(train_moe_directory, exist_ok=True)\n",
    "    history_path = os.path.join(train_moe_directory, f'{species_name}_cluster_{cluster_label}_training_history.csv')\n",
    "    pd.DataFrame(history.history).to_csv(history_path, index=False)\n",
    "    \n",
    "    print(f'Modelo MoE, scaler y datos de entrenamiento guardados para {species_name} en clúster {cluster_label}')\n",
    "    return model, scaler\n",
    "\n",
    "# Función para hacer predicciones con bandas de confianza usando bootstrap\n",
    "def predict_with_confidence_intervals(model, scaler, data, look_back=6, n_bootstrap=100, alpha=0.01):\n",
    "    features = ['landed_w_kg','Cluster_Label','mean_temp_30m','mean_temp_10m','thetao_sfc=6',\n",
    "                   'thetao_sfc=7.92956018447876','thetao_sfc=9.572997093200684','thetao_sfc=11.40499973297119',\n",
    "                   'thetao_sfc=13.46714019775391','thetao_sfc=15.8100700378418','thetao_sfc=18.49555969238281',\n",
    "                   'thetao_sfc=21.59881973266602','thetao_sfc=25.21141052246094','thetao_sfc=29.44473075866699']\n",
    "    group_scaled = scaler.transform(data[features])\n",
    "\n",
    "    X = []\n",
    "    for i in range(len(group_scaled) - look_back):\n",
    "        a = group_scaled[i:(i + look_back)]\n",
    "        X.append(a)\n",
    "    X = np.array(X)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2]))\n",
    "    \n",
    "    predictions = model.predict(X)\n",
    "    predictions = scaler.inverse_transform(np.hstack((predictions, X[:, -1, 1:])))[:, 0]\n",
    "    \n",
    "    # Bootstrap para bandas de confianza\n",
    "    bootstrap_predictions = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        indices = np.random.choice(range(len(X)), len(X), replace=True)\n",
    "        X_sample = X[indices]\n",
    "        pred_sample = model.predict(X_sample)\n",
    "        pred_sample = scaler.inverse_transform(np.hstack((pred_sample, X_sample[:, -1, 1:])))[:, 0]\n",
    "        bootstrap_predictions.append(pred_sample)\n",
    "    \n",
    "    bootstrap_predictions = np.array(bootstrap_predictions)\n",
    "    lower_bound = np.percentile(bootstrap_predictions, 100 * alpha / 2, axis=0)\n",
    "    upper_bound = np.percentile(bootstrap_predictions, 100 * (1 - alpha / 2), axis=0)\n",
    "    \n",
    "    return predictions, lower_bound, upper_bound\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la ruta del directorio donde se almacenan los modelos\n",
    "models_directory = 'modelos_moe'  # Cambia esto a la ruta real de tu directorio de modelos\n",
    "\n",
    "# Filtrar las especies y clústeres únicos de la tabla de datos\n",
    "unique_species = data['species'].unique()\n",
    "unique_clusters = data['Cluster_Label'].unique()\n",
    "\n",
    "# Crear una lista de los modelos esperados solo para combinaciones que tienen datos suficientes\n",
    "expected_models = []\n",
    "for species in unique_species:\n",
    "    for cluster in unique_clusters:\n",
    "        # Filtrar los datos para la combinación específica de especie y clúster\n",
    "        filtered_data = data[(data['species'] == species) & (data['Cluster_Label'] == cluster)]\n",
    "        # Verificar si hay suficientes datos para entrenar\n",
    "        if len(filtered_data) > 10:\n",
    "            expected_models.append(f'{species}_cluster_{cluster}_moe_model.h5')\n",
    "\n",
    "# Obtener la lista de archivos existentes en el directorio de modelos\n",
    "existing_models = os.listdir(models_directory)\n",
    "\n",
    "# Identificar los modelos faltantes\n",
    "missing_models = [model for model in expected_models if model not in existing_models]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MOJARRA_cluster_4_moe_model.h5',\n",
       " 'CORVINA_cluster_2_moe_model.h5',\n",
       " 'PARGO_cluster_2_moe_model.h5',\n",
       " 'SIERRA_cluster_2_moe_model.h5',\n",
       " 'JUREL_cluster_2_moe_model.h5',\n",
       " 'GUACHINANGO_cluster_2_moe_model.h5',\n",
       " 'GUACHINANGO_cluster_4_moe_model.h5',\n",
       " 'BAQUETA_cluster_2_moe_model.h5',\n",
       " 'LENGUADO_cluster_2_moe_model.h5',\n",
       " 'CABRILLA_cluster_2_moe_model.h5',\n",
       " 'LISA_cluster_2_moe_model.h5',\n",
       " 'ALMEJA_cluster_2_moe_model.h5',\n",
       " 'CAZON_cluster_4_moe_model.h5',\n",
       " 'SARDINA_cluster_4_moe_model.h5',\n",
       " 'RAYA Y SIMILARES_cluster_2_moe_model.h5',\n",
       " 'PULPO_cluster_2_moe_model.h5',\n",
       " 'CAMARON_cluster_2_moe_model.h5']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: MOJARRA, cluster: 4\n",
      "Epoch 1/50\n",
      "38/38 [==============================] - 5s 32ms/step - loss: 0.0557 - val_loss: 0.1102\n",
      "Epoch 2/50\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0397 - val_loss: 0.1017\n",
      "Epoch 3/50\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0399 - val_loss: 0.1677\n",
      "Epoch 4/50\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0299 - val_loss: 0.1350\n",
      "Epoch 5/50\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0251 - val_loss: 0.1247\n",
      "Epoch 6/50\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0269 - val_loss: 0.1345\n",
      "Epoch 7/50\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0211 - val_loss: 0.1832\n",
      "Epoch 8/50\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0219 - val_loss: 0.1646\n",
      "Epoch 9/50\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0211 - val_loss: 0.1371\n",
      "Epoch 10/50\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0178 - val_loss: 0.1328\n",
      "Epoch 11/50\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0153 - val_loss: 0.1469\n",
      "Epoch 12/50\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0164  Restoring model weights from the end of the best epoch: 2.\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0159 - val_loss: 0.1378\n",
      "Epoch 12: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para MOJARRA en clúster 4\n",
      "No se tienen datos suficientes para MOJARRA en clúster 4 en el último año\n",
      "Training model for species: CORVINA, cluster: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 5s 87ms/step - loss: 0.4117 - val_loss: 0.0165\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2640 - val_loss: 0.0059\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1755 - val_loss: 0.0374\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1613 - val_loss: 0.0776\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1444 - val_loss: 0.0722\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1387 - val_loss: 0.0624\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1171 - val_loss: 0.0552\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1173 - val_loss: 0.0487\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1110 - val_loss: 0.0537\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1023 - val_loss: 0.0594\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1049 - val_loss: 0.0827\n",
      "Epoch 12/50\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0717Restoring model weights from the end of the best epoch: 2.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0988 - val_loss: 0.0576\n",
      "Epoch 12: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CORVINA en clúster 2\n",
      "No se tienen datos suficientes para CORVINA en clúster 2 en el último año\n",
      "Training model for species: PARGO, cluster: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "18/18 [==============================] - 5s 49ms/step - loss: 0.0610 - val_loss: 0.0272\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0478 - val_loss: 0.0249\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0373 - val_loss: 0.0268\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0363 - val_loss: 0.0272\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0327 - val_loss: 0.0246\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0326 - val_loss: 0.0272\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0273 - val_loss: 0.0304\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0250 - val_loss: 0.0279\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0223 - val_loss: 0.0302\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0240 - val_loss: 0.0284\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0229 - val_loss: 0.0319\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0184 - val_loss: 0.0284\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0178 - val_loss: 0.0305\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0178 - val_loss: 0.0314\n",
      "Epoch 15/50\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.0112Restoring model weights from the end of the best epoch: 5.\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0314\n",
      "Epoch 15: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para PARGO en clúster 2\n",
      "Error entrenando el modelo para especie: PARGO, clúster: 2. Error: tuple index out of range\n",
      "Training model for species: JUREL, cluster: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 5s 87ms/step - loss: 0.1322 - val_loss: 0.5994\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1029 - val_loss: 0.5088\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0850 - val_loss: 0.4671\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0778 - val_loss: 0.4776\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0737 - val_loss: 0.4598\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0689 - val_loss: 0.4646\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0638 - val_loss: 0.4530\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0628 - val_loss: 0.4318\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0542 - val_loss: 0.4567\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0508 - val_loss: 0.4662\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0461 - val_loss: 0.4855\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0439 - val_loss: 0.5025\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0377 - val_loss: 0.4634\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0382 - val_loss: 0.4660\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0310 - val_loss: 0.5033\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0301 - val_loss: 0.5200\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0296 - val_loss: 0.4741\n",
      "Epoch 18/50\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1381Restoring model weights from the end of the best epoch: 8.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.5021\n",
      "Epoch 18: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para JUREL en clúster 2\n",
      "No se tienen datos suficientes para JUREL en clúster 2 en el último año\n",
      "Training model for species: GUACHINANGO, cluster: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 5s 87ms/step - loss: 0.0700 - val_loss: 0.0173\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0631 - val_loss: 0.0143\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0630 - val_loss: 0.0184\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0545 - val_loss: 0.0070\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0532 - val_loss: 0.0211\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0503 - val_loss: 0.0133\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0474 - val_loss: 0.0097\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0466 - val_loss: 0.0156\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0434 - val_loss: 0.0117\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0437 - val_loss: 0.0068\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0413 - val_loss: 0.0189\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0513 - val_loss: 0.0167\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0413 - val_loss: 0.0179\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0391 - val_loss: 0.0097\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0451 - val_loss: 0.0198\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0362 - val_loss: 0.0178\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0318 - val_loss: 0.0215\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0310 - val_loss: 0.0235\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0290 - val_loss: 0.0206\n",
      "Epoch 20/50\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0102Restoring model weights from the end of the best epoch: 10.\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0315 - val_loss: 0.0357\n",
      "Epoch 20: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para GUACHINANGO en clúster 2\n",
      "No se tienen datos suficientes para GUACHINANGO en clúster 2 en el último año\n",
      "Training model for species: GUACHINANGO, cluster: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "37/37 [==============================] - 5s 26ms/step - loss: 0.0443 - val_loss: 0.0033\n",
      "Epoch 2/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0041 - val_loss: 0.0065\n",
      "Epoch 3/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 4/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 5/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 6/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 7/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 8/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 9/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 10/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 11/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 12/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 13/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 14/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 15/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 16/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 17/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 18/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 19/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 20/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 21/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 22/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 23/50\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 0.0020Restoring model weights from the end of the best epoch: 13.\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 23: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para GUACHINANGO en clúster 4\n",
      "No se tienen datos suficientes para GUACHINANGO en clúster 4 en el último año\n",
      "Training model for species: BAQUETA, cluster: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 5s 70ms/step - loss: 0.0739 - val_loss: 0.0676\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0555 - val_loss: 0.0723\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0387 - val_loss: 0.0790\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0304 - val_loss: 0.0676\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0783\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0731\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0837\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0864\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0815\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0950\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0068 - val_loss: 0.0818\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0063 - val_loss: 0.0996\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0932\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0046Restoring model weights from the end of the best epoch: 4.\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0992\n",
      "Epoch 14: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para BAQUETA en clúster 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 712ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "MSE Mensual para BAQUETA en clúster 2: 61104.85046960527, R2 Mensual: 0.8105094606417295\n",
      "Training model for species: LENGUADO, cluster: 2\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 5s 37ms/step - loss: 0.0902 - val_loss: 0.0722\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0772 - val_loss: 0.0786\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0757 - val_loss: 0.0653\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0684 - val_loss: 0.0607\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0669 - val_loss: 0.0662\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0628 - val_loss: 0.0573\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0625 - val_loss: 0.0606\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0607 - val_loss: 0.0584\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0599 - val_loss: 0.0569\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0626 - val_loss: 0.0723\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0581 - val_loss: 0.0563\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0556 - val_loss: 0.0553\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0549 - val_loss: 0.0575\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0554 - val_loss: 0.0609\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0518 - val_loss: 0.0577\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0517 - val_loss: 0.0654\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0521 - val_loss: 0.0670\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0488 - val_loss: 0.0535\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0524 - val_loss: 0.0670\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0506 - val_loss: 0.0584\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0516 - val_loss: 0.0625\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0442 - val_loss: 0.0572\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0473 - val_loss: 0.0618\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0435 - val_loss: 0.0663\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0427 - val_loss: 0.0597\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0442 - val_loss: 0.0714\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0434 - val_loss: 0.0578\n",
      "Epoch 28/50\n",
      "13/24 [===============>..............] - ETA: 0s - loss: 0.0223Restoring model weights from the end of the best epoch: 18.\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0386 - val_loss: 0.0620\n",
      "Epoch 28: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LENGUADO en clúster 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 707ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "MSE Mensual para LENGUADO en clúster 2: 137248.62019799787, R2 Mensual: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/sklearn/metrics/_regression.py:1187: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: LISA, cluster: 2\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 5s 181ms/step - loss: 0.4133 - val_loss: 0.0580\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3445 - val_loss: 0.0174\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2612 - val_loss: 0.0055\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1933 - val_loss: 0.0109\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2067 - val_loss: 0.0332\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1617 - val_loss: 0.0350\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1379 - val_loss: 0.0554\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1511 - val_loss: 0.0726\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1256 - val_loss: 0.0883\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0987 - val_loss: 0.1012\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0895 - val_loss: 0.1193\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0620 - val_loss: 0.1564\n",
      "Epoch 13/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0705Restoring model weights from the end of the best epoch: 3.\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0585 - val_loss: 0.2131\n",
      "Epoch 13: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para LISA en clúster 2\n",
      "No se tienen datos suficientes para LISA en clúster 2 en el último año\n",
      "Training model for species: ALMEJA, cluster: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 5s 70ms/step - loss: 0.0835 - val_loss: 0.0022\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0765 - val_loss: 0.0043\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0725 - val_loss: 0.0064\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0678 - val_loss: 0.0044\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0625 - val_loss: 0.0060\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0574 - val_loss: 0.0094\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0570 - val_loss: 0.0129\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0552 - val_loss: 0.0075\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0488 - val_loss: 0.0113\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0462 - val_loss: 0.0122\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0468Restoring model weights from the end of the best epoch: 1.\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0468 - val_loss: 0.0173\n",
      "Epoch 11: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para ALMEJA en clúster 2\n",
      "No se tienen datos suficientes para ALMEJA en clúster 2 en el último año\n",
      "Training model for species: CAZON, cluster: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 5s 68ms/step - loss: 0.0064 - val_loss: 0.3357\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.3294\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.3243\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.3216\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.3196\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.3165\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.3177\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.3214\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.3184\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.3193\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.3175\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.3190\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.3192\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.3160\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.3209\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.3170\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.3193\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.3167\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.3211\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.3161\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.3183\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.3139\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.3165\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 0.3224\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.3138\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.3161\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.3121\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.3135\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.3141\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.3139\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.3165\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.3138\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.3118\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.3145\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.3197\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.3098\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.3079\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.3115\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.3095\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.3075\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.3126\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.3084\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.3117\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.3117\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.3128\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.3097\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.3086\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.3099\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.3132\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0016    Restoring model weights from the end of the best epoch: 40.\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.3123\n",
      "Epoch 50: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CAZON en clúster 4\n",
      "No se tienen datos suficientes para CAZON en clúster 4 en el último año\n",
      "Training model for species: SARDINA, cluster: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "28/28 [==============================] - 5s 32ms/step - loss: 0.0578 - val_loss: 0.0412\n",
      "Epoch 2/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0470 - val_loss: 0.0200\n",
      "Epoch 3/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0462 - val_loss: 0.0207\n",
      "Epoch 4/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0399 - val_loss: 0.0197\n",
      "Epoch 5/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0367 - val_loss: 0.0221\n",
      "Epoch 6/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0383 - val_loss: 0.0149\n",
      "Epoch 7/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0354 - val_loss: 0.0238\n",
      "Epoch 8/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0280 - val_loss: 0.0130\n",
      "Epoch 9/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0273 - val_loss: 0.0078\n",
      "Epoch 10/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0258 - val_loss: 0.0053\n",
      "Epoch 11/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0237 - val_loss: 0.0208\n",
      "Epoch 12/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0223 - val_loss: 0.0066\n",
      "Epoch 13/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0230 - val_loss: 0.0136\n",
      "Epoch 14/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0213 - val_loss: 0.0092\n",
      "Epoch 15/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0211 - val_loss: 0.0144\n",
      "Epoch 16/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0220 - val_loss: 0.0100\n",
      "Epoch 17/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0180 - val_loss: 0.0057\n",
      "Epoch 18/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0156 - val_loss: 0.0030\n",
      "Epoch 19/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0153 - val_loss: 0.0078\n",
      "Epoch 20/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0162 - val_loss: 0.0075\n",
      "Epoch 21/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0015\n",
      "Epoch 22/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0150 - val_loss: 0.0298\n",
      "Epoch 23/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0197 - val_loss: 0.0040\n",
      "Epoch 24/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0152 - val_loss: 0.0084\n",
      "Epoch 25/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0127 - val_loss: 0.0038\n",
      "Epoch 26/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0078\n",
      "Epoch 27/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.0070\n",
      "Epoch 28/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0117 - val_loss: 0.0090\n",
      "Epoch 29/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0117 - val_loss: 0.0105\n",
      "Epoch 30/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0113 - val_loss: 0.0085\n",
      "Epoch 31/50\n",
      "23/28 [=======================>......] - ETA: 0s - loss: 0.0126Restoring model weights from the end of the best epoch: 21.\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0124 - val_loss: 0.0102\n",
      "Epoch 31: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para SARDINA en clúster 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 688ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "MSE Mensual para SARDINA en clúster 4: 1650952.1901642508, R2 Mensual: 0.8287546153301288\n",
      "Training model for species: CAMARON, cluster: 2\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 6s 192ms/step - loss: 0.1757 - val_loss: 0.0114\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1472 - val_loss: 0.0046\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1275 - val_loss: 0.0024\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1164 - val_loss: 0.0040\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1012 - val_loss: 0.0100\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0985 - val_loss: 0.0242\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0829 - val_loss: 0.0328\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0864 - val_loss: 0.0580\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0845 - val_loss: 0.0789\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0732 - val_loss: 0.0693\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0729 - val_loss: 0.0468\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0756 - val_loss: 0.0425\n",
      "Epoch 13/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0752Restoring model weights from the end of the best epoch: 3.\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0686 - val_loss: 0.0317\n",
      "Epoch 13: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CAMARON en clúster 2\n",
      "No se tienen datos suficientes para CAMARON en clúster 2 en el último año\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Crear los modelos faltantes si hay suficientes datos\n",
    "for model_name in missing_models:\n",
    "    species_name, cluster_label = model_name.replace('_moe_model.h5', '').split('_cluster_')\n",
    "    cluster_label = int(cluster_label)\n",
    "    \n",
    "    # Filtrar los datos para la combinación específica de especie y clúster\n",
    "    filtered_data = data[(data['species'] == species_name) & (data['Cluster_Label'] == cluster_label)].dropna()\n",
    "    \n",
    "    if len(filtered_data) > 12:\n",
    "\n",
    "        if len(filtered_data) >= look_back:\n",
    "            filtered_data = filtered_data.sort_values('date')\n",
    "            try:\n",
    "                print(f'Training model for species: {species_name}, cluster: {cluster_label}')\n",
    "                model, scaler = train_and_save_moe_model(filtered_data, species_name, cluster_label, look_back)\n",
    "\n",
    "                # Verificar cuál es el último año de la serie de tiempo\n",
    "                last_year = filtered_data['date'].dt.year.max()\n",
    "                \n",
    "                # Filtrar los datos del último año\n",
    "                test_data_last_year = filtered_data[filtered_data['date'].dt.year == last_year]\n",
    "                if len(test_data_last_year) >= look_back:\n",
    "                    predictions, lower_bound, upper_bound = predict_with_confidence_intervals(model, scaler, test_data_last_year, look_back)\n",
    "                    real_values = test_data_last_year['landed_w_kg'].values[look_back:]\n",
    "                    \n",
    "                    # Crear un DataFrame para los resultados\n",
    "                    results_df = pd.DataFrame({\n",
    "                        'date': test_data_last_year['date'].values[look_back:],\n",
    "                        'real_values': real_values,\n",
    "                        'predictions': predictions,\n",
    "                        'lower_bound': lower_bound,\n",
    "                        'upper_bound': upper_bound\n",
    "                    })\n",
    "                    \n",
    "                    # Guardar los resultados\n",
    "                    results_directory = 'resultados_moe'\n",
    "                    os.makedirs(results_directory, exist_ok=True)\n",
    "                    results_path = os.path.join(results_directory, f'{species_name}_cluster_{str(cluster_label)}_predictions.csv')\n",
    "                    results_df.to_csv(results_path, index=False)\n",
    "                    \n",
    "                    # Agrupar por mes y sumar los valores\n",
    "                    monthly_totals = results_df.set_index('date').resample('ME').sum()\n",
    "                    \n",
    "                    # Calcular MSE y R2 para los totales mensuales\n",
    "                    mse = mean_squared_error(monthly_totals['real_values'], monthly_totals['predictions'])\n",
    "                    r2 = r2_score(monthly_totals['real_values'], monthly_totals['predictions'])\n",
    "                    print(f'MSE Mensual para {species_name} en clúster {cluster_label}: {mse}, R2 Mensual: {r2}')\n",
    "                    \n",
    "                    # Crear figura\n",
    "                    plt.figure(figsize=(10, 6))\n",
    "                    plt.plot(monthly_totals.index, monthly_totals['real_values'], color='blue', label='Real')\n",
    "                    plt.plot(monthly_totals.index, monthly_totals['predictions'], color='red', linestyle='--', label='Predicho')\n",
    "                    plt.fill_between(monthly_totals.index, monthly_totals['lower_bound'], monthly_totals['upper_bound'], color='gray', alpha=0.2, label='Intervalo de Confianza 95%')\n",
    "                    plt.title(f'Totales Mensuales de {species_name} en clúster {cluster_label} para el Último Año')\n",
    "                    plt.xlabel('Fecha')\n",
    "                    plt.ylabel('Peso Desembarcado (kg)')\n",
    "                    plt.legend()\n",
    "                    plot_path = os.path.join(results_directory, f'{species_name}_cluster_{cluster_label}_plot.png')\n",
    "                    plt.savefig(plot_path)\n",
    "                    plt.close()\n",
    "                else:\n",
    "                    print(f'No se tienen datos suficientes para {species_name} en clúster {cluster_label} en el último año')\n",
    "            except Exception as e:\n",
    "                print(f'Error entrenando el modelo para especie: {species_name}, clúster: {cluster_label}. Error: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cedo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
