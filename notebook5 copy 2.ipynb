{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-19 18:17:40.739464: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-19 18:17:40.741837: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-19 18:17:40.774941: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-19 18:17:40.774960: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-19 18:17:40.775868: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-19 18:17:40.781404: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-19 18:17:40.782221: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-19 18:17:41.515615: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import LSTM, Dense, Dropout, Input, Conv1D, Flatten, concatenate\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Definir look_back\n",
    "look_back = 6  \n",
    "\n",
    "# Cargar el archivo y eliminar filas donde el clúster es NaN\n",
    "file_path = 'data/data.csv'   # Cambia esta ruta al archivo que has subido\n",
    "data = pd.read_csv(file_path)\n",
    "data = data.dropna(subset=['Cluster_Label'])\n",
    "\n",
    "# Convertir 'year' y 'month_no' a una sola columna de tipo fecha\n",
    "data['date'] = pd.to_datetime(data['year'].astype(str) + '-' + data['month_no'].astype(str))\n",
    "\n",
    "# Seleccionar las columnas necesarias para la serie temporal\n",
    "columns_to_keep = ['date', 'species', 'Cluster_Label', 'landed_w_kg',\n",
    "                   'mean_temp_30m','mean_temp_10m','thetao_sfc=6',\n",
    "                   'thetao_sfc=7.92956018447876','thetao_sfc=9.572997093200684','thetao_sfc=11.40499973297119',\n",
    "                   'thetao_sfc=13.46714019775391','thetao_sfc=15.8100700378418','thetao_sfc=18.49555969238281',\n",
    "                   'thetao_sfc=21.59881973266602','thetao_sfc=25.21141052246094','thetao_sfc=29.44473075866699']\n",
    "data = data[columns_to_keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para preparar los datos\n",
    "def prepare_data(group, look_back=6):\n",
    "    features = ['landed_w_kg','Cluster_Label', 'mean_temp_30m','mean_temp_10m','thetao_sfc=6',\n",
    "                   'thetao_sfc=7.92956018447876','thetao_sfc=9.572997093200684','thetao_sfc=11.40499973297119',\n",
    "                   'thetao_sfc=13.46714019775391','thetao_sfc=15.8100700378418','thetao_sfc=18.49555969238281',\n",
    "                   'thetao_sfc=21.59881973266602','thetao_sfc=25.21141052246094','thetao_sfc=29.44473075866699']\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    group_scaled = scaler.fit_transform(group[features])\n",
    "    \n",
    "    X, y = [], []\n",
    "    for i in range(len(group_scaled) - look_back):\n",
    "        a = group_scaled[i:(i + look_back)]\n",
    "        X.append(a)\n",
    "        y.append(group_scaled[i + look_back, 0])  # La primera columna es 'landed_w_kg'\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2]))\n",
    "    return X, y, scaler\n",
    "\n",
    "# Crear el modelo LSTM\n",
    "def create_lstm_model(input_shape):\n",
    "    lstm_input = Input(shape=input_shape)\n",
    "    x = LSTM(50, return_sequences=True)(lstm_input)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = LSTM(25, activation='relu', return_sequences=True)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = LSTM(12, activation='linear')(x)\n",
    "    lstm_output = Dense(1, activation='linear')(x)\n",
    "    return Model(inputs=lstm_input, outputs=lstm_output)\n",
    "\n",
    "# Crear el modelo DNN\n",
    "def create_dnn_model(input_shape):\n",
    "    dnn_input = Input(shape=(input_shape[0], input_shape[1]))\n",
    "    x = Flatten()(dnn_input)\n",
    "    x = Dense(10, activation='relu')(x)\n",
    "    x = Dense(5, activation='relu')(x)\n",
    "    dnn_output = Dense(1, activation='linear')(x)\n",
    "    return Model(inputs=dnn_input, outputs=dnn_output)\n",
    "\n",
    "# Crear el modelo CNN\n",
    "def create_cnn_model(input_shape):\n",
    "    cnn_input = Input(shape=input_shape)\n",
    "    x = Conv1D(32, kernel_size=3, activation='relu')(cnn_input)\n",
    "    x = Flatten()(x)\n",
    "    cnn_output = Dense(1, activation='linear')(x)\n",
    "    return Model(inputs=cnn_input, outputs=cnn_output)\n",
    "\n",
    "# Crear el modelo Mixture of Experts (MoE)\n",
    "def create_moe_model(input_shape):\n",
    "    # Definir los expertos\n",
    "    lstm_model = create_lstm_model(input_shape)\n",
    "    dnn_model = create_dnn_model(input_shape)\n",
    "    cnn_model = create_cnn_model(input_shape)\n",
    "    \n",
    "    # Definir el gating network\n",
    "    moe_input = Input(shape=input_shape)\n",
    "    x = Flatten()(moe_input)\n",
    "    x = Dense(10, activation='relu')(x)\n",
    "    gate_output = Dense(3, activation='softmax')(x)  # Tres expertos\n",
    "\n",
    "    # Obtener las salidas de los expertos\n",
    "    lstm_output = lstm_model(moe_input)\n",
    "    dnn_output = dnn_model(moe_input)\n",
    "    cnn_output = cnn_model(moe_input)\n",
    "    \n",
    "    # Combinar las salidas usando el gating network\n",
    "    output = concatenate([lstm_output * gate_output[:, 0:1],\n",
    "                          dnn_output * gate_output[:, 1:2],\n",
    "                          cnn_output * gate_output[:, 2:3]], axis=1)\n",
    "    output = Dense(1, activation='linear')(output)\n",
    "    \n",
    "    model = Model(inputs=moe_input, outputs=output)\n",
    "    model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar y guardar el modelo MoE\n",
    "def train_and_save_moe_model(data, species_name, cluster_label, look_back=look_back, epochs=50, batch_size=1):\n",
    "    X, y, scaler = prepare_data(data, look_back)\n",
    "    model = create_moe_model((look_back, X.shape[2]))\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "    history = model.fit(X, y, validation_split=0.2, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[early_stopping])\n",
    "    \n",
    "    # Guardar el modelo y el scaler\n",
    "    model_directory = 'modelos_moe'\n",
    "    os.makedirs(model_directory, exist_ok=True)\n",
    "    model_path = os.path.join(model_directory, f'{species_name}_cluster_{cluster_label}_moe_model.h5')\n",
    "    scaler_path = os.path.join(model_directory, f'{species_name}_cluster_{cluster_label}_moe_scaler.pkl')\n",
    "    model.save(model_path)\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    \n",
    "    # Guardar los valores de monitoreo del entrenamiento\n",
    "    train_moe_directory = 'train_moe'\n",
    "    os.makedirs(train_moe_directory, exist_ok=True)\n",
    "    history_path = os.path.join(train_moe_directory, f'{species_name}_cluster_{cluster_label}_training_history.csv')\n",
    "    pd.DataFrame(history.history).to_csv(history_path, index=False)\n",
    "    \n",
    "    print(f'Modelo MoE, scaler y datos de entrenamiento guardados para {species_name} en clúster {cluster_label}')\n",
    "    return model, scaler\n",
    "\n",
    "# Función para hacer predicciones con bandas de confianza usando bootstrap\n",
    "def predict_with_confidence_intervals(model, scaler, data, look_back=6, n_bootstrap=100, alpha=0.01):\n",
    "    features = ['landed_w_kg','Cluster_Label','mean_temp_30m','mean_temp_10m','thetao_sfc=6',\n",
    "                   'thetao_sfc=7.92956018447876','thetao_sfc=9.572997093200684','thetao_sfc=11.40499973297119',\n",
    "                   'thetao_sfc=13.46714019775391','thetao_sfc=15.8100700378418','thetao_sfc=18.49555969238281',\n",
    "                   'thetao_sfc=21.59881973266602','thetao_sfc=25.21141052246094','thetao_sfc=29.44473075866699']\n",
    "    group_scaled = scaler.transform(data[features])\n",
    "\n",
    "    X = []\n",
    "    for i in range(len(group_scaled) - look_back):\n",
    "        a = group_scaled[i:(i + look_back)]\n",
    "        X.append(a)\n",
    "    X = np.array(X)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2]))\n",
    "    \n",
    "    predictions = model.predict(X)\n",
    "    predictions = scaler.inverse_transform(np.hstack((predictions, X[:, -1, 1:])))[:, 0]\n",
    "    \n",
    "    # Bootstrap para bandas de confianza\n",
    "    bootstrap_predictions = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        indices = np.random.choice(range(len(X)), len(X), replace=True)\n",
    "        X_sample = X[indices]\n",
    "        pred_sample = model.predict(X_sample)\n",
    "        pred_sample = scaler.inverse_transform(np.hstack((pred_sample, X_sample[:, -1, 1:])))[:, 0]\n",
    "        bootstrap_predictions.append(pred_sample)\n",
    "    \n",
    "    bootstrap_predictions = np.array(bootstrap_predictions)\n",
    "    lower_bound = np.percentile(bootstrap_predictions, 100 * alpha / 2, axis=0)\n",
    "    upper_bound = np.percentile(bootstrap_predictions, 100 * (1 - alpha / 2), axis=0)\n",
    "    \n",
    "    return predictions, lower_bound, upper_bound\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: CORVINA, cluster: 7\n",
      "Epoch 1/50\n",
      "8460/8460 [==============================] - 44s 5ms/step - loss: 4.2842e-04 - val_loss: 7.5258e-05\n",
      "Epoch 2/50\n",
      "8460/8460 [==============================] - 40s 5ms/step - loss: 4.0585e-04 - val_loss: 6.9219e-05\n",
      "Epoch 3/50\n",
      "8460/8460 [==============================] - 40s 5ms/step - loss: 3.9413e-04 - val_loss: 7.0506e-05\n",
      "Epoch 4/50\n",
      "8460/8460 [==============================] - 40s 5ms/step - loss: 3.9701e-04 - val_loss: 9.3715e-05\n",
      "Epoch 5/50\n",
      "8460/8460 [==============================] - 40s 5ms/step - loss: 3.7278e-04 - val_loss: 7.1228e-05\n",
      "Epoch 6/50\n",
      "8460/8460 [==============================] - 40s 5ms/step - loss: 3.7716e-04 - val_loss: 7.1896e-05\n",
      "Epoch 7/50\n",
      "8460/8460 [==============================] - 40s 5ms/step - loss: 3.5887e-04 - val_loss: 7.0003e-05\n",
      "Epoch 8/50\n",
      "8460/8460 [==============================] - 40s 5ms/step - loss: 3.6941e-04 - val_loss: 6.9730e-05\n",
      "Epoch 9/50\n",
      "8460/8460 [==============================] - 40s 5ms/step - loss: 3.5708e-04 - val_loss: 7.2128e-05\n",
      "Epoch 10/50\n",
      "8460/8460 [==============================] - 40s 5ms/step - loss: 3.5641e-04 - val_loss: 6.9482e-05\n",
      "Epoch 11/50\n",
      "8460/8460 [==============================] - 40s 5ms/step - loss: 3.5448e-04 - val_loss: 7.0428e-05\n",
      "Epoch 12/50\n",
      "8450/8460 [============================>.] - ETA: 0s - loss: 3.4855e-04Restoring model weights from the end of the best epoch: 2.\n",
      "8460/8460 [==============================] - 40s 5ms/step - loss: 3.4829e-04 - val_loss: 1.6763e-04\n",
      "Epoch 12: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CORVINA en clúster 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para CORVINA en clúster 7: 15186032.425566895, R2 Mensual: 0.6420241305689797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1491139/3138292417.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: CORVINA, cluster: 0\n",
      "Epoch 1/50\n",
      "28/28 [==============================] - 5s 29ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "26/28 [==========================>...] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "28/28 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CORVINA en clúster 0\n",
      "No se tienen datos suficientes para CORVINA en clúster 0 en los últimos seis meses de 2023\n",
      "Training model for species: CORVINA, cluster: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12908/12908 [==============================] - 65s 5ms/step - loss: 2.9250e-04 - val_loss: 1.2823e-04\n",
      "Epoch 2/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.8979e-04 - val_loss: 1.3097e-04\n",
      "Epoch 3/50\n",
      "12908/12908 [==============================] - 62s 5ms/step - loss: 2.8918e-04 - val_loss: 1.2983e-04\n",
      "Epoch 4/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.9065e-04 - val_loss: 1.2426e-04\n",
      "Epoch 5/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.9074e-04 - val_loss: 1.2295e-04\n",
      "Epoch 6/50\n",
      "12908/12908 [==============================] - 62s 5ms/step - loss: 2.8931e-04 - val_loss: 1.2710e-04\n",
      "Epoch 7/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.9067e-04 - val_loss: 1.2428e-04\n",
      "Epoch 8/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.9020e-04 - val_loss: 1.2794e-04\n",
      "Epoch 9/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.8473e-04 - val_loss: 1.2863e-04\n",
      "Epoch 10/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.7578e-04 - val_loss: 1.2535e-04\n",
      "Epoch 11/50\n",
      "12908/12908 [==============================] - 60s 5ms/step - loss: 2.6886e-04 - val_loss: 1.2932e-04\n",
      "Epoch 12/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.6955e-04 - val_loss: 1.6701e-04\n",
      "Epoch 13/50\n",
      "12908/12908 [==============================] - 60s 5ms/step - loss: 2.6865e-04 - val_loss: 1.2055e-04\n",
      "Epoch 14/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.7058e-04 - val_loss: 1.3629e-04\n",
      "Epoch 15/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.6090e-04 - val_loss: 1.1964e-04\n",
      "Epoch 16/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.5844e-04 - val_loss: 1.5894e-04\n",
      "Epoch 17/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.6033e-04 - val_loss: 1.3163e-04\n",
      "Epoch 18/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.5453e-04 - val_loss: 1.1767e-04\n",
      "Epoch 19/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.5204e-04 - val_loss: 1.4962e-04\n",
      "Epoch 20/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.5746e-04 - val_loss: 1.1696e-04\n",
      "Epoch 21/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.5264e-04 - val_loss: 1.1534e-04\n",
      "Epoch 22/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.4469e-04 - val_loss: 1.2505e-04\n",
      "Epoch 23/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.4660e-04 - val_loss: 1.2037e-04\n",
      "Epoch 24/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.4742e-04 - val_loss: 1.2532e-04\n",
      "Epoch 25/50\n",
      "12908/12908 [==============================] - 60s 5ms/step - loss: 2.4970e-04 - val_loss: 1.1972e-04\n",
      "Epoch 26/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.5057e-04 - val_loss: 1.1007e-04\n",
      "Epoch 27/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.3993e-04 - val_loss: 1.1365e-04\n",
      "Epoch 28/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.4595e-04 - val_loss: 1.2458e-04\n",
      "Epoch 29/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.4134e-04 - val_loss: 1.1370e-04\n",
      "Epoch 30/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.4652e-04 - val_loss: 1.1311e-04\n",
      "Epoch 31/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.4448e-04 - val_loss: 2.3856e-04\n",
      "Epoch 32/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.4220e-04 - val_loss: 1.0985e-04\n",
      "Epoch 33/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.4329e-04 - val_loss: 1.0428e-04\n",
      "Epoch 34/50\n",
      "12908/12908 [==============================] - 60s 5ms/step - loss: 2.4008e-04 - val_loss: 1.7195e-04\n",
      "Epoch 35/50\n",
      "12908/12908 [==============================] - 61s 5ms/step - loss: 2.3859e-04 - val_loss: 1.1767e-04\n",
      "Epoch 36/50\n",
      "12908/12908 [==============================] - 60s 5ms/step - loss: 2.4066e-04 - val_loss: 1.1315e-04\n",
      "Epoch 37/50\n",
      "12908/12908 [==============================] - 60s 5ms/step - loss: 2.4058e-04 - val_loss: 1.1079e-04\n",
      "Epoch 38/50\n",
      "12908/12908 [==============================] - 60s 5ms/step - loss: 2.3746e-04 - val_loss: 1.2134e-04\n",
      "Epoch 39/50\n",
      "12908/12908 [==============================] - 60s 5ms/step - loss: 2.3972e-04 - val_loss: 1.0958e-04\n",
      "Epoch 40/50\n",
      "12908/12908 [==============================] - 60s 5ms/step - loss: 2.3557e-04 - val_loss: 1.1932e-04\n",
      "Epoch 41/50\n",
      "12908/12908 [==============================] - 59s 5ms/step - loss: 2.3533e-04 - val_loss: 1.1745e-04\n",
      "Epoch 42/50\n",
      "12908/12908 [==============================] - 60s 5ms/step - loss: 2.3800e-04 - val_loss: 1.1508e-04\n",
      "Epoch 43/50\n",
      "12903/12908 [============================>.] - ETA: 0s - loss: 2.4181e-04Restoring model weights from the end of the best epoch: 33.\n",
      "12908/12908 [==============================] - 59s 5ms/step - loss: 2.4178e-04 - val_loss: 1.8662e-04\n",
      "Epoch 43: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CORVINA en clúster 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 1s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 2ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 2ms/step\n",
      "80/80 [==============================] - 0s 2ms/step\n",
      "80/80 [==============================] - 0s 2ms/step\n",
      "80/80 [==============================] - 0s 2ms/step\n",
      "80/80 [==============================] - 0s 2ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 2ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 2ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 2ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "80/80 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para CORVINA en clúster 3: 810599900.67686, R2 Mensual: 0.44221537290325375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1491139/3138292417.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: CORVINA, cluster: 6\n",
      "Epoch 1/50\n",
      "4856/4856 [==============================] - 27s 5ms/step - loss: 7.4873e-04 - val_loss: 6.6681e-04\n",
      "Epoch 2/50\n",
      "4856/4856 [==============================] - 23s 5ms/step - loss: 7.1951e-04 - val_loss: 9.0056e-04\n",
      "Epoch 3/50\n",
      "4856/4856 [==============================] - 23s 5ms/step - loss: 7.3151e-04 - val_loss: 6.4448e-04\n",
      "Epoch 4/50\n",
      "4856/4856 [==============================] - 23s 5ms/step - loss: 7.1977e-04 - val_loss: 6.6270e-04\n",
      "Epoch 5/50\n",
      "4856/4856 [==============================] - 23s 5ms/step - loss: 7.1384e-04 - val_loss: 6.3544e-04\n",
      "Epoch 6/50\n",
      "4856/4856 [==============================] - 23s 5ms/step - loss: 7.0424e-04 - val_loss: 6.1299e-04\n",
      "Epoch 7/50\n",
      "4856/4856 [==============================] - 23s 5ms/step - loss: 7.0654e-04 - val_loss: 6.4234e-04\n",
      "Epoch 8/50\n",
      "4856/4856 [==============================] - 23s 5ms/step - loss: 7.0770e-04 - val_loss: 6.1098e-04\n",
      "Epoch 9/50\n",
      "4856/4856 [==============================] - 23s 5ms/step - loss: 7.0057e-04 - val_loss: 6.0926e-04\n",
      "Epoch 10/50\n",
      "4856/4856 [==============================] - 22s 5ms/step - loss: 7.0233e-04 - val_loss: 6.1991e-04\n",
      "Epoch 11/50\n",
      "4856/4856 [==============================] - 23s 5ms/step - loss: 7.0376e-04 - val_loss: 6.1356e-04\n",
      "Epoch 12/50\n",
      "4856/4856 [==============================] - 23s 5ms/step - loss: 7.0291e-04 - val_loss: 6.0809e-04\n",
      "Epoch 13/50\n",
      "4856/4856 [==============================] - 23s 5ms/step - loss: 6.9936e-04 - val_loss: 6.3124e-04\n",
      "Epoch 14/50\n",
      "4856/4856 [==============================] - 23s 5ms/step - loss: 7.0734e-04 - val_loss: 6.1921e-04\n",
      "Epoch 15/50\n",
      "4856/4856 [==============================] - 23s 5ms/step - loss: 7.0643e-04 - val_loss: 6.1630e-04\n",
      "Epoch 16/50\n",
      "4856/4856 [==============================] - 23s 5ms/step - loss: 7.0443e-04 - val_loss: 6.1855e-04\n",
      "Epoch 17/50\n",
      "4856/4856 [==============================] - 23s 5ms/step - loss: 7.0429e-04 - val_loss: 6.3248e-04\n",
      "Epoch 18/50\n",
      "4856/4856 [==============================] - 23s 5ms/step - loss: 7.0479e-04 - val_loss: 6.1260e-04\n",
      "Epoch 19/50\n",
      "4856/4856 [==============================] - 23s 5ms/step - loss: 6.9806e-04 - val_loss: 6.1901e-04\n",
      "Epoch 20/50\n",
      "4856/4856 [==============================] - 23s 5ms/step - loss: 7.0294e-04 - val_loss: 6.1511e-04\n",
      "Epoch 21/50\n",
      "4856/4856 [==============================] - 23s 5ms/step - loss: 7.0436e-04 - val_loss: 6.4100e-04\n",
      "Epoch 22/50\n",
      "4849/4856 [============================>.] - ETA: 0s - loss: 6.9932e-04Restoring model weights from the end of the best epoch: 12.\n",
      "4856/4856 [==============================] - 23s 5ms/step - loss: 6.9862e-04 - val_loss: 6.3662e-04\n",
      "Epoch 22: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CORVINA en clúster 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "MSE Mensual para CORVINA en clúster 6: 3905611605.860934, R2 Mensual: 0.6903243592558382\n",
      "Training model for species: CORVINA, cluster: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1491139/3138292417.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5976/5976 [==============================] - 33s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "5976/5976 [==============================] - 28s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "5976/5976 [==============================] - 28s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "5976/5976 [==============================] - 28s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "5976/5976 [==============================] - 28s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "5976/5976 [==============================] - 28s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "5976/5976 [==============================] - 28s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "5976/5976 [==============================] - 28s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "5976/5976 [==============================] - 28s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "5969/5976 [============================>.] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "5976/5976 [==============================] - 28s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CORVINA en clúster 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "MSE Mensual para CORVINA en clúster 5: 1325180347645.1, R2 Mensual: -0.2303712473441435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1491139/3138292417.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: CORVINA, cluster: 2\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 4s 51ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "13/15 [=========================>....] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "15/15 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CORVINA en clúster 2\n",
      "No se tienen datos suficientes para CORVINA en clúster 2 en los últimos seis meses de 2023\n",
      "Training model for species: CORVINA, cluster: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4557/4557 [==============================] - 26s 5ms/step - loss: 2.6648e-04 - val_loss: 1.7828e-05\n",
      "Epoch 2/50\n",
      "4557/4557 [==============================] - 22s 5ms/step - loss: 2.5569e-04 - val_loss: 1.8209e-05\n",
      "Epoch 3/50\n",
      "4557/4557 [==============================] - 22s 5ms/step - loss: 2.5299e-04 - val_loss: 1.8891e-05\n",
      "Epoch 4/50\n",
      "4557/4557 [==============================] - 22s 5ms/step - loss: 2.4984e-04 - val_loss: 2.8009e-05\n",
      "Epoch 5/50\n",
      "4557/4557 [==============================] - 22s 5ms/step - loss: 2.5209e-04 - val_loss: 2.1408e-05\n",
      "Epoch 6/50\n",
      "4557/4557 [==============================] - 22s 5ms/step - loss: 2.5269e-04 - val_loss: 1.8626e-05\n",
      "Epoch 7/50\n",
      "4557/4557 [==============================] - 22s 5ms/step - loss: 2.5173e-04 - val_loss: 1.9579e-05\n",
      "Epoch 8/50\n",
      "4557/4557 [==============================] - 22s 5ms/step - loss: 2.5096e-04 - val_loss: 2.2150e-05\n",
      "Epoch 9/50\n",
      "4557/4557 [==============================] - 21s 5ms/step - loss: 2.5276e-04 - val_loss: 1.9397e-05\n",
      "Epoch 10/50\n",
      "4557/4557 [==============================] - 21s 5ms/step - loss: 2.5319e-04 - val_loss: 1.7973e-05\n",
      "Epoch 11/50\n",
      "4556/4557 [============================>.] - ETA: 0s - loss: 2.5158e-04Restoring model weights from the end of the best epoch: 1.\n",
      "4557/4557 [==============================] - 22s 5ms/step - loss: 2.5153e-04 - val_loss: 2.3907e-05\n",
      "Epoch 11: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CORVINA en clúster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "MSE Mensual para CORVINA en clúster 1: 146515978.12874678, R2 Mensual: -0.7281062465009449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1491139/3138292417.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: CORVINA, cluster: 4\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 4s 23ms/step - loss: 0.0786 - val_loss: 0.0467\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0601 - val_loss: 0.0483\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0550 - val_loss: 0.0491\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0526 - val_loss: 0.0457\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0488 - val_loss: 0.0519\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0434 - val_loss: 0.0481\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0446 - val_loss: 0.0524\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0481 - val_loss: 0.0556\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0432 - val_loss: 0.0499\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0388 - val_loss: 0.0531\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0389 - val_loss: 0.0573\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0377 - val_loss: 0.0585\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0354 - val_loss: 0.0576\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0342Restoring model weights from the end of the best epoch: 4.\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0342 - val_loss: 0.0592\n",
      "Epoch 14: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para CORVINA en clúster 4\n",
      "No se tienen datos suficientes para CORVINA en clúster 4 en los últimos seis meses de 2023\n",
      "Training model for species: PARGO, cluster: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8716/8716 [==============================] - 46s 5ms/step - loss: 9.3130e-04 - val_loss: 3.4095e-04\n",
      "Epoch 2/50\n",
      "8716/8716 [==============================] - 41s 5ms/step - loss: 8.7376e-04 - val_loss: 3.3699e-04\n",
      "Epoch 3/50\n",
      "8716/8716 [==============================] - 41s 5ms/step - loss: 8.7159e-04 - val_loss: 3.3676e-04\n",
      "Epoch 4/50\n",
      "8716/8716 [==============================] - 41s 5ms/step - loss: 8.8799e-04 - val_loss: 3.4159e-04\n",
      "Epoch 5/50\n",
      "8716/8716 [==============================] - 41s 5ms/step - loss: 8.6155e-04 - val_loss: 3.3841e-04\n",
      "Epoch 6/50\n",
      "8716/8716 [==============================] - 41s 5ms/step - loss: 8.6334e-04 - val_loss: 3.4489e-04\n",
      "Epoch 7/50\n",
      "8716/8716 [==============================] - 41s 5ms/step - loss: 8.5198e-04 - val_loss: 3.2004e-04\n",
      "Epoch 8/50\n",
      "8716/8716 [==============================] - 41s 5ms/step - loss: 8.2800e-04 - val_loss: 3.2147e-04\n",
      "Epoch 9/50\n",
      "8716/8716 [==============================] - 41s 5ms/step - loss: 8.3289e-04 - val_loss: 3.2042e-04\n",
      "Epoch 10/50\n",
      "8716/8716 [==============================] - 41s 5ms/step - loss: 8.2735e-04 - val_loss: 3.5033e-04\n",
      "Epoch 11/50\n",
      "8716/8716 [==============================] - 41s 5ms/step - loss: 8.1571e-04 - val_loss: 3.6652e-04\n",
      "Epoch 12/50\n",
      "8716/8716 [==============================] - 41s 5ms/step - loss: 8.1328e-04 - val_loss: 3.1093e-04\n",
      "Epoch 13/50\n",
      "8716/8716 [==============================] - 41s 5ms/step - loss: 8.0922e-04 - val_loss: 3.5759e-04\n",
      "Epoch 14/50\n",
      "8716/8716 [==============================] - 41s 5ms/step - loss: 8.0972e-04 - val_loss: 3.1052e-04\n",
      "Epoch 15/50\n",
      "8716/8716 [==============================] - 41s 5ms/step - loss: 8.1037e-04 - val_loss: 3.1611e-04\n",
      "Epoch 16/50\n",
      "8716/8716 [==============================] - 41s 5ms/step - loss: 8.0610e-04 - val_loss: 3.1181e-04\n",
      "Epoch 17/50\n",
      "8716/8716 [==============================] - 41s 5ms/step - loss: 8.0346e-04 - val_loss: 3.0956e-04\n",
      "Epoch 18/50\n",
      "8716/8716 [==============================] - 42s 5ms/step - loss: 8.0342e-04 - val_loss: 3.3923e-04\n",
      "Epoch 19/50\n",
      "8716/8716 [==============================] - 41s 5ms/step - loss: 8.0462e-04 - val_loss: 3.0711e-04\n",
      "Epoch 20/50\n",
      "8716/8716 [==============================] - 41s 5ms/step - loss: 8.0303e-04 - val_loss: 3.1195e-04\n",
      "Epoch 21/50\n",
      "8716/8716 [==============================] - 41s 5ms/step - loss: 7.9872e-04 - val_loss: 3.6614e-04\n",
      "Epoch 22/50\n",
      "8716/8716 [==============================] - 41s 5ms/step - loss: 8.0108e-04 - val_loss: 3.1701e-04\n",
      "Epoch 23/50\n",
      "8716/8716 [==============================] - 41s 5ms/step - loss: 7.9485e-04 - val_loss: 3.1231e-04\n",
      "Epoch 24/50\n",
      "8716/8716 [==============================] - 41s 5ms/step - loss: 7.9930e-04 - val_loss: 3.1781e-04\n",
      "Epoch 25/50\n",
      "8716/8716 [==============================] - 41s 5ms/step - loss: 7.9759e-04 - val_loss: 3.1152e-04\n",
      "Epoch 26/50\n",
      "8716/8716 [==============================] - 41s 5ms/step - loss: 7.9411e-04 - val_loss: 3.2532e-04\n",
      "Epoch 27/50\n",
      "8716/8716 [==============================] - 41s 5ms/step - loss: 7.9719e-04 - val_loss: 3.0955e-04\n",
      "Epoch 28/50\n",
      "8716/8716 [==============================] - 41s 5ms/step - loss: 7.9116e-04 - val_loss: 3.1397e-04\n",
      "Epoch 29/50\n",
      "8707/8716 [============================>.] - ETA: 0s - loss: 7.9770e-04Restoring model weights from the end of the best epoch: 19.\n",
      "8716/8716 [==============================] - 41s 5ms/step - loss: 7.9732e-04 - val_loss: 3.9755e-04\n",
      "Epoch 29: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para PARGO en clúster 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para PARGO en clúster 7: 8871278.779948395, R2 Mensual: 0.8686996983714856\n",
      "Training model for species: PARGO, cluster: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1491139/3138292417.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "24/24 [==============================] - 4s 33ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "14/24 [================>.............] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "24/24 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para PARGO en clúster 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 591ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "MSE Mensual para PARGO en clúster 0: 1000000.0, R2 Mensual: nan\n",
      "Training model for species: PARGO, cluster: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1491139/3138292417.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n",
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/sklearn/metrics/_regression.py:1187: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16284/16284 [==============================] - 81s 5ms/step - loss: 3.6502e-04 - val_loss: 7.8439e-04\n",
      "Epoch 2/50\n",
      "16284/16284 [==============================] - 76s 5ms/step - loss: 3.4381e-04 - val_loss: 8.0123e-04\n",
      "Epoch 3/50\n",
      "16284/16284 [==============================] - 76s 5ms/step - loss: 3.3076e-04 - val_loss: 7.8469e-04\n",
      "Epoch 4/50\n",
      "16284/16284 [==============================] - 76s 5ms/step - loss: 3.1492e-04 - val_loss: 8.0994e-04\n",
      "Epoch 5/50\n",
      "16284/16284 [==============================] - 76s 5ms/step - loss: 3.1379e-04 - val_loss: 7.6040e-04\n",
      "Epoch 6/50\n",
      "16284/16284 [==============================] - 76s 5ms/step - loss: 3.0761e-04 - val_loss: 7.4802e-04\n",
      "Epoch 7/50\n",
      "16284/16284 [==============================] - 77s 5ms/step - loss: 3.0711e-04 - val_loss: 7.0825e-04\n",
      "Epoch 8/50\n",
      "16284/16284 [==============================] - 76s 5ms/step - loss: 2.9983e-04 - val_loss: 7.5332e-04\n",
      "Epoch 9/50\n",
      "16284/16284 [==============================] - 76s 5ms/step - loss: 3.0508e-04 - val_loss: 7.4497e-04\n",
      "Epoch 10/50\n",
      "16284/16284 [==============================] - 77s 5ms/step - loss: 3.0283e-04 - val_loss: 7.0107e-04\n",
      "Epoch 11/50\n",
      "16284/16284 [==============================] - 76s 5ms/step - loss: 2.9047e-04 - val_loss: 7.8636e-04\n",
      "Epoch 12/50\n",
      "16284/16284 [==============================] - 77s 5ms/step - loss: 3.0047e-04 - val_loss: 7.0207e-04\n",
      "Epoch 13/50\n",
      "16284/16284 [==============================] - 76s 5ms/step - loss: 2.9251e-04 - val_loss: 6.9612e-04\n",
      "Epoch 14/50\n",
      "16284/16284 [==============================] - 76s 5ms/step - loss: 2.9334e-04 - val_loss: 7.1319e-04\n",
      "Epoch 15/50\n",
      "16284/16284 [==============================] - 77s 5ms/step - loss: 2.9183e-04 - val_loss: 7.2338e-04\n",
      "Epoch 16/50\n",
      "16284/16284 [==============================] - 76s 5ms/step - loss: 2.9013e-04 - val_loss: 7.1872e-04\n",
      "Epoch 17/50\n",
      "16284/16284 [==============================] - 77s 5ms/step - loss: 2.8923e-04 - val_loss: 7.0574e-04\n",
      "Epoch 18/50\n",
      "16284/16284 [==============================] - 77s 5ms/step - loss: 2.8747e-04 - val_loss: 6.8919e-04\n",
      "Epoch 19/50\n",
      "16284/16284 [==============================] - 76s 5ms/step - loss: 2.8899e-04 - val_loss: 7.0158e-04\n",
      "Epoch 20/50\n",
      "16284/16284 [==============================] - 76s 5ms/step - loss: 2.8671e-04 - val_loss: 7.0379e-04\n",
      "Epoch 21/50\n",
      "16284/16284 [==============================] - 76s 5ms/step - loss: 2.8998e-04 - val_loss: 7.0621e-04\n",
      "Epoch 22/50\n",
      "16284/16284 [==============================] - 76s 5ms/step - loss: 2.8752e-04 - val_loss: 7.0564e-04\n",
      "Epoch 23/50\n",
      "16284/16284 [==============================] - 76s 5ms/step - loss: 2.8718e-04 - val_loss: 6.8404e-04\n",
      "Epoch 24/50\n",
      "16284/16284 [==============================] - 76s 5ms/step - loss: 2.8880e-04 - val_loss: 7.2455e-04\n",
      "Epoch 25/50\n",
      "16284/16284 [==============================] - 76s 5ms/step - loss: 2.8827e-04 - val_loss: 7.0424e-04\n",
      "Epoch 26/50\n",
      "16284/16284 [==============================] - 76s 5ms/step - loss: 2.8680e-04 - val_loss: 7.1450e-04\n",
      "Epoch 27/50\n",
      "16284/16284 [==============================] - 76s 5ms/step - loss: 2.8463e-04 - val_loss: 6.9050e-04\n",
      "Epoch 28/50\n",
      "16284/16284 [==============================] - 76s 5ms/step - loss: 2.8484e-04 - val_loss: 6.9473e-04\n",
      "Epoch 29/50\n",
      "16284/16284 [==============================] - 76s 5ms/step - loss: 2.8480e-04 - val_loss: 6.9528e-04\n",
      "Epoch 30/50\n",
      "16284/16284 [==============================] - 76s 5ms/step - loss: 2.8543e-04 - val_loss: 6.8063e-04\n",
      "Epoch 31/50\n",
      "16284/16284 [==============================] - 76s 5ms/step - loss: 2.8505e-04 - val_loss: 6.8048e-04\n",
      "Epoch 32/50\n",
      "16284/16284 [==============================] - 75s 5ms/step - loss: 2.8618e-04 - val_loss: 6.8753e-04\n",
      "Epoch 33/50\n",
      "16284/16284 [==============================] - 75s 5ms/step - loss: 2.8477e-04 - val_loss: 6.9037e-04\n",
      "Epoch 34/50\n",
      "16284/16284 [==============================] - 75s 5ms/step - loss: 2.8454e-04 - val_loss: 6.9950e-04\n",
      "Epoch 35/50\n",
      "16284/16284 [==============================] - 75s 5ms/step - loss: 2.8384e-04 - val_loss: 6.8362e-04\n",
      "Epoch 36/50\n",
      "16284/16284 [==============================] - 75s 5ms/step - loss: 2.8461e-04 - val_loss: 6.8342e-04\n",
      "Epoch 37/50\n",
      "16284/16284 [==============================] - 76s 5ms/step - loss: 2.8220e-04 - val_loss: 7.1729e-04\n",
      "Epoch 38/50\n",
      "16284/16284 [==============================] - 77s 5ms/step - loss: 2.8442e-04 - val_loss: 6.8200e-04\n",
      "Epoch 39/50\n",
      "16284/16284 [==============================] - 76s 5ms/step - loss: 2.8239e-04 - val_loss: 6.9260e-04\n",
      "Epoch 40/50\n",
      "16284/16284 [==============================] - 76s 5ms/step - loss: 2.8508e-04 - val_loss: 7.0692e-04\n",
      "Epoch 41/50\n",
      "16281/16284 [============================>.] - ETA: 0s - loss: 2.8302e-04Restoring model weights from the end of the best epoch: 31.\n",
      "16284/16284 [==============================] - 77s 5ms/step - loss: 2.8297e-04 - val_loss: 6.8865e-04\n",
      "Epoch 41: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para PARGO en clúster 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 2ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 2ms/step\n",
      "86/86 [==============================] - 0s 2ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 2ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 2ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 2ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 2ms/step\n",
      "86/86 [==============================] - 0s 2ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 2ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 2ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 2ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 2ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 2ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 2ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 2ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para PARGO en clúster 3: 498009939.72773933, R2 Mensual: -0.5793738647188842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1491139/3138292417.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: PARGO, cluster: 6\n",
      "Epoch 1/50\n",
      "3132/3132 [==============================] - 20s 5ms/step - loss: 0.0016 - val_loss: 4.9181e-04\n",
      "Epoch 2/50\n",
      "3132/3132 [==============================] - 15s 5ms/step - loss: 0.0016 - val_loss: 7.3104e-04\n",
      "Epoch 3/50\n",
      "3132/3132 [==============================] - 15s 5ms/step - loss: 0.0016 - val_loss: 5.1726e-04\n",
      "Epoch 4/50\n",
      "3132/3132 [==============================] - 15s 5ms/step - loss: 0.0016 - val_loss: 4.8944e-04\n",
      "Epoch 5/50\n",
      "3132/3132 [==============================] - 15s 5ms/step - loss: 0.0016 - val_loss: 5.3472e-04\n",
      "Epoch 6/50\n",
      "3132/3132 [==============================] - 15s 5ms/step - loss: 0.0016 - val_loss: 5.8422e-04\n",
      "Epoch 7/50\n",
      "3132/3132 [==============================] - 15s 5ms/step - loss: 0.0015 - val_loss: 5.3957e-04\n",
      "Epoch 8/50\n",
      "3132/3132 [==============================] - 15s 5ms/step - loss: 0.0015 - val_loss: 8.3983e-04\n",
      "Epoch 9/50\n",
      "3132/3132 [==============================] - 15s 5ms/step - loss: 0.0015 - val_loss: 5.2078e-04\n",
      "Epoch 10/50\n",
      "3132/3132 [==============================] - 14s 5ms/step - loss: 0.0015 - val_loss: 6.2324e-04\n",
      "Epoch 11/50\n",
      "3132/3132 [==============================] - 14s 5ms/step - loss: 0.0015 - val_loss: 5.6271e-04\n",
      "Epoch 12/50\n",
      "3132/3132 [==============================] - 15s 5ms/step - loss: 0.0015 - val_loss: 5.4255e-04\n",
      "Epoch 13/50\n",
      "3132/3132 [==============================] - 15s 5ms/step - loss: 0.0016 - val_loss: 5.1797e-04\n",
      "Epoch 14/50\n",
      "3127/3132 [============================>.] - ETA: 0s - loss: 0.0015Restoring model weights from the end of the best epoch: 4.\n",
      "3132/3132 [==============================] - 15s 5ms/step - loss: 0.0015 - val_loss: 5.1534e-04\n",
      "Epoch 14: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para PARGO en clúster 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para PARGO en clúster 6: 9380255.221233966, R2 Mensual: 0.5791924245322284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1491139/3138292417.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: PARGO, cluster: 2\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 4s 32ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "14/24 [================>.............] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "24/24 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para PARGO en clúster 2\n",
      "Error entrenando el modelo para especie: PARGO, clúster: 2. Error: tuple index out of range\n",
      "Training model for species: PARGO, cluster: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13066/13066 [==============================] - 65s 5ms/step - loss: 7.2223e-04 - val_loss: 7.1978e-04\n",
      "Epoch 2/50\n",
      "13066/13066 [==============================] - 61s 5ms/step - loss: 6.7855e-04 - val_loss: 6.8205e-04\n",
      "Epoch 3/50\n",
      "13066/13066 [==============================] - 61s 5ms/step - loss: 6.5365e-04 - val_loss: 7.0856e-04\n",
      "Epoch 4/50\n",
      "13066/13066 [==============================] - 60s 5ms/step - loss: 6.4847e-04 - val_loss: 6.2489e-04\n",
      "Epoch 5/50\n",
      "13066/13066 [==============================] - 61s 5ms/step - loss: 6.4261e-04 - val_loss: 7.3493e-04\n",
      "Epoch 6/50\n",
      "13066/13066 [==============================] - 62s 5ms/step - loss: 6.4195e-04 - val_loss: 6.8919e-04\n",
      "Epoch 7/50\n",
      "13066/13066 [==============================] - 61s 5ms/step - loss: 6.3813e-04 - val_loss: 6.4431e-04\n",
      "Epoch 8/50\n",
      "13066/13066 [==============================] - 60s 5ms/step - loss: 6.3668e-04 - val_loss: 6.4063e-04\n",
      "Epoch 9/50\n",
      "13066/13066 [==============================] - 61s 5ms/step - loss: 6.3317e-04 - val_loss: 6.0372e-04\n",
      "Epoch 10/50\n",
      "13066/13066 [==============================] - 62s 5ms/step - loss: 6.3163e-04 - val_loss: 6.2352e-04\n",
      "Epoch 11/50\n",
      "13066/13066 [==============================] - 63s 5ms/step - loss: 6.3190e-04 - val_loss: 6.4167e-04\n",
      "Epoch 12/50\n",
      "13066/13066 [==============================] - 63s 5ms/step - loss: 6.2998e-04 - val_loss: 6.1297e-04\n",
      "Epoch 13/50\n",
      "13066/13066 [==============================] - 63s 5ms/step - loss: 6.3106e-04 - val_loss: 6.2830e-04\n",
      "Epoch 14/50\n",
      "13066/13066 [==============================] - 62s 5ms/step - loss: 6.2644e-04 - val_loss: 6.5808e-04\n",
      "Epoch 15/50\n",
      "13066/13066 [==============================] - 62s 5ms/step - loss: 6.3083e-04 - val_loss: 6.5415e-04\n",
      "Epoch 16/50\n",
      "13066/13066 [==============================] - 62s 5ms/step - loss: 6.2788e-04 - val_loss: 6.5767e-04\n",
      "Epoch 17/50\n",
      "13066/13066 [==============================] - 62s 5ms/step - loss: 6.2643e-04 - val_loss: 6.1360e-04\n",
      "Epoch 18/50\n",
      "13066/13066 [==============================] - 62s 5ms/step - loss: 6.2699e-04 - val_loss: 6.3407e-04\n",
      "Epoch 19/50\n",
      "13065/13066 [============================>.] - ETA: 0s - loss: 6.2608e-04Restoring model weights from the end of the best epoch: 9.\n",
      "13066/13066 [==============================] - 62s 5ms/step - loss: 6.2604e-04 - val_loss: 6.2041e-04\n",
      "Epoch 19: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para PARGO en clúster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 1s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para PARGO en clúster 1: 153745241.62983945, R2 Mensual: 0.1752047933505131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1491139/3138292417.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: PARGO, cluster: 4\n",
      "Epoch 1/50\n",
      "73/73 [==============================] - 4s 15ms/step - loss: 0.0063 - val_loss: 0.0669\n",
      "Epoch 2/50\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.0053 - val_loss: 0.0615\n",
      "Epoch 3/50\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0655\n",
      "Epoch 4/50\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0672\n",
      "Epoch 5/50\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0637\n",
      "Epoch 6/50\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0650\n",
      "Epoch 7/50\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0660\n",
      "Epoch 8/50\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0657\n",
      "Epoch 9/50\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0621\n",
      "Epoch 10/50\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0610\n",
      "Epoch 11/50\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0665\n",
      "Epoch 12/50\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0633\n",
      "Epoch 13/50\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0638\n",
      "Epoch 14/50\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0652\n",
      "Epoch 15/50\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0621\n",
      "Epoch 16/50\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0617\n",
      "Epoch 17/50\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0632\n",
      "Epoch 18/50\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0612\n",
      "Epoch 19/50\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0597\n",
      "Epoch 20/50\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0630\n",
      "Epoch 21/50\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0609\n",
      "Epoch 22/50\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0629\n",
      "Epoch 23/50\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0622\n",
      "Epoch 24/50\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0618\n",
      "Epoch 25/50\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0606\n",
      "Epoch 26/50\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0619\n",
      "Epoch 27/50\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0605\n",
      "Epoch 28/50\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0632\n",
      "Epoch 29/50\n",
      "72/73 [============================>.] - ETA: 0s - loss: 0.0046Restoring model weights from the end of the best epoch: 19.\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0633\n",
      "Epoch 29: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para PARGO en clúster 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 644ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "MSE Mensual para PARGO en clúster 4: 5324.3859722269535, R2 Mensual: nan\n",
      "Training model for species: SIERRA, cluster: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1491139/3138292417.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n",
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/sklearn/metrics/_regression.py:1187: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8237/8237 [==============================] - 43s 5ms/step - loss: 0.0084 - val_loss: 0.0094\n",
      "Epoch 2/50\n",
      "8237/8237 [==============================] - 39s 5ms/step - loss: 0.0080 - val_loss: 0.0096\n",
      "Epoch 3/50\n",
      "8237/8237 [==============================] - 39s 5ms/step - loss: 0.0077 - val_loss: 0.0091\n",
      "Epoch 4/50\n",
      "8237/8237 [==============================] - 39s 5ms/step - loss: 0.0077 - val_loss: 0.0088\n",
      "Epoch 5/50\n",
      "8237/8237 [==============================] - 39s 5ms/step - loss: 0.0076 - val_loss: 0.0093\n",
      "Epoch 6/50\n",
      "8237/8237 [==============================] - 39s 5ms/step - loss: 0.0076 - val_loss: 0.0088\n",
      "Epoch 7/50\n",
      "8237/8237 [==============================] - 39s 5ms/step - loss: 0.0076 - val_loss: 0.0091\n",
      "Epoch 8/50\n",
      "8237/8237 [==============================] - 39s 5ms/step - loss: 0.0076 - val_loss: 0.0087\n",
      "Epoch 9/50\n",
      "8237/8237 [==============================] - 39s 5ms/step - loss: 0.0074 - val_loss: 0.0088\n",
      "Epoch 10/50\n",
      "8237/8237 [==============================] - 39s 5ms/step - loss: 0.0073 - val_loss: 0.0087\n",
      "Epoch 11/50\n",
      "8237/8237 [==============================] - 39s 5ms/step - loss: 0.0073 - val_loss: 0.0086\n",
      "Epoch 12/50\n",
      "8237/8237 [==============================] - 39s 5ms/step - loss: 0.0073 - val_loss: 0.0088\n",
      "Epoch 13/50\n",
      "8237/8237 [==============================] - 39s 5ms/step - loss: 0.0073 - val_loss: 0.0086\n",
      "Epoch 14/50\n",
      "8237/8237 [==============================] - 39s 5ms/step - loss: 0.0073 - val_loss: 0.0087\n",
      "Epoch 15/50\n",
      "8237/8237 [==============================] - 39s 5ms/step - loss: 0.0072 - val_loss: 0.0086\n",
      "Epoch 16/50\n",
      "8237/8237 [==============================] - 39s 5ms/step - loss: 0.0073 - val_loss: 0.0084\n",
      "Epoch 17/50\n",
      "8237/8237 [==============================] - 39s 5ms/step - loss: 0.0072 - val_loss: 0.0089\n",
      "Epoch 18/50\n",
      "8237/8237 [==============================] - 39s 5ms/step - loss: 0.0072 - val_loss: 0.0087\n",
      "Epoch 19/50\n",
      "8237/8237 [==============================] - 39s 5ms/step - loss: 0.0072 - val_loss: 0.0087\n",
      "Epoch 20/50\n",
      "8237/8237 [==============================] - 39s 5ms/step - loss: 0.0072 - val_loss: 0.0089\n",
      "Epoch 21/50\n",
      "8237/8237 [==============================] - 39s 5ms/step - loss: 0.0072 - val_loss: 0.0087\n",
      "Epoch 22/50\n",
      "8237/8237 [==============================] - 39s 5ms/step - loss: 0.0072 - val_loss: 0.0086\n",
      "Epoch 23/50\n",
      "8237/8237 [==============================] - 39s 5ms/step - loss: 0.0072 - val_loss: 0.0085\n",
      "Epoch 24/50\n",
      "8237/8237 [==============================] - 39s 5ms/step - loss: 0.0072 - val_loss: 0.0086\n",
      "Epoch 25/50\n",
      "8237/8237 [==============================] - 39s 5ms/step - loss: 0.0072 - val_loss: 0.0086\n",
      "Epoch 26/50\n",
      "8227/8237 [============================>.] - ETA: 0s - loss: 0.0072Restoring model weights from the end of the best epoch: 16.\n",
      "8237/8237 [==============================] - 39s 5ms/step - loss: 0.0072 - val_loss: 0.0085\n",
      "Epoch 26: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para SIERRA en clúster 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para SIERRA en clúster 7: 90795092.45218432, R2 Mensual: 0.9358170384592494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1491139/3138292417.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: SIERRA, cluster: 0\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 4s 209ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "1/4 [======>.......................] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "4/4 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para SIERRA en clúster 0\n",
      "No se tienen datos suficientes para SIERRA en clúster 0 en los últimos seis meses de 2023\n",
      "Training model for species: SIERRA, cluster: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "9257/9257 [==============================] - 48s 5ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 2/50\n",
      "9257/9257 [==============================] - 44s 5ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 3/50\n",
      "9257/9257 [==============================] - 44s 5ms/step - loss: 0.0014 - val_loss: 9.2650e-04\n",
      "Epoch 4/50\n",
      "9257/9257 [==============================] - 44s 5ms/step - loss: 0.0014 - val_loss: 9.3110e-04\n",
      "Epoch 5/50\n",
      "9257/9257 [==============================] - 44s 5ms/step - loss: 0.0014 - val_loss: 9.4663e-04\n",
      "Epoch 6/50\n",
      "9257/9257 [==============================] - 44s 5ms/step - loss: 0.0014 - val_loss: 9.2483e-04\n",
      "Epoch 7/50\n",
      "9257/9257 [==============================] - 44s 5ms/step - loss: 0.0014 - val_loss: 9.6762e-04\n",
      "Epoch 8/50\n",
      "9257/9257 [==============================] - 44s 5ms/step - loss: 0.0013 - val_loss: 9.2075e-04\n",
      "Epoch 9/50\n",
      "9257/9257 [==============================] - 44s 5ms/step - loss: 0.0014 - val_loss: 8.9875e-04\n",
      "Epoch 10/50\n",
      "9257/9257 [==============================] - 45s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 11/50\n",
      "9257/9257 [==============================] - 45s 5ms/step - loss: 0.0013 - val_loss: 8.9957e-04\n",
      "Epoch 12/50\n",
      "9257/9257 [==============================] - 45s 5ms/step - loss: 0.0013 - val_loss: 8.6142e-04\n",
      "Epoch 13/50\n",
      "9257/9257 [==============================] - 44s 5ms/step - loss: 0.0013 - val_loss: 9.3092e-04\n",
      "Epoch 14/50\n",
      "9257/9257 [==============================] - 45s 5ms/step - loss: 0.0013 - val_loss: 8.5335e-04\n",
      "Epoch 15/50\n",
      "9257/9257 [==============================] - 45s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 16/50\n",
      "9257/9257 [==============================] - 44s 5ms/step - loss: 0.0013 - val_loss: 9.0857e-04\n",
      "Epoch 17/50\n",
      "9257/9257 [==============================] - 45s 5ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 18/50\n",
      "9257/9257 [==============================] - 45s 5ms/step - loss: 0.0013 - val_loss: 8.5343e-04\n",
      "Epoch 19/50\n",
      "9257/9257 [==============================] - 44s 5ms/step - loss: 0.0013 - val_loss: 9.5039e-04\n",
      "Epoch 20/50\n",
      "9257/9257 [==============================] - 44s 5ms/step - loss: 0.0013 - val_loss: 8.8751e-04\n",
      "Epoch 21/50\n",
      "9257/9257 [==============================] - 44s 5ms/step - loss: 0.0013 - val_loss: 8.4648e-04\n",
      "Epoch 22/50\n",
      "9257/9257 [==============================] - 44s 5ms/step - loss: 0.0013 - val_loss: 9.1992e-04\n",
      "Epoch 23/50\n",
      "9257/9257 [==============================] - 45s 5ms/step - loss: 0.0013 - val_loss: 9.1094e-04\n",
      "Epoch 24/50\n",
      "9257/9257 [==============================] - 45s 5ms/step - loss: 0.0013 - val_loss: 8.4811e-04\n",
      "Epoch 25/50\n",
      "9257/9257 [==============================] - 44s 5ms/step - loss: 0.0013 - val_loss: 9.9181e-04\n",
      "Epoch 26/50\n",
      "9257/9257 [==============================] - 44s 5ms/step - loss: 0.0013 - val_loss: 8.9895e-04\n",
      "Epoch 27/50\n",
      "9257/9257 [==============================] - 45s 5ms/step - loss: 0.0013 - val_loss: 8.9808e-04\n",
      "Epoch 28/50\n",
      "9257/9257 [==============================] - 45s 5ms/step - loss: 0.0013 - val_loss: 9.1318e-04\n",
      "Epoch 29/50\n",
      "9257/9257 [==============================] - 45s 5ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 30/50\n",
      "9257/9257 [==============================] - 45s 5ms/step - loss: 0.0013 - val_loss: 8.7795e-04\n",
      "Epoch 31/50\n",
      "9248/9257 [============================>.] - ETA: 0s - loss: 0.0013Restoring model weights from the end of the best epoch: 21.\n",
      "9257/9257 [==============================] - 45s 5ms/step - loss: 0.0013 - val_loss: 8.5869e-04\n",
      "Epoch 31: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para SIERRA en clúster 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 1s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 2ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 2ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 2ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 2ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 2ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 2ms/step\n",
      "56/56 [==============================] - 0s 2ms/step\n",
      "56/56 [==============================] - 0s 2ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "56/56 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para SIERRA en clúster 3: 243995993.31665894, R2 Mensual: 0.6989364627660584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1491139/3138292417.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: SIERRA, cluster: 6\n",
      "Epoch 1/50\n",
      "3990/3990 [==============================] - 24s 5ms/step - loss: 0.0118 - val_loss: 0.0107\n",
      "Epoch 2/50\n",
      "3990/3990 [==============================] - 19s 5ms/step - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 3/50\n",
      "3990/3990 [==============================] - 19s 5ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 4/50\n",
      "3990/3990 [==============================] - 19s 5ms/step - loss: 0.0107 - val_loss: 0.0099\n",
      "Epoch 5/50\n",
      "3990/3990 [==============================] - 19s 5ms/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 6/50\n",
      "3990/3990 [==============================] - 19s 5ms/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 7/50\n",
      "3990/3990 [==============================] - 19s 5ms/step - loss: 0.0106 - val_loss: 0.0099\n",
      "Epoch 8/50\n",
      "3990/3990 [==============================] - 19s 5ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 9/50\n",
      "3990/3990 [==============================] - 19s 5ms/step - loss: 0.0104 - val_loss: 0.0099\n",
      "Epoch 10/50\n",
      "3990/3990 [==============================] - 19s 5ms/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 11/50\n",
      "3990/3990 [==============================] - 19s 5ms/step - loss: 0.0106 - val_loss: 0.0100\n",
      "Epoch 12/50\n",
      "3990/3990 [==============================] - 19s 5ms/step - loss: 0.0105 - val_loss: 0.0099\n",
      "Epoch 13/50\n",
      "3990/3990 [==============================] - 19s 5ms/step - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 14/50\n",
      "3990/3990 [==============================] - 19s 5ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 15/50\n",
      "3990/3990 [==============================] - 18s 5ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 16/50\n",
      "3990/3990 [==============================] - 19s 5ms/step - loss: 0.0104 - val_loss: 0.0097\n",
      "Epoch 17/50\n",
      "3990/3990 [==============================] - 18s 5ms/step - loss: 0.0103 - val_loss: 0.0306\n",
      "Epoch 18/50\n",
      "3990/3990 [==============================] - 18s 5ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 19/50\n",
      "3990/3990 [==============================] - 19s 5ms/step - loss: 0.0103 - val_loss: 0.0098\n",
      "Epoch 20/50\n",
      "3990/3990 [==============================] - 18s 5ms/step - loss: 0.0103 - val_loss: 0.0099\n",
      "Epoch 21/50\n",
      "3990/3990 [==============================] - 18s 5ms/step - loss: 0.0103 - val_loss: 0.0115\n",
      "Epoch 22/50\n",
      "3990/3990 [==============================] - 17s 4ms/step - loss: 0.0103 - val_loss: 0.0098\n",
      "Epoch 23/50\n",
      "3979/3990 [============================>.] - ETA: 0s - loss: 0.0103Restoring model weights from the end of the best epoch: 13.\n",
      "3990/3990 [==============================] - 19s 5ms/step - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 23: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para SIERRA en clúster 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para SIERRA en clúster 6: 939576470.7955184, R2 Mensual: 0.9484129429667706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1491139/3138292417.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for species: SIERRA, cluster: 5\n",
      "Epoch 1/50\n",
      "678/678 [==============================] - 7s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "678/678 [==============================] - 3s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "678/678 [==============================] - 3s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "678/678 [==============================] - 3s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "678/678 [==============================] - 3s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "678/678 [==============================] - 3s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "678/678 [==============================] - 3s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "678/678 [==============================] - 3s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "678/678 [==============================] - 3s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "668/678 [============================>.] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "678/678 [==============================] - 3s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para SIERRA en clúster 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para SIERRA en clúster 5: 267887691617.66666, R2 Mensual: -0.3452082393260856\n",
      "Training model for species: SIERRA, cluster: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1491139/3138292417.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 4s 191ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "1/4 [======>.......................] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "4/4 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para SIERRA en clúster 2\n",
      "No se tienen datos suficientes para SIERRA en clúster 2 en los últimos seis meses de 2023\n",
      "Training model for species: SIERRA, cluster: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5388/5388 [==============================] - 28s 5ms/step - loss: 6.6397e-04 - val_loss: 2.9974e-04\n",
      "Epoch 2/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.9232e-04 - val_loss: 3.0135e-04\n",
      "Epoch 3/50\n",
      "5388/5388 [==============================] - 24s 5ms/step - loss: 5.8632e-04 - val_loss: 3.1565e-04\n",
      "Epoch 4/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.7428e-04 - val_loss: 3.4346e-04\n",
      "Epoch 5/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.7416e-04 - val_loss: 3.0129e-04\n",
      "Epoch 6/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.7557e-04 - val_loss: 2.8019e-04\n",
      "Epoch 7/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.6620e-04 - val_loss: 2.8160e-04\n",
      "Epoch 8/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.6476e-04 - val_loss: 2.7469e-04\n",
      "Epoch 9/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.6765e-04 - val_loss: 2.8003e-04\n",
      "Epoch 10/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.6313e-04 - val_loss: 2.7829e-04\n",
      "Epoch 11/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.6122e-04 - val_loss: 2.8672e-04\n",
      "Epoch 12/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.6480e-04 - val_loss: 2.6963e-04\n",
      "Epoch 13/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.6075e-04 - val_loss: 3.0362e-04\n",
      "Epoch 14/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.6187e-04 - val_loss: 2.7053e-04\n",
      "Epoch 15/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.6144e-04 - val_loss: 2.7845e-04\n",
      "Epoch 16/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.5509e-04 - val_loss: 2.9195e-04\n",
      "Epoch 17/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.5592e-04 - val_loss: 2.7086e-04\n",
      "Epoch 18/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.5620e-04 - val_loss: 2.6727e-04\n",
      "Epoch 19/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.5508e-04 - val_loss: 2.7343e-04\n",
      "Epoch 20/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.5667e-04 - val_loss: 3.5102e-04\n",
      "Epoch 21/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.5424e-04 - val_loss: 2.7447e-04\n",
      "Epoch 22/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.5533e-04 - val_loss: 2.6765e-04\n",
      "Epoch 23/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.5524e-04 - val_loss: 2.8036e-04\n",
      "Epoch 24/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.5410e-04 - val_loss: 3.5774e-04\n",
      "Epoch 25/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.5357e-04 - val_loss: 2.8267e-04\n",
      "Epoch 26/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.5548e-04 - val_loss: 2.9651e-04\n",
      "Epoch 27/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.5418e-04 - val_loss: 2.7472e-04\n",
      "Epoch 28/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.5401e-04 - val_loss: 2.6722e-04\n",
      "Epoch 29/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.4947e-04 - val_loss: 2.8417e-04\n",
      "Epoch 30/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.5125e-04 - val_loss: 3.0769e-04\n",
      "Epoch 31/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.5379e-04 - val_loss: 2.6830e-04\n",
      "Epoch 32/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.5269e-04 - val_loss: 5.9928e-04\n",
      "Epoch 33/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.5448e-04 - val_loss: 2.7242e-04\n",
      "Epoch 34/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.4957e-04 - val_loss: 3.0381e-04\n",
      "Epoch 35/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.5481e-04 - val_loss: 2.9338e-04\n",
      "Epoch 36/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.5069e-04 - val_loss: 2.7122e-04\n",
      "Epoch 37/50\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.5507e-04 - val_loss: 2.7642e-04\n",
      "Epoch 38/50\n",
      "5388/5388 [==============================] - ETA: 0s - loss: 5.5344e-04Restoring model weights from the end of the best epoch: 28.\n",
      "5388/5388 [==============================] - 25s 5ms/step - loss: 5.5344e-04 - val_loss: 2.7389e-04\n",
      "Epoch 38: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para SIERRA en clúster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para SIERRA en clúster 1: 336579882.394815, R2 Mensual: 0.943365092544263\n",
      "Training model for species: SIERRA, cluster: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1491139/3138292417.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19/19 [==============================] - 5s 40ms/step - loss: 0.1547 - val_loss: 0.0061\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.1271 - val_loss: 0.0098\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.0980 - val_loss: 0.0275\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0762 - val_loss: 0.0538\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0815 - val_loss: 0.0479\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0723 - val_loss: 0.0620\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0649 - val_loss: 0.0485\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0645 - val_loss: 0.0772\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0550 - val_loss: 0.0616\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0521 - val_loss: 0.0860\n",
      "Epoch 11/50\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.0622Restoring model weights from the end of the best epoch: 1.\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0485 - val_loss: 0.0817\n",
      "Epoch 11: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para SIERRA en clúster 4\n",
      "No se tienen datos suficientes para SIERRA en clúster 4 en los últimos seis meses de 2023\n",
      "Training model for species: TIBURON, cluster: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5870/5870 [==============================] - 31s 5ms/step - loss: 0.0020 - val_loss: 7.4398e-05\n",
      "Epoch 2/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0020 - val_loss: 1.0046e-04\n",
      "Epoch 3/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0020 - val_loss: 8.6524e-05\n",
      "Epoch 4/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0020 - val_loss: 1.6193e-04\n",
      "Epoch 5/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0019 - val_loss: 1.8350e-04\n",
      "Epoch 6/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0018 - val_loss: 8.1813e-05\n",
      "Epoch 7/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0019 - val_loss: 1.0518e-04\n",
      "Epoch 8/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0019 - val_loss: 7.3916e-05\n",
      "Epoch 9/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0018 - val_loss: 1.1305e-04\n",
      "Epoch 10/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0018 - val_loss: 8.0858e-05\n",
      "Epoch 11/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0017 - val_loss: 2.9106e-04\n",
      "Epoch 12/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0018 - val_loss: 4.6202e-04\n",
      "Epoch 13/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0017 - val_loss: 6.7561e-05\n",
      "Epoch 14/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0018 - val_loss: 8.5059e-05\n",
      "Epoch 15/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0018 - val_loss: 7.7562e-05\n",
      "Epoch 16/50\n",
      "5870/5870 [==============================] - 26s 4ms/step - loss: 0.0017 - val_loss: 6.8551e-05\n",
      "Epoch 17/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0017 - val_loss: 1.4664e-04\n",
      "Epoch 18/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0017 - val_loss: 2.0646e-04\n",
      "Epoch 19/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0017 - val_loss: 3.6892e-04\n",
      "Epoch 20/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0017 - val_loss: 1.7845e-04\n",
      "Epoch 21/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0016 - val_loss: 6.7329e-05\n",
      "Epoch 22/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0016 - val_loss: 2.4888e-04\n",
      "Epoch 23/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0017 - val_loss: 9.0679e-05\n",
      "Epoch 24/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0017 - val_loss: 7.3850e-05\n",
      "Epoch 25/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0017 - val_loss: 2.0041e-04\n",
      "Epoch 26/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0016 - val_loss: 7.9734e-05\n",
      "Epoch 27/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0017 - val_loss: 1.1648e-04\n",
      "Epoch 28/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0017 - val_loss: 1.6357e-04\n",
      "Epoch 29/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0016 - val_loss: 7.7801e-05\n",
      "Epoch 30/50\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0017 - val_loss: 8.9535e-05\n",
      "Epoch 31/50\n",
      "5859/5870 [============================>.] - ETA: 0s - loss: 0.0016Restoring model weights from the end of the best epoch: 21.\n",
      "5870/5870 [==============================] - 27s 5ms/step - loss: 0.0016 - val_loss: 1.2846e-04\n",
      "Epoch 31: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para TIBURON en clúster 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 2ms/step\n",
      "23/23 [==============================] - 0s 2ms/step\n",
      "23/23 [==============================] - 0s 2ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 2ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 2ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 2ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 2ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 2ms/step\n",
      "23/23 [==============================] - 0s 2ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 2ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 2ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para TIBURON en clúster 7: 466518015.1075092, R2 Mensual: -1.7207074145793473\n",
      "Training model for species: TIBURON, cluster: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1491139/3138292417.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "99/99 [==============================] - 4s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "92/99 [==========================>...] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "99/99 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para TIBURON en clúster 0\n",
      "No se tienen datos suficientes para TIBURON en clúster 0 en los últimos seis meses de 2023\n",
      "Training model for species: TIBURON, cluster: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4142/4142 [==============================] - 23s 5ms/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 2/50\n",
      "4142/4142 [==============================] - 18s 4ms/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 3/50\n",
      "4142/4142 [==============================] - 19s 4ms/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 4/50\n",
      "4142/4142 [==============================] - 19s 5ms/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 5/50\n",
      "4142/4142 [==============================] - 19s 5ms/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 6/50\n",
      "4142/4142 [==============================] - 19s 5ms/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 7/50\n",
      "4142/4142 [==============================] - 19s 5ms/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 8/50\n",
      "4142/4142 [==============================] - 18s 4ms/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 9/50\n",
      "4142/4142 [==============================] - 19s 5ms/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 10/50\n",
      "4142/4142 [==============================] - 19s 5ms/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 11/50\n",
      "4142/4142 [==============================] - 19s 5ms/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 12/50\n",
      "4142/4142 [==============================] - 19s 5ms/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 13/50\n",
      "4142/4142 [==============================] - 19s 5ms/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 14/50\n",
      "4142/4142 [==============================] - 19s 5ms/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 15/50\n",
      "4142/4142 [==============================] - 19s 5ms/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 16/50\n",
      "4142/4142 [==============================] - 19s 5ms/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 17/50\n",
      "4142/4142 [==============================] - 18s 4ms/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 18/50\n",
      "4142/4142 [==============================] - 19s 5ms/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 19/50\n",
      "4142/4142 [==============================] - 19s 5ms/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 20/50\n",
      "4142/4142 [==============================] - 19s 5ms/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 21/50\n",
      "4142/4142 [==============================] - 19s 5ms/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 22/50\n",
      "4142/4142 [==============================] - 18s 4ms/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 23/50\n",
      "4142/4142 [==============================] - 18s 4ms/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 24/50\n",
      "4138/4142 [============================>.] - ETA: 0s - loss: 0.0015Restoring model weights from the end of the best epoch: 14.\n",
      "4142/4142 [==============================] - 18s 4ms/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 24: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para TIBURON en clúster 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para TIBURON en clúster 3: 1520633057.1795428, R2 Mensual: 0.9657984745611953\n",
      "Training model for species: TIBURON, cluster: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1491139/3138292417.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4124/4124 [==============================] - 21s 4ms/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 2/50\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 3/50\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 4/50\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 5/50\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 6/50\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 7/50\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 8/50\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 9/50\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 10/50\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 11/50\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 12/50\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 13/50\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 14/50\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 15/50\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 16/50\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 17/50\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 18/50\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 19/50\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 20/50\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 21/50\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 22/50\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 23/50\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 24/50\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 25/50\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 26/50\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 27/50\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 28/50\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 29/50\n",
      "4122/4124 [============================>.] - ETA: 0s - loss: 0.0022Restoring model weights from the end of the best epoch: 19.\n",
      "4124/4124 [==============================] - 18s 4ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 29: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para TIBURON en clúster 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para TIBURON en clúster 6: 81875006.66894443, R2 Mensual: 0.9579534162420911\n",
      "Training model for species: TIBURON, cluster: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1491139/3138292417.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "54/54 [==============================] - 4s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "53/54 [============================>.] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "54/54 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para TIBURON en clúster 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 528ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "MSE Mensual para TIBURON en clúster 5: 12373200.0, R2 Mensual: -0.352619445746549\n",
      "Training model for species: TIBURON, cluster: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1491139/3138292417.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 4s 278ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "1/3 [=========>....................] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "3/3 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para TIBURON en clúster 2\n",
      "No se tienen datos suficientes para TIBURON en clúster 2 en los últimos seis meses de 2023\n",
      "Training model for species: TIBURON, cluster: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5963/5963 [==============================] - 29s 4ms/step - loss: 0.0030 - val_loss: 0.0133\n",
      "Epoch 2/50\n",
      "5963/5963 [==============================] - 26s 4ms/step - loss: 0.0025 - val_loss: 0.0128\n",
      "Epoch 3/50\n",
      "5963/5963 [==============================] - 26s 4ms/step - loss: 0.0025 - val_loss: 0.0129\n",
      "Epoch 4/50\n",
      "5963/5963 [==============================] - 26s 4ms/step - loss: 0.0024 - val_loss: 0.0130\n",
      "Epoch 5/50\n",
      "5963/5963 [==============================] - 26s 4ms/step - loss: 0.0024 - val_loss: 0.0123\n",
      "Epoch 6/50\n",
      "5963/5963 [==============================] - 26s 4ms/step - loss: 0.0024 - val_loss: 0.0123\n",
      "Epoch 7/50\n",
      "5963/5963 [==============================] - 26s 4ms/step - loss: 0.0024 - val_loss: 0.0125\n",
      "Epoch 8/50\n",
      "5963/5963 [==============================] - 26s 4ms/step - loss: 0.0024 - val_loss: 0.0123\n",
      "Epoch 9/50\n",
      "5963/5963 [==============================] - 26s 4ms/step - loss: 0.0024 - val_loss: 0.0135\n",
      "Epoch 10/50\n",
      "5963/5963 [==============================] - 26s 4ms/step - loss: 0.0023 - val_loss: 0.0120\n",
      "Epoch 11/50\n",
      "5963/5963 [==============================] - 26s 4ms/step - loss: 0.0023 - val_loss: 0.0132\n",
      "Epoch 12/50\n",
      "5963/5963 [==============================] - 26s 4ms/step - loss: 0.0023 - val_loss: 0.0121\n",
      "Epoch 13/50\n",
      "5963/5963 [==============================] - 26s 4ms/step - loss: 0.0023 - val_loss: 0.0123\n",
      "Epoch 14/50\n",
      "5963/5963 [==============================] - 26s 4ms/step - loss: 0.0023 - val_loss: 0.0126\n",
      "Epoch 15/50\n",
      "5963/5963 [==============================] - 26s 4ms/step - loss: 0.0023 - val_loss: 0.0126\n",
      "Epoch 16/50\n",
      "5963/5963 [==============================] - 26s 4ms/step - loss: 0.0023 - val_loss: 0.0123\n",
      "Epoch 17/50\n",
      "5963/5963 [==============================] - 26s 4ms/step - loss: 0.0023 - val_loss: 0.0128\n",
      "Epoch 18/50\n",
      "5963/5963 [==============================] - 26s 4ms/step - loss: 0.0023 - val_loss: 0.0126\n",
      "Epoch 19/50\n",
      "5963/5963 [==============================] - 26s 4ms/step - loss: 0.0023 - val_loss: 0.0128\n",
      "Epoch 20/50\n",
      "5957/5963 [============================>.] - ETA: 0s - loss: 0.0023Restoring model weights from the end of the best epoch: 10.\n",
      "5963/5963 [==============================] - 26s 4ms/step - loss: 0.0023 - val_loss: 0.0129\n",
      "Epoch 20: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para TIBURON en clúster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 1s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "MSE Mensual para TIBURON en clúster 1: 1405708734.4881077, R2 Mensual: 0.9696283055275228\n",
      "Training model for species: TIBURON, cluster: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1491139/3138292417.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 4s 23ms/step - loss: 0.0024 - val_loss: 0.3273\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.7442e-04 - val_loss: 0.3218\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.3064e-04 - val_loss: 0.3233\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.4491e-04 - val_loss: 0.3177\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.8972e-04 - val_loss: 0.3165\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.4625e-04 - val_loss: 0.3134\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.5429e-04 - val_loss: 0.3083\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.2903e-04 - val_loss: 0.2922\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.3422e-04 - val_loss: 0.2960\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.9831e-04 - val_loss: 0.2880\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.7158e-04 - val_loss: 0.2908\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.8121e-04 - val_loss: 0.2788\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.7420e-04 - val_loss: 0.2845\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.9908e-04 - val_loss: 0.2610\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.4153e-04 - val_loss: 0.2397\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.5212e-04 - val_loss: 0.2580\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.9905e-04 - val_loss: 0.2611\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.0533e-04 - val_loss: 0.2650\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.9724e-04 - val_loss: 0.2526\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.0554e-04 - val_loss: 0.2551\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.0225e-04 - val_loss: 0.2510\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.9312e-04 - val_loss: 0.2553\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.3108e-04 - val_loss: 0.2525\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.0463e-04 - val_loss: 0.2669\n",
      "Epoch 25/50\n",
      "26/32 [=======================>......] - ETA: 0s - loss: 3.0606e-04Restoring model weights from the end of the best epoch: 15.\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.8968e-04 - val_loss: 0.2551\n",
      "Epoch 25: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para TIBURON en clúster 4\n",
      "No se tienen datos suficientes para TIBURON en clúster 4 en los últimos seis meses de 2023\n",
      "Training model for species: JUREL, cluster: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "500/500 [==============================] - 6s 6ms/step - loss: 0.0082 - val_loss: 0.0058\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0081 - val_loss: 0.0060\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0080 - val_loss: 0.0058\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0079 - val_loss: 0.0057\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0079 - val_loss: 0.0058\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0077 - val_loss: 0.0068\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0076 - val_loss: 0.0054\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0072 - val_loss: 0.0052\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0071 - val_loss: 0.0051\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0069 - val_loss: 0.0052\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0061 - val_loss: 0.0106\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 35/50\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0050Restoring model weights from the end of the best epoch: 25.\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 35: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para JUREL en clúster 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para JUREL en clúster 7: 1231263.4466962398, R2 Mensual: 0.7021286058479757\n",
      "Training model for species: JUREL, cluster: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1491139/3138292417.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1707/1707 [==============================] - 12s 5ms/step - loss: 5.7955e-04 - val_loss: 0.0027\n",
      "Epoch 2/50\n",
      "1707/1707 [==============================] - 7s 4ms/step - loss: 5.2453e-04 - val_loss: 0.0027\n",
      "Epoch 3/50\n",
      "1707/1707 [==============================] - 7s 4ms/step - loss: 5.3039e-04 - val_loss: 0.0027\n",
      "Epoch 4/50\n",
      "1707/1707 [==============================] - 8s 4ms/step - loss: 5.2424e-04 - val_loss: 0.0027\n",
      "Epoch 5/50\n",
      "1707/1707 [==============================] - 8s 4ms/step - loss: 5.2325e-04 - val_loss: 0.0027\n",
      "Epoch 6/50\n",
      "1707/1707 [==============================] - 7s 4ms/step - loss: 5.1917e-04 - val_loss: 0.0027\n",
      "Epoch 7/50\n",
      "1707/1707 [==============================] - 7s 4ms/step - loss: 5.1857e-04 - val_loss: 0.0027\n",
      "Epoch 8/50\n",
      "1707/1707 [==============================] - 7s 4ms/step - loss: 5.1918e-04 - val_loss: 0.0027\n",
      "Epoch 9/50\n",
      "1707/1707 [==============================] - 7s 4ms/step - loss: 5.2292e-04 - val_loss: 0.0027\n",
      "Epoch 10/50\n",
      "1707/1707 [==============================] - 7s 4ms/step - loss: 5.1698e-04 - val_loss: 0.0027\n",
      "Epoch 11/50\n",
      "1707/1707 [==============================] - 7s 4ms/step - loss: 5.1787e-04 - val_loss: 0.0027\n",
      "Epoch 12/50\n",
      "1707/1707 [==============================] - 7s 4ms/step - loss: 5.1798e-04 - val_loss: 0.0028\n",
      "Epoch 13/50\n",
      "1706/1707 [============================>.] - ETA: 0s - loss: 5.1933e-04Restoring model weights from the end of the best epoch: 3.\n",
      "1707/1707 [==============================] - 7s 4ms/step - loss: 5.1906e-04 - val_loss: 0.0027\n",
      "Epoch 13: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para JUREL en clúster 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para JUREL en clúster 3: 175050645.47781405, R2 Mensual: 0.6773353615319347\n",
      "Training model for species: JUREL, cluster: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1491139/3138292417.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1639/1639 [==============================] - 11s 5ms/step - loss: 0.0152 - val_loss: 0.0105\n",
      "Epoch 2/50\n",
      "1639/1639 [==============================] - 7s 4ms/step - loss: 0.0143 - val_loss: 0.0090\n",
      "Epoch 3/50\n",
      "1639/1639 [==============================] - 7s 4ms/step - loss: 0.0143 - val_loss: 0.0100\n",
      "Epoch 4/50\n",
      "1639/1639 [==============================] - 7s 4ms/step - loss: 0.0139 - val_loss: 0.0082\n",
      "Epoch 5/50\n",
      "1639/1639 [==============================] - 7s 4ms/step - loss: 0.0134 - val_loss: 0.0083\n",
      "Epoch 6/50\n",
      "1639/1639 [==============================] - 7s 4ms/step - loss: 0.0135 - val_loss: 0.0081\n",
      "Epoch 7/50\n",
      "1639/1639 [==============================] - 7s 4ms/step - loss: 0.0134 - val_loss: 0.0077\n",
      "Epoch 8/50\n",
      "1639/1639 [==============================] - 7s 4ms/step - loss: 0.0131 - val_loss: 0.0078\n",
      "Epoch 9/50\n",
      "1639/1639 [==============================] - 7s 4ms/step - loss: 0.0132 - val_loss: 0.0079\n",
      "Epoch 10/50\n",
      "1639/1639 [==============================] - 7s 4ms/step - loss: 0.0132 - val_loss: 0.0078\n",
      "Epoch 11/50\n",
      "1639/1639 [==============================] - 7s 4ms/step - loss: 0.0131 - val_loss: 0.0082\n",
      "Epoch 12/50\n",
      "1639/1639 [==============================] - 7s 4ms/step - loss: 0.0131 - val_loss: 0.0077\n",
      "Epoch 13/50\n",
      "1639/1639 [==============================] - 7s 4ms/step - loss: 0.0131 - val_loss: 0.0075\n",
      "Epoch 14/50\n",
      "1639/1639 [==============================] - 7s 4ms/step - loss: 0.0131 - val_loss: 0.0077\n",
      "Epoch 15/50\n",
      "1639/1639 [==============================] - 7s 4ms/step - loss: 0.0131 - val_loss: 0.0078\n",
      "Epoch 16/50\n",
      "1639/1639 [==============================] - 7s 4ms/step - loss: 0.0130 - val_loss: 0.0078\n",
      "Epoch 17/50\n",
      "1639/1639 [==============================] - 7s 4ms/step - loss: 0.0129 - val_loss: 0.0078\n",
      "Epoch 18/50\n",
      "1639/1639 [==============================] - 7s 4ms/step - loss: 0.0129 - val_loss: 0.0076\n",
      "Epoch 19/50\n",
      "1639/1639 [==============================] - 7s 4ms/step - loss: 0.0128 - val_loss: 0.0077\n",
      "Epoch 20/50\n",
      "1639/1639 [==============================] - 7s 4ms/step - loss: 0.0128 - val_loss: 0.0078\n",
      "Epoch 21/50\n",
      "1639/1639 [==============================] - 7s 4ms/step - loss: 0.0129 - val_loss: 0.0080\n",
      "Epoch 22/50\n",
      "1639/1639 [==============================] - 7s 4ms/step - loss: 0.0128 - val_loss: 0.0082\n",
      "Epoch 23/50\n",
      "1635/1639 [============================>.] - ETA: 0s - loss: 0.0129Restoring model weights from the end of the best epoch: 13.\n",
      "1639/1639 [==============================] - 7s 4ms/step - loss: 0.0129 - val_loss: 0.0077\n",
      "Epoch 23: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para JUREL en clúster 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para JUREL en clúster 6: 61755727.3070485, R2 Mensual: 0.8229174250684812\n",
      "Training model for species: JUREL, cluster: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1491139/3138292417.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 4s 32ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "14/21 [===================>..........] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "21/21 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para JUREL en clúster 5\n",
      "No se tienen datos suficientes para JUREL en clúster 5 en los últimos seis meses de 2023\n",
      "Training model for species: JUREL, cluster: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 4s 54ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      " 1/12 [=>............................] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "12/12 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para JUREL en clúster 2\n",
      "No se tienen datos suficientes para JUREL en clúster 2 en los últimos seis meses de 2023\n",
      "Training model for species: JUREL, cluster: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3896/3896 [==============================] - 20s 4ms/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 2/50\n",
      "3896/3896 [==============================] - 17s 4ms/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 3/50\n",
      "3896/3896 [==============================] - 17s 4ms/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 4/50\n",
      "3896/3896 [==============================] - 17s 4ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 5/50\n",
      "3896/3896 [==============================] - 17s 4ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 6/50\n",
      "3896/3896 [==============================] - 17s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 7/50\n",
      "3896/3896 [==============================] - 17s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 8/50\n",
      "3896/3896 [==============================] - 17s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 9/50\n",
      "3896/3896 [==============================] - 17s 4ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 10/50\n",
      "3896/3896 [==============================] - 17s 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 11/50\n",
      "3896/3896 [==============================] - 17s 4ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 12/50\n",
      "3896/3896 [==============================] - 17s 4ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 13/50\n",
      "3896/3896 [==============================] - 17s 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 14/50\n",
      "3896/3896 [==============================] - 17s 4ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 15/50\n",
      "3884/3896 [============================>.] - ETA: 0s - loss: 0.0039Restoring model weights from the end of the best epoch: 5.\n",
      "3896/3896 [==============================] - 17s 4ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 15: early stopping\n",
      "Modelo MoE, scaler y datos de entrenamiento guardados para JUREL en clúster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cedo/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 1s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "MSE Mensual para JUREL en clúster 1: 284401676.4919075, R2 Mensual: 0.8820440774088545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1491139/3138292417.py:58: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_totals = results_df.set_index('date').resample('M').sum()\n"
     ]
    }
   ],
   "source": [
    "# Obtener listas de especies y clústeres únicos\n",
    "unique_species = data['species'].unique()\n",
    "unique_clusters = data['Cluster_Label'].unique()\n",
    "\n",
    "# Definir la especie y clúster desde donde retomar el proceso y detenerlo\n",
    "start_species = 'CORVINA'\n",
    "start_cluster = 7.0\n",
    "stop_species = 'JUREL'\n",
    "stop_cluster = 4.0\n",
    "\n",
    "# Inicializar banderas\n",
    "start_training = False\n",
    "stop_training = False\n",
    "\n",
    "for species_name in unique_species:\n",
    "    for cluster_label in unique_clusters:\n",
    "        # Activar la bandera cuando se alcance la especie y clúster deseados para iniciar\n",
    "        if species_name == start_species and cluster_label == start_cluster:\n",
    "            start_training = True\n",
    "        \n",
    "        # Detener el proceso cuando se alcance la especie y clúster deseados para detener\n",
    "        if species_name == stop_species and cluster_label == stop_cluster:\n",
    "            stop_training = True\n",
    "        \n",
    "        # Continuar solo si la bandera de inicio está activada y la de detener no lo está\n",
    "        if start_training and not stop_training:\n",
    "            # Filtrar los datos para obtener una especie y un clúster específico\n",
    "            filtered_data = data[(data['species'] == species_name) & (data['Cluster_Label'] == cluster_label)]\n",
    "            \n",
    "            if len(filtered_data) >= look_back:\n",
    "                filtered_data = filtered_data.sort_values('date')\n",
    "                try:\n",
    "                    print(f'Training model for species: {species_name}, cluster: {cluster_label}')\n",
    "                    model, scaler = train_and_save_moe_model(filtered_data, species_name, cluster_label, look_back)\n",
    "\n",
    "                    # Guardar los datos para las bandas de confianza\n",
    "                    test_data_2023 = filtered_data[(filtered_data['date'].dt.year == 2023) & (filtered_data['date'].dt.month >= 1)]\n",
    "                    if len(test_data_2023) >= look_back:\n",
    "                        predictions, lower_bound, upper_bound = predict_with_confidence_intervals(model, scaler, test_data_2023, look_back)\n",
    "                        real_values = test_data_2023['landed_w_kg'].values[look_back:]\n",
    "                        \n",
    "                        # Crear un DataFrame para los resultados\n",
    "                        results_df = pd.DataFrame({\n",
    "                            'date': test_data_2023['date'].values[look_back:],\n",
    "                            'real_values': real_values,\n",
    "                            'predictions': predictions,\n",
    "                            'lower_bound': lower_bound,\n",
    "                            'upper_bound': upper_bound\n",
    "                        })\n",
    "                        \n",
    "                        # Guardar los resultados\n",
    "                        results_directory = 'resultados_moe'\n",
    "                        os.makedirs(results_directory, exist_ok=True)\n",
    "                        results_path = os.path.join(results_directory, f'{species_name}_cluster_{cluster_label}_predictions.csv')\n",
    "                        results_df.to_csv(results_path, index=False)\n",
    "                        \n",
    "                        # Agrupar por mes y sumar los valores\n",
    "                        monthly_totals = results_df.set_index('date').resample('M').sum()\n",
    "                        \n",
    "                        # Calcular MSE y R2 para los totales mensuales\n",
    "                        mse = mean_squared_error(monthly_totals['real_values'], monthly_totals['predictions'])\n",
    "                        r2 = r2_score(monthly_totals['real_values'], monthly_totals['predictions'])\n",
    "                        print(f'MSE Mensual para {species_name} en clúster {cluster_label}: {mse}, R2 Mensual: {r2}')\n",
    "                        \n",
    "                        # Crear figura\n",
    "                        plt.figure(figsize=(10, 6))\n",
    "                        plt.plot(monthly_totals.index, monthly_totals['real_values'], color='blue', label='Real')\n",
    "                        plt.plot(monthly_totals.index, monthly_totals['predictions'], color='red', linestyle='--', label='Predicho')\n",
    "                        plt.fill_between(monthly_totals.index, monthly_totals['lower_bound'], monthly_totals['upper_bound'], color='gray', alpha=0.2, label='Intervalo de Confianza 95%')\n",
    "                        plt.title(f'Totales Mensuales de {species_name} en clúster {cluster_label} para los Últimos Seis Meses de 2023')\n",
    "                        plt.xlabel('Fecha')\n",
    "                        plt.ylabel('Peso Desembarcado (kg)')\n",
    "                        plt.legend()\n",
    "                        plot_path = os.path.join(results_directory, f'{species_name}_cluster_{cluster_label}_plot.png')\n",
    "                        plt.savefig(plot_path)\n",
    "                        plt.close()\n",
    "                    else:\n",
    "                        print(f'No se tienen datos suficientes para {species_name} en clúster {cluster_label} en los últimos seis meses de 2023')\n",
    "                except Exception as e:\n",
    "                    print(f'Error entrenando el modelo para especie: {species_name}, clúster: {cluster_label}. Error: {e}')\n",
    "        \n",
    "        # Salir del bucle si se alcanza el punto de detener\n",
    "        if stop_training:\n",
    "            break\n",
    "    if stop_training:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cedo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
